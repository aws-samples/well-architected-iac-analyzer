This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-21T16:02:37.849Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
ecs_fargate_app/
  backend/
    src/
      config/
        aws.config.ts
        configuration.ts
        storage.config.ts
      modules/
        analyzer/
          dto/
            iac-generation.dto.ts
          analyzer.controller.ts
          analyzer.gateway.ts
          analyzer.module.ts
          analyzer.service.ts
        report/
          report.controller.ts
          report.module.ts
          report.service.ts
        well-architected/
          well-architected.controller.ts
          well-architected.module.ts
          well-architected.service.ts
      shared/
        dto/
          analysis.dto.ts
          file-upload.dto.ts
        interfaces/
          analysis.interface.ts
        services/
          storage.service.ts
      tasks/
        cleanup.task.ts
      app.module.ts
      main.ts
    nest-cli.json
    package.json
    tsconfig.build.json
    tsconfig.json
  finch/
    backend.dev.Dockerfile
    backend.Dockerfile
    frontend.dev.Dockerfile
    frontend.Dockerfile
    nginx.conf
  frontend/
    src/
      assets/
        react.svg
      components/
        utils/
          table-configs/
            analysis-table-config.ts
          CopyButton.tsx
          help-content.tsx
          HelpButton.tsx
        AnalysisResults.tsx
        DetailsModal.tsx
        DocumentView.tsx
        FileUpload.tsx
        IaCTemplateSelector.tsx
        PillarSelector.tsx
        RiskSummary.tsx
        WellArchitectedAnalyzer.tsx
        WorkloadIdInput.tsx
      contexts/
        HelpPanelContext.tsx
      hooks/
        useAnalyzer.ts
      services/
        api.ts
        socket.ts
      types/
        index.ts
      App.css
      App.tsx
      index.css
      main.tsx
      vite-env.d.ts
    index.html
    package.json
    tsconfig.app.json
    tsconfig.json
    tsconfig.node.json
    vite.config.ts
  lambda_kb_synchronizer/
    kb_synchronizer.py
    requirements.txt
  well_architected_docs/
    well_architected_best_practices.csv
    well_architected_best_practices.json
  wa_genai_stack.py
.gitignore
app.py
cdk.json
CODE_OF_CONDUCT.md
config.ini
CONTRIBUTING.md
deploy-wa-analyzer.sh
destroy-wa-analyzer.sh
dev.sh
finch-compose.dev.yaml
finch.yaml
LICENSE
package.json
README.md
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="ecs_fargate_app/backend/src/config/aws.config.ts">
import { Injectable } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { S3Client } from '@aws-sdk/client-s3';
import { BedrockRuntimeClient } from '@aws-sdk/client-bedrock-runtime';
import { WellArchitectedClient } from '@aws-sdk/client-wellarchitected';
import { BedrockAgentRuntimeClient } from '@aws-sdk/client-bedrock-agent-runtime';

@Injectable()
export class AwsConfigService {
  constructor(private configService: ConfigService) {}

  createS3Client(): S3Client {
    return new S3Client(this.getAwsConfig());
  }

  createBedrockClient(): BedrockRuntimeClient {
    return new BedrockRuntimeClient(this.getAwsConfig());
  }

  createWAClient(): WellArchitectedClient {
    return new WellArchitectedClient(this.getAwsConfig());
  }

  createBedrockAgentClient(): BedrockAgentRuntimeClient {
    return new BedrockAgentRuntimeClient(this.getAwsConfig());
  }

  private getAwsConfig() {
    return {
      region: this.configService.get<string>('aws.region'),
    };
  }
}
</file>

<file path="ecs_fargate_app/backend/src/config/configuration.ts">
export default () => ({
  port: parseInt(process.env.PORT, 10) || 3000,
  aws: {
    region: process.env.AWS_REGION || process.env.CDK_DEPLOY_REGION,
    s3: {
      waDocsBucket: process.env.WA_DOCS_S3_BUCKET,
    },
    bedrock: {
      knowledgeBaseId: process.env.KNOWLEDGE_BASE_ID,
      modelId: process.env.MODEL_ID,
    },
  },
});
</file>

<file path="ecs_fargate_app/backend/src/config/storage.config.ts">
export default () => ({
    AWS_REGION: process.env.AWS_REGION || 'us-east-1',
    STORAGE_BUCKET_NAME: process.env.STORAGE_BUCKET_NAME || 'wa-analyzer-files'
});
</file>

<file path="ecs_fargate_app/backend/src/modules/analyzer/dto/iac-generation.dto.ts">
import { IsString, IsArray, IsOptional } from 'class-validator';
import { IaCTemplateType } from '../../../shared/dto/analysis.dto';

export class IaCGenerationRequestDto {
  @IsString()
  fileId: string;

  @IsString()
  fileName: string;

  @IsString()
  fileType: string;

  @IsArray()
  recommendations: any[];

  @IsOptional()
  @IsString()
  templateType?: IaCTemplateType;
}
</file>

<file path="ecs_fargate_app/backend/src/modules/analyzer/analyzer.controller.ts">
import {
  Controller,
  Post,
  Body,
  HttpException,
  HttpStatus,
  Logger,
  UseInterceptors,
  UploadedFile, BadRequestException
} from '@nestjs/common';
import { FileInterceptor } from '@nestjs/platform-express';
import { diskStorage } from 'multer';
import { v4 as uuidv4 } from 'uuid';
import * as path from 'path';
import { FileUploadResponseDto } from '../../shared/dto/file-upload.dto';
import { AnalyzerService } from './analyzer.service';
import * as fs from 'fs';
import { AnalyzeRequestDto, IaCTemplateType } from '../../shared/dto/analysis.dto';

@Controller('analyzer')
export class AnalyzerController {
  private readonly logger = new Logger(AnalyzerController.name);
  private readonly uploadDir = 'temp-uploads';

  constructor(private readonly analyzerService: AnalyzerService) {
    // Ensure upload directory exists
    if (!fs.existsSync(this.uploadDir)) {
      fs.mkdirSync(this.uploadDir, { recursive: true });
    }
  }

  @Post('upload')
  @UseInterceptors(FileInterceptor('file', {
    storage: diskStorage({
      destination: './temp-uploads',
      filename: (req, file, cb) => {
        const fileId = uuidv4();
        const extension = path.extname(file.originalname);
        cb(null, `${fileId}${extension}`);
      },
    }),
    limits: {
      fileSize: 50 * 1024 * 1024, // 50MB limit
    },
  }))
  async uploadFile(@UploadedFile() file): Promise<FileUploadResponseDto> {
    if (!file) {
      throw new BadRequestException('No file uploaded');
      return;
    }

    return {
      fileId: path.parse(file.filename).name, // Return UUID without extension
    };
  }

  @Post('analyze')
  async analyze(@Body() analyzeRequest: AnalyzeRequestDto) {
    try {
      // Read the file content from the temp uploads directory
      const filePath = path.join(this.uploadDir, analyzeRequest.fileId);
      
      if (!fs.existsSync(filePath)) {
        throw new HttpException('File not found. Please upload the file again.', HttpStatus.NOT_FOUND);
      }
      const fileContent = await fs.promises.readFile(filePath, 'utf8');

      // Clean up the temporary file after reading
      try {
        await fs.promises.unlink(filePath);
      } catch (error) {
        this.logger.warn(`Failed to delete temporary file ${filePath}: ${error}`);
      }
      return await this.analyzerService.analyze(
        fileContent,
        analyzeRequest.fileName,
        analyzeRequest.workloadId,
        analyzeRequest.selectedPillars,
        analyzeRequest.fileType
      );
    } catch (error) {
      this.logger.error('Analysis failed:', error);
      throw new HttpException(
        `Failed to analyze template: ${error.message || error}`,
        HttpStatus.INTERNAL_SERVER_ERROR
      );
    }
  }

  @Post('generate-iac')
  async generateIacDocument(@Body() body: {
    fileId: string;
    fileName: string;
    fileType: string;
    recommendations: any[];
    templateType: IaCTemplateType;
  }) {
    try {
      const result = await this.analyzerService.generateIacDocument(
        body.fileId,
        body.fileName,
        body.fileType,
        body.recommendations,
        body.templateType
      );
      return result;
    } catch (error) {
      this.logger.error('IaC generation failed:', error);
      return {
        content: '',
        isCancelled: false,
        error: error instanceof Error ? error.message : 'Failed to generate IaC document'
      };
    }
  }

  @Post('get-more-details')
  async getMoreDetails(@Body() body: {
    selectedItems: any[];
    fileContent: string;
    fileType: string;
    templateType?: IaCTemplateType;
  }) {
    try {
      const result = await this.analyzerService.getMoreDetails(
        body.selectedItems,
        body.fileContent,
        body.fileType,
        body.templateType
      );
      return result;
    } catch (error) {
      this.logger.error('Getting more details failed:', error);
      return {
        content: '',
        error: error instanceof Error ? error.message : 'Failed to get detailed analysis'
      };
    }
  }

  @Post('cancel-iac-generation')
  async cancelIaCGeneration() {
    this.analyzerService.cancelIaCGeneration();
    return { message: 'Generation cancelled successfully' };
  }

  @Post('cancel-analysis')
  async cancelAnalysis() {
    try {
      this.analyzerService.cancelAnalysis();
      return { message: 'Analysis cancelled' };
    } catch (error) {
      this.logger.error('Failed to cancel analysis:', error);
      throw new HttpException(
        `Failed to cancel analysis: ${error.message || error}`,
        HttpStatus.INTERNAL_SERVER_ERROR
      );
    }
  }
}
</file>

<file path="ecs_fargate_app/backend/src/modules/analyzer/analyzer.gateway.ts">
import { WebSocketGateway, WebSocketServer, OnGatewayConnection, OnGatewayDisconnect } from '@nestjs/websockets';
import { Server, Socket } from 'socket.io';
import { Logger } from '@nestjs/common';

@WebSocketGateway({
  cors: {
    origin: '*',
  },
  path: '/socket.io/', // Explicitly set the path
  pingInterval: 10000, // Send ping every 10 seconds
  pingTimeout: 5000,   // Wait 5 seconds for pong response
})
export class AnalyzerGateway implements OnGatewayConnection, OnGatewayDisconnect {
  @WebSocketServer()
  server: Server;

  private readonly logger = new Logger(AnalyzerGateway.name);

  handleConnection(client: Socket) {
    this.logger.log(`Client connected: ${client.id}`);
  }

  handleDisconnect(client: Socket) {
    this.logger.log(`Client disconnected: ${client.id}`);
  }

  emitAnalysisProgress(data: {
    processedQuestions: number;
    totalQuestions: number;
    currentPillar: string;
    currentQuestion: string;
  }) {
    this.server.emit('analysisProgress', data);
  }

  emitImplementationProgress(data: {
    status: string;
    progress: number;
  }) {
    this.server.emit('implementationProgress', data);
  }
}
</file>

<file path="ecs_fargate_app/backend/src/modules/analyzer/analyzer.module.ts">
import { Module } from '@nestjs/common';
import { AnalyzerController } from './analyzer.controller';
import { AnalyzerService } from './analyzer.service';
import { StorageService } from '../../shared/services/storage.service';
import { ConfigModule } from '@nestjs/config';
import storageConfig from '../../config/storage.config';
import { AnalyzerGateway } from './analyzer.gateway';
import { AwsConfigService } from '../../config/aws.config';

@Module({
  imports: [
    ConfigModule.forFeature(storageConfig),
  ],
  controllers: [AnalyzerController],
  providers: [AnalyzerService, AnalyzerGateway, AwsConfigService, StorageService],
  exports: [AnalyzerService, StorageService]
})
export class AnalyzerModule {}
</file>

<file path="ecs_fargate_app/backend/src/modules/analyzer/analyzer.service.ts">
import {Injectable, Logger} from '@nestjs/common';
import {StorageService} from '../../shared/services/storage.service';
import {AwsConfigService} from '../../config/aws.config';
import {InvokeModelCommand} from '@aws-sdk/client-bedrock-runtime';
import {RetrieveCommand} from '@aws-sdk/client-bedrock-agent-runtime';
import {GetObjectCommand} from '@aws-sdk/client-s3';
import {paginateListAnswers, AnswerSummary} from '@aws-sdk/client-wellarchitected';
import {ConfigService} from '@nestjs/config';
import {AnalyzerGateway} from './analyzer.gateway';
import {IaCTemplateType} from '../../shared/dto/analysis.dto';
import {Subject} from 'rxjs';
import {AnalysisResult} from '../../shared/interfaces/analysis.interface';

interface QuestionGroup {
    pillar: string;
    title: string;
    questionId: string;
    bestPractices: string[];
    bestPracticeIds: string[];
}

interface WellArchitectedBestPractice {
    Pillar: string;
    Question: string;
    questionId: string;
    'Best Practice': string;
    bestPracticeId: string;
}

interface BestPractice {
    name: string;
    applied: boolean;
    reasonApplied: string;
    reasonNotApplied: string;
    recommendations: string;
}

interface ModelResponse {
    bestPractices: BestPractice[];
}

interface WellArchitectedAnswer {
    AnswerSummaries: AnswerSummary[];
    WorkloadId: string;
    LensAlias?: string;
    LensArn?: string;
}

interface DocumentSection {
    content: string;
    order: number;
    description: string;
}

interface ModelSectionResponse {
    isComplete: boolean;
    sections: DocumentSection[];
}

@Injectable()
export class AnalyzerService {
    private readonly logger = new Logger(AnalyzerService.name);
    private cachedBestPractices: WellArchitectedBestPractice[] | null = null;
    private cancelGeneration$ = new Subject<void>();
    private cancelAnalysis$ = new Subject<void>();

    constructor(
        private readonly awsConfig: AwsConfigService,
        private readonly configService: ConfigService,
        private readonly analyzerGateway: AnalyzerGateway,
        private readonly storageService: StorageService,
    ) {
    }

    private isImageFile(fileType: string | undefined): boolean {
        if (!fileType) return false;
        return fileType.startsWith('image/');
    }

    cancelAnalysis() {
        this.cancelAnalysis$.next();
    }

    async analyze(fileContent: string, fileName: string, workloadId: string, selectedPillars: string[], fileType: string): Promise<{
        results: AnalysisResult[];
        isCancelled: boolean;
        error?: string;
        fileId: string
    }> {
        const fileId = await this.storageService.uploadFile(fileContent, fileName);
        const results: AnalysisResult[] = [];
        try {
            // Load all best practices once
            await this.loadBestPractices(workloadId);

            // Pre-calculate question groups for all selected pillars
            const pillarQuestionGroups = await Promise.all(
                selectedPillars.map(pillar => this.retrieveBestPractices(pillar, workloadId))
            );

            // Calculate total questions
            const totalQuestions = pillarQuestionGroups.reduce(
                (sum, groups) => sum + groups.length,
                0
            );

            let processedQuestions = 0;

            // Create a Promise that resolves when cancelAnalysis$ emits
            const cancelPromise = new Promise<boolean>((resolve) => {
                const subscription = this.cancelAnalysis$.subscribe(() => {
                    subscription.unsubscribe();
                    resolve(true);
                });
            });

            // Process each pillar's questions
            for (let i = 0; i < selectedPillars.length; i++) {
                const pillar = selectedPillars[i];
                const questionGroups = pillarQuestionGroups[i];

                for (const question of questionGroups) {
                    try {
                        // Check for cancellation
                        const isCancelled = await Promise.race([
                            cancelPromise,
                            Promise.resolve(false)
                        ]);

                        if (isCancelled) {
                            this.analyzerGateway.emitAnalysisProgress({
                                processedQuestions,
                                totalQuestions,
                                currentPillar: pillar,
                                currentQuestion: 'Analysis cancelled',
                            });
                            return {results, isCancelled: true, fileId: fileId};
                        }

                        let kbContexts: string[];
                        try {
                            kbContexts = await this.retrieveFromKnowledgeBase(
                                question.pillar,
                                question.title
                            );
                        } catch (error) {
                            this.logger.error(`Error retrieving from knowledge base: ${error}`);
                            return {
                                results,
                                isCancelled: false,
                                error: `Error retrieving from knowledge base. Analysis stopped. ${error}`,
                                fileId: fileId
                            };
                        }

                        // Emit progress before processing
                        this.analyzerGateway.emitAnalysisProgress({
                            processedQuestions,
                            totalQuestions,
                            currentPillar: pillar,
                            currentQuestion: question.title,
                        });

                        try {
                            const analysis = await this.analyzeQuestion(
                                fileContent,
                                question,
                                kbContexts,
                                fileType
                            );
                            results.push(analysis);
                        } catch (error) {
                            this.logger.error(`Error analyzing question "${question.pillar} - ${question.title}". Error: ${error}`);
                            // Return partial results with error
                            return {
                                results,
                                isCancelled: false,
                                error: `${error}. Error analyzing question "${question.pillar} - ${question.title}". Analysis stopped, ${processedQuestions} questions where analyzed out of ${totalQuestions}.`,
                                fileId: fileId
                            };
                        }

                        processedQuestions++;

                        // Emit progress after processing
                        this.analyzerGateway.emitAnalysisProgress({
                            processedQuestions,
                            totalQuestions,
                            currentPillar: pillar,
                            currentQuestion: question.title,
                        });
                    } catch (error) {
                        this.logger.error(`Error processing question: ${error}`);
                        // Return partial results with error
                        return {
                            results,
                            isCancelled: false,
                            error: 'Error processing question. Analysis stopped.',
                            fileId: fileId
                        };
                    }
                }
            }

            return {results, isCancelled: false, fileId: fileId};
        } catch (error) {
            this.logger.error('Analysis failed:', error);
            // Return partial results with error
            return {
                results,
                isCancelled: false,
                error: `Showing partial results. Analysis failed with error: ${error}`,
                fileId: fileId
            };
        }
    }

    cancelIaCGeneration() {
        this.cancelGeneration$.next();
    }

    async generateIacDocument(
        fileId: string,
        fileName: string,
        fileType: string,
        recommendations: any[],
        templateType?: IaCTemplateType
    ): Promise<{ content: string; isCancelled: boolean; error?: string }> {
        const fileContent = await this.storageService.getFileContent(fileId);
        try {
            // Only proceed if it's an image file
            if (!this.isImageFile(fileType)) {
                throw new Error('This operation is only supported for architecture diagrams');
            }

            let isComplete = false;
            let allSections: DocumentSection[] = [];
            let iteration = 0;

            // Extract base64 data and media type
            const base64Data = fileContent.split(',')[1];
            const mediaType = fileContent.split(';')[0].split(':')[1];

            while (!isComplete) {
                try {
                    this.analyzerGateway.emitImplementationProgress({
                        status: `Generating IaC document...`,
                        progress: Math.min(iteration * 10, 90)
                    });

                    iteration++;

                    const response = await this.invokeBedrockModelForIacGeneration(
                        base64Data,
                        mediaType,
                        recommendations,
                        allSections.length,
                        allSections.length > 0 ? `${JSON.stringify(allSections, null, 2)}` : 'No previous sections generated yet',
                        templateType
                    );

                    // If generation was cancelled, return what we have so far
                    if (response.isCancelled) {
                        const sortedSections = allSections.sort((a, b) => a.order - b.order);
                        const cancellationNote = '# Note: Template generation was cancelled. Below is a partial version.\n\n';
                        const content = sortedSections.map(section =>
                            `# ${section.description}\n${section.content}`
                        ).join('\n\n');

                        return {
                            content: cancellationNote + content,
                            isCancelled: true
                        };
                    }

                    const {
                        isComplete: batchComplete,
                        sections
                    } = this.parseImplementationModelResponse(response.content);

                    allSections.push(...sections);
                    isComplete = batchComplete;

                    await new Promise(resolve => setTimeout(resolve, 1000));
                } catch (error) {
                    this.logger.error(`Error in IaC generation iteration: ${error}`);
                    // If we have any sections generated, return them as partial results
                    if (allSections.length > 0) {
                        const sortedSections = allSections.sort((a, b) => a.order - b.order);
                        const errorNote = '# Note: Template generation encountered an error. Below is a partial version.\n\n';
                        const content = sortedSections.map(section =>
                            `# ${section.description}\n${section.content}`
                        ).join('\n\n');

                        return {
                            content: errorNote + content,
                            isCancelled: false,
                            error: `Template generation encountered an error. Showing partial results. ${error}`
                        };
                    }
                    throw error;
                }
            }

            this.analyzerGateway.emitImplementationProgress({
                status: 'Finalizing IaC document...',
                progress: 100
            });

            const sortedSections = allSections.sort((a, b) => a.order - b.order);
            return {
                content: sortedSections.map(section =>
                    `# ${section.description}\n${section.content}`
                ).join('\n\n'),
                isCancelled: false
            };

        } catch (error) {
            this.logger.error('Error generating IaC document:', error);
            throw new Error('Failed to generate IaC document');
        }
    }

    private parseImplementationModelResponse(content: string): ModelSectionResponse {
        const isComplete = content.includes('<end_of_iac_document_generation>');
        const cleanContent = content.replace('<end_of_iac_document_generation>', '').trim();

        // Split content into sections based on comments
        const sectionMatches = cleanContent.match(/#\s*Section\s*\d+.*?(?=#\s*Section|\s*$)/gs) || [];

        const sections: DocumentSection[] = sectionMatches.map(section => {
            const orderMatch = section.match(/^#\s*Section\s*(\d+)/);
            const descriptionMatch = section.match(/^#\s*Section\s*\d+\s*-\s*(.+?)\n/);
            const cleanedContent = section
                .replace(/^#\s*Section\s*\d+.*?\n/, '') // Remove section header
                .replace(/<message_truncated>\s*$/, '') // Remove <message_truncated> flag
                .trim();

            return {
                content: cleanedContent,
                order: orderMatch ? parseInt(orderMatch[1]) : 999,
                description: descriptionMatch ? descriptionMatch[1].trim() : 'Unnamed Section'
            };
        });

        return {
            isComplete,
            sections
        };
    }

    private buildDetailsPrompt(item: any, fileContent: string, previousContent: string): string {
        return `
          <bp_recommendation_analysis>
          ${JSON.stringify([item], null, 2)}
          </bp_recommendation_analysis>
          
          <iac_document>
          ${fileContent}
          </iac_document>
          ${previousContent ? `\nPreviously generated content:\n${previousContent}` : ''}
        `;
    }

    private buildDetailsSystemPrompt(): string {
        return `You are an AWS Cloud Solutions Architect who specializes in reviewing solution architecture documents against the AWS Well-Architected Framework. Your answer should be formatted in Markdown.
        
        For the best practice provided in the <bp_recommendation_analysis> section:
        1. Provide detailed implementation guidance
        2. Include CloudFormation or Terraform template modification examples based on the document in <iac_document> section. Use the same format as the <iac_document> document, for example, if the <iac_document> document is CloudFormation in YAML format then provide examples as YAML, if it is in JSON, provide examples in JSON and if it is a Terraform document, use Terraform language, etc.
        3. Include risks of not implementing the best practice
        4. Provide specific AWS services and features recommendations
        5. If you have completed your detailed analysis, add the marker "<end_of_details_generation>" at the very end
        6. If you have more details to provide, end your response with "<details_truncated>"
        
        Structure your response as:
        # {Pillar as in the <bp_recommendation_analysis> section} - {Best Practice Name as in the <bp_recommendation_analysis> section}
        ## Implementation Guidance
        [Your guidance here]
        ## Template Modifications
        [Your examples here]
        ## Risks and Recommendations
        [Your analysis here]`;
    }

    async getMoreDetails(
        selectedItems: any[],
        fileContent: string,
        fileType: string,
        templateType?: IaCTemplateType
    ): Promise<{ content: string; error?: string }> {
        const filteredItems = selectedItems.filter(item => !item.applied);
        try {
            if (!selectedItems || selectedItems.length === 0) {
                throw new Error('No items selected for detailed analysis');
            }

            if (!fileContent) {
                throw new Error('No file content provided');
            }

            if (!fileType) {
                throw new Error('No file type provided');
            }

            let allDetails = '';
            let hasError = false;
            const totalItems = filteredItems.length;
            const isImage = this.isImageFile(fileType);

            this.analyzerGateway.emitImplementationProgress({
                status: `Analyzing 1 of ${totalItems} selected best practices not applied - Best practice: '${filteredItems[0].name}'`,
                progress: 0
            });

            for (let i = 0; i < totalItems; i++) {
                try {
                    const item = filteredItems[i];

                    let itemDetails = '';
                    let isComplete = false;

                    while (!isComplete) {
                        const response = isImage
                            ? await this.invokeBedrockModelForImageDetails(
                                fileContent,
                                item,
                                itemDetails,
                                templateType
                            )
                            : await this.invokeBedrockModelForMoreDetails(
                                this.buildDetailsPrompt(item, fileContent, itemDetails),
                                this.buildDetailsSystemPrompt()
                            );

                        const {content, isComplete: sectionComplete} =
                            this.parseDetailsModelResponse(response.content[0].text);

                        itemDetails += content;
                        isComplete = sectionComplete;

                        await new Promise(resolve => setTimeout(resolve, 1000));
                    }

                    // Update progress
                    this.analyzerGateway.emitImplementationProgress({
                        status: `Analyzing ${i + 1} of ${totalItems} selected best practices not applied - Best practice: '${item.name}'`,
                        progress: Math.round(((i + 1) / totalItems) * 100)
                    });

                    allDetails += itemDetails + '\n\n---\n\n';
                } catch (error) {
                    this.logger.error(`Error analyzing item ${i + 1}:`, error);
                    hasError = true;
                    // Continue with next item instead of stopping completely
                    continue;
                }
            }

            this.analyzerGateway.emitImplementationProgress({
                status: 'Analysis complete',
                progress: 100
            });

            // If we have any details but also encountered errors
            if (allDetails && hasError) {
                return {
                    content: allDetails,
                    error: 'Some items could not be analyzed. Showing partial results.'
                };
            }

            // If we have no details at all
            if (!allDetails) {
                throw new Error('Failed to generate any detailed analysis');
            }

            return {content: allDetails.trim()};
        } catch (error) {
            this.logger.error('Error getting more details:', error);
            if (error instanceof Error) {
                throw error;
            }
            throw new Error('Failed to get detailed analysis');
        }
    }

    private async invokeBedrockModelForImageDetails(
        imageContent: string,
        item: any,
        previousContent: string,
        templateType?: IaCTemplateType
    ): Promise<any> {
        const bedrockClient = this.awsConfig.createBedrockClient();
        const modelId = this.configService.get<string>('aws.bedrock.modelId');

        // Extract base64 data and media type from data URL
        const base64Data = imageContent.split(',')[1];
        const mediaType = imageContent.split(';')[0].split(':')[1];

        const systemPrompt = `You are an AWS Cloud Solutions Architect who specializes in reviewing architecture diagrams against the AWS Well-Architected Framework. Your answer should be formatted in Markdown.

        For the best practice provided in the <bp_recommendation_analysis> section:
        1. Provide detailed implementation guidance
        2. Include ${templateType} examples
        3. Include risks of not implementing the best practice
        4. Provide specific AWS services and features recommendations
        5. If you have completed your detailed analysis, add the marker "<end_of_details_generation>" at the very end
        6. If you have more details to provide, end your response with "<details_truncated>"
        
        Structure your response in Markdown format as follows:
        # {Pillar as in the <bp_recommendation_analysis> section} - {Best Practice Name as in the <bp_recommendation_analysis> section}
        ## Implementation Guidance
        [Detailed guidance based on the diagram]
        ## Architecture Modifications
        [Specific changes needed in the architecture]
        ## Risks and Recommendations
        [Analysis of risks and detailed recommendations including ${templateType} examples]
    
        If you have completed your analysis, add "<end_of_details_generation>"
        If you have more details to provide, end with "<details_truncated>"`;

        const prompt = `<bp_recommendation_analysis>${JSON.stringify([item], null, 2)}</bp_recommendation_analysis>
        ${previousContent ? `\nPreviously generated content:\n${previousContent}` : ''}`;

        const payload = {
            max_tokens: 4096,
            anthropic_version: "bedrock-2023-05-31",
            system: systemPrompt,
            messages: [
                {
                    role: "user",
                    content: [
                        {
                            type: "image",
                            source: {
                                type: "base64",
                                media_type: mediaType,
                                data: base64Data,
                            },
                        },
                        {
                            type: "text",
                            text: prompt
                        }
                    ],
                }
            ],
        };

        try {
            const command = new InvokeModelCommand({
                modelId,
                contentType: 'application/json',
                accept: 'application/json',
                body: JSON.stringify(payload),
            });

            const response = await bedrockClient.send(command);
            return JSON.parse(new TextDecoder().decode(response.body));
        } catch (error) {
            this.logger.error('Error invoking Bedrock model:', error);
            throw new Error(`Failed to get detailed analysis. Error invoking Bedrock model: ${error}`);
        }
    }

    private parseDetailsModelResponse(content: string): { content: string; isComplete: boolean } {
        const isComplete = content.includes('<end_of_details_generation>');

        // Clean up the content
        let cleanContent = content
            .replace('<end_of_details_generation>', '')
            .replace('<details_truncated>', '')
            .trim();

        // If this isn't the final section, we need to find the last complete section
        if (!isComplete && cleanContent.includes('#')) {
            const sections = cleanContent.split(/(?=# )/);
            // Remove the last potentially incomplete section
            sections.pop();
            cleanContent = sections.join('');
        }

        return {
            content: cleanContent,
            isComplete
        };
    }

    private async retrieveFromKnowledgeBase(pillar: string, question: string) {
        const bedrockAgent = this.awsConfig.createBedrockAgentClient();
        const knowledgeBaseId = this.configService.get<string>('aws.bedrock.knowledgeBaseId');

        const command = new RetrieveCommand({
            knowledgeBaseId,
            retrievalQuery: {
                text: `For each best practice of the question "${question}" in the Well-Architected pillar "${pillar}" provide:
        - Recommendations
        - Best practices
        - Examples
        - Risks`,
            },
            retrievalConfiguration: {
                vectorSearchConfiguration: {
                    numberOfResults: 20,
                },
            },
        });

        const response = await bedrockAgent.send(command);
        return response.retrievalResults?.map(result => result.content?.text || '') || [];
    }

    private async analyzeQuestion(
        fileContent: string,
        question: QuestionGroup,
        kbContexts: string[],
        fileType: string
    ) {
        const isImage = this.isImageFile(fileType);
        const prompt = isImage
            ? this.buildImagePrompt(question, kbContexts)
            : this.buildPrompt(question, kbContexts);

        const systemPrompt = isImage
            ? this.buildImageSystemPrompt(question)
            : this.buildSystemPrompt(fileContent, question);

        const response = isImage
            ? await this.invokeBedrockModelWithImage(prompt, systemPrompt, fileContent)
            : await this.invokeBedrockModel(prompt, systemPrompt);

        return {
            pillar: question.pillar,
            question: question.title,
            questionId: question.questionId,
            bestPractices: this.parseModelResponse(response, question),
        };
    }

    private cleanJsonString(jsonString: string): string {
        // First trim everything outside the outermost curly braces
        const firstCurlyBrace = jsonString.indexOf('{');
        const lastCurlyBrace = jsonString.lastIndexOf('}');

        if (firstCurlyBrace !== -1 && lastCurlyBrace !== -1) {
            jsonString = jsonString.substring(firstCurlyBrace, lastCurlyBrace + 1);
        }

        // Remove newlines and extra spaces
        jsonString = jsonString.replace(/\s+/g, " ");

        // Remove spaces after colons that are not within quotes
        jsonString = jsonString.replace(/(?<!"):\s+/g, ":");

        // Remove spaces before colons
        jsonString = jsonString.replace(/\s+:/g, ":");

        // Remove spaces after commas that are not within quotes
        jsonString = jsonString.replace(/(?<!"),\s+/g, ",");

        // Remove spaces before commas
        jsonString = jsonString.replace(/\s+,/g, ",");

        // Remove spaces after opening brackets and before closing brackets
        jsonString = jsonString.replace(/{\s+/g, "{");
        jsonString = jsonString.replace(/\s+}/g, "}");
        jsonString = jsonString.replace(/\[\s+/g, "[");
        jsonString = jsonString.replace(/\s+\]/g, "]");

        // Convert Python boolean values to JSON boolean values
        jsonString = jsonString.replace(/: True/g, ": true");
        jsonString = jsonString.replace(/: False/g, ": false");

        return jsonString;
    }

    private buildImagePrompt(question: QuestionGroup, kbContexts: string[]): string {
        const bestPracticesJson = JSON.stringify({
            pillar: question.pillar,
            question: question.title,
            bestPractices: question.bestPractices
        }, null, 2);

        return `
          Analyze the provided architecture diagram against the following Well-Architected best practices.
          
          <kb>
          ${kbContexts.join('\n\n')}
          </kb>
    
          <best_practices_json>
          ${bestPracticesJson}
          </best_practices_json>
        `;
    }

    private buildImageSystemPrompt(question: QuestionGroup): string {
        const numberOfBestPractices = question.bestPractices.length;

        return `
          You are an AWS Cloud Solutions Architect who specializes in reviewing architecture diagrams against the AWS Well-Architected Framework, using a process called the Well-Architected Framework Review (WAFR).
          The WAFR process consists of evaluating the provided solution architecture document against the 6 pillars of the Well-Architected Framework, namely - Operational Excellence Pillar, Security Pillar, Reliability Pillar, Performance Efficiency Pillar, Cost Optimization Pillar, and Sustainability Pillar - by asking fixed questions for each pillar.
          An architecture diagram has been provided. Follow the instructions listed under "instructions" section below.

          <instructions>
      1) In the "best_practices_json" section, you are provided with the name of the ${numberOfBestPractices} Best Practices related to the questions "${question.title}" of the Well-Architected Framework. For each Best Practice, determine if it is applied or not in the given architecture diagram image.
      2) For each of the ${numberOfBestPractices} best practices listed in the "best_practices_json" section, create your respond in the following EXACT JSON format only:
      {
          "bestPractices": [
            {
              "name": [Exact Best Practice Name as given in Best Practices in the "best_practices_json" section],
              "applied": [Boolean],
              "reasonApplied": [Why do you consider this best practice is already applied or followed in the provided architecture diagram? (Important: 50 words maximum and only add this field when applied=true)],
              "reasonNotApplied": [Why do you consider this best practice is not applied or followed in the provided architecture diagram? (Important: 50 words maximum and only add this field when applied=false)],
              "recommendations": [Provide recommendations for the best practice. Include what is the risk of not following, and also provide recommendations and examples of how to implement this best practice. (Important: 350 words maximum and only add this field when applied=false)]
            }
          ]
      }

      For your reference, below is an example of how the JSON-formatted response should look like:
        {
            "bestPractices": [
                {
                "name": "Implement secure key and certificate management",
                "applied": true,
                "reasonApplied": "The architecture diagram references the use of an AWS Certificate Manager (ACM) certificate for the Application Load Balancer to enforce HTTPS encryption in transit."
                },
                {
                "name": "Enforce encryption in transit",
                "applied": true,
                "reasonApplied": "The Application Load Balancer referenced in the diagram is configured to use HTTPS protocol on port 443 with SSL policy ELBSecurityPolicy-2016-08."
                },
                {
                "name": "Prefer hub-and-spoke topologies over many-to-many mesh",
                "applied": false,
                "reasonNotApplied": "The architecture diagram does not provide details about the overall network topology or interconnections between multiple VPCs.",
                "recommendations": "While not specifically relevant for this single VPC deployment,if you have multiple VPCs that need to communicate,you should implement a hub-and-spoke model using transit gateways. This simplifies network management and reduces the risk of misconfiguration compared to peering every VPC directly in a mesh topology. The risk of using a mesh topology is increased complexity,potential misconfiguration leading to reachability issues,and difficulty applying consistent network policies across VPCs."
                }
            ]
        }

      3) Do not rephrase or summarize the practice name, and DO NOT skip any of the ${numberOfBestPractices} best practices listed in the "best_practices_json" section.
      4) Do not make any assumptions or make up information. Your responses should only be based on the actual architecture diagram provided.
      5) You are also provided with a Knowledge Base which has more information about the specific question from the Well-Architected Framework. The relevant parts from the Knowledge Base will be provided under the "kb" section.
      </instructions>
        `;
    }

    private buildPrompt(question: QuestionGroup, kbContexts: string[]): string {
        const bestPracticesJson = JSON.stringify({
            pillar: question.pillar,
            question: question.title,
            bestPractices: question.bestPractices
        }, null, 2);

        return `
      <kb>
      ${kbContexts.join('\n\n')}
      </kb>

      <best_practices_json>
      ${bestPracticesJson}
      </best_practices_json>
    `;
    }

    private buildSystemPrompt(fileContent: string, question: QuestionGroup): string {
        const numberOfBestPractices = question.bestPractices.length;

        return `
      You are an AWS Cloud Solutions Architect who specializes in reviewing solution architecture documents against the AWS Well-Architected Framework, using a process called the Well-Architected Framework Review (WAFR).
      The WAFR process consists of evaluating the provided solution architecture document against the 6 pillars of the Well-Architected Framework, namely - Operational Excellence Pillar, Security Pillar, Reliability Pillar, Performance Efficiency Pillar, Cost Optimization Pillar, and Sustainability Pillar - by asking fixed questions for each pillar.
      The content of a CloudFormation or Terraform template document is provided below in the "uploaded_template_document" section. Follow the instructions listed under "instructions" section below. 
      
      <instructions>
      1) In the "best_practices_json" section, you are provided with the name of the ${numberOfBestPractices} Best Practices related to the questions "${question.title}" of the Well-Architected Framework. For each Best Practice, determine if it is applied or not in the given CloudFormation or Terraform template document.
      2) For each of the ${numberOfBestPractices} best practices listed in the "best_practices_json" section, create your respond in the following EXACT JSON format only:
      {
          "bestPractices": [
            {
              "name": [Exact Best Practice Name as given in Best Practices in the "best_practices_json" section],
              "applied": [Boolean],
              "reasonApplied": [Why do you consider this best practice is already applied or followed in the provided architecture document? (Important: 50 words maximum and only add this field when applied=true)],
              "reasonNotApplied": [Why do you consider this best practice is not applied or followed in the provided architecture document? (Important: 50 words maximum and only add this field when applied=false)],
              "recommendations": [Provide recommendations for the best practice. Include what is the risk of not following, and also provide recommendations and examples of how to implement this best practice. (Important: 350 words maximum and only add this field when applied=false)]
            }
          ]
      }

      For your reference, below is an example of how the JSON-formatted response should look like:
        {
            "bestPractices": [
                {
                "name": "Implement secure key and certificate management",
                "applied": true,
                "reasonApplied": "The template provisions an AWS Certificate Manager (ACM) certificate for the Application Load Balancer to enforce HTTPS encryption in transit."
                },
                {
                "name": "Enforce encryption in transit",
                "applied": true,
                "reasonApplied": "The Application Load Balancer is configured to use HTTPS protocol on port 443 with the SSL policy ELBSecurityPolicy-2016-08."
                },
                {
                "name": "Prefer hub-and-spoke topologies over many-to-many mesh",
                "applied": false,
                "reasonNotApplied": "The template does not provide details about the overall network topology or interconnections between multiple VPCs.",
                "recommendations": "While not specifically relevant for this single VPC deployment,if you have multiple VPCs that need to communicate,you should implement a hub-and-spoke model using transit gateways. This simplifies network management and reduces the risk of misconfiguration compared to peering every VPC directly in a mesh topology. The risk of using a mesh topology is increased complexity,potential misconfiguration leading to reachability issues,and difficulty applying consistent network policies across VPCs."
                }
            ]
        }

      3) Do not rephrase or summarize the practice name, and DO NOT skip any of the ${numberOfBestPractices} best practices listed in the "best_practices_json" section.
      4) Do not make any assumptions or make up information. Your responses should only be based on the actual solution document provided in the "uploaded_template_document" section below.
      5) You are also provided with a Knowledge Base which has more information about the specific question from the Well-Architected Framework. The relevant parts from the Knowledge Base will be provided under the "kb" section.
      </instructions>

      <uploaded_template_document>
      ${fileContent}
      </uploaded_template_document>
    `;
    }

    private async invokeBedrockModelWithImage(
        prompt: string,
        systemPrompt: string,
        imageContent: string
    ): Promise<ModelResponse> {
        const bedrockClient = this.awsConfig.createBedrockClient();
        const modelId = this.configService.get<string>('aws.bedrock.modelId');

        // Extract base64 data from data URL
        const base64Data = imageContent.split(',')[1];
        const mediaType = imageContent.split(';')[0].split(':')[1];

        const payload = {
            max_tokens: 4096,
            anthropic_version: "bedrock-2023-05-31",
            system: systemPrompt,
            messages: [
                {
                    role: "user",
                    content: [
                        {
                            type: "image",
                            source: {
                                type: "base64",
                                media_type: mediaType,
                                data: base64Data,
                            },
                        },
                        {
                            type: "text",
                            text: prompt
                        }
                    ],
                }
            ],
        };

        try {
            const command = new InvokeModelCommand({
                modelId,
                contentType: 'application/json',
                accept: 'application/json',
                body: JSON.stringify(payload),
            });

            const response = await bedrockClient.send(command);
            const responseBody = new TextDecoder().decode(response.body);
            const parsedResponse = JSON.parse(responseBody);

            const cleanedAnalysisJsonString = this.cleanJsonString(parsedResponse.content[0].text)

            const parsedAnalysis = JSON.parse(cleanedAnalysisJsonString)

            // return JSON.parse(responseBody);
            return parsedAnalysis;
        } catch (error) {
            this.logger.error('Error invoking Bedrock model:', error);
            throw new Error(`Failed to analyze diagram with AI model. Error invoking Bedrock model: ${error}`);
        }
    }

    private async invokeBedrockModel(prompt: string, systemPrompt: string): Promise<ModelResponse> {
        const bedrockClient = this.awsConfig.createBedrockClient();
        const modelId = this.configService.get<string>('aws.bedrock.modelId');

        const payload = {
            max_tokens: 4096,
            anthropic_version: "bedrock-2023-05-31",
            system: systemPrompt,
            messages: [
                {
                    role: "user",
                    content: [{type: "text", text: prompt}],
                },
            ],
        };

        try {
            const command = new InvokeModelCommand({
                modelId,
                contentType: 'application/json',
                accept: 'application/json',
                body: JSON.stringify(payload),
            });

            const response = await bedrockClient.send(command);

            const responseBody = new TextDecoder().decode(response.body);

            const parsedResponse = JSON.parse(responseBody);

            const cleanedAnalysisJsonString = this.cleanJsonString(parsedResponse.content[0].text)

            const parsedAnalysis = JSON.parse(cleanedAnalysisJsonString)

            return parsedAnalysis;
        } catch (error) {
            this.logger.error('Error invoking Bedrock model:', error);
            throw new Error(`Failed to analyze template with AI model. Error invoking Bedrock model: ${error}`);
        }
    }

    private async invokeBedrockModelForMoreDetails(prompt: string, systemPrompt: string): Promise<any> {
        const bedrockClient = this.awsConfig.createBedrockClient();
        const modelId = this.configService.get<string>('aws.bedrock.modelId');

        const payload = {
            max_tokens: 4096,
            anthropic_version: "bedrock-2023-05-31",
            system: systemPrompt,
            messages: [
                {
                    role: "user",
                    content: [{type: "text", text: prompt}],
                },
            ],
        };

        try {
            const command = new InvokeModelCommand({
                modelId,
                contentType: 'application/json',
                accept: 'application/json',
                body: JSON.stringify(payload),
            });

            const response = await bedrockClient.send(command);

            const responseBody = new TextDecoder().decode(response.body);

            const parsedResponse = JSON.parse(responseBody);

            return parsedResponse;
        } catch (error) {
            this.logger.error('Error invoking Bedrock model:', error);
            throw new Error(`Failed to get detailed analysis. Error invoking Bedrock model: ${error}`);
        }
    }

    private async invokeBedrockModelForIacGeneration(
        imageData: string,
        mediaType: string,
        recommendations: any[],
        previousSections: number,
        allPreviousSections: string,
        templateType?: IaCTemplateType
    ): Promise<{ content: string; isCancelled: boolean }> {
        const bedrockClient = this.awsConfig.createBedrockClient();
        const modelId = this.configService.get<string>('aws.bedrock.modelId');

        const systemPrompt = `You are an AWS Cloud Solutions Architect who specializes in creating Infrastructure as Code (IaC) templates. 
        An architecture diagram has been provided along with AWS Well-Architected Framework recommendations for your reference.

        Generate a ${templateType} that implements this architecture following AWS best practices. Follow the instructions below when generating the template:

        <instructions>
        1. If the template you are going to generate is too large, split the template into multiple parts, each part starting with "# Section {number} - {description}.
        2. If you complete the template (e.g. you are providing with the last part of the template), end your response with "<end_of_iac_document_generation>".
        3. If you need to provide with more parts or sections for the template, end your response with "<message_truncated>".
        4. Each of your answers have at least 800 words, unless you are providing a response with the last part of a template.
        5. Do not repeat any section or part already provided.
        </instructions>
        
        For your reference, after you complete providing all parts of the template, all template parts/sections you provided will be concatenated into a single ${templateType}.`;

        const prompt = `Based on the architecture diagram and the recommendations within the <recommendations> below, generate an IaC template.
        Consider the ${previousSections} previously generated sections within the <previous_responses> section below (if any).

        <previous_responses>
        ${allPreviousSections}
        </previous_responses>
        
        <recommendations>
        ${JSON.stringify(recommendations, null, 2)}
        </recommendations>`;

        const payload = {
            max_tokens: 4096,
            anthropic_version: "bedrock-2023-05-31",
            system: systemPrompt,
            messages: [
                {
                    role: "user",
                    content: [
                        {
                            type: "image",
                            source: {
                                type: "base64",
                                media_type: mediaType,
                                data: imageData,
                            },
                        },
                        {
                            type: "text",
                            text: prompt
                        }
                    ],
                }
            ],
        };

        // Create a Promise that resolves when cancelGeneration$ emits
        const cancelPromise = new Promise<void>((resolve) => {
            const subscription = this.cancelGeneration$.subscribe(() => {
                subscription.unsubscribe();
                resolve();
            });
        });

        try {
            const command = new InvokeModelCommand({
                modelId,
                contentType: 'application/json',
                accept: 'application/json',
                body: JSON.stringify(payload),
            });

            // Race between the Bedrock call and cancellation
            const modelResponse = bedrockClient.send(command);
            const raceResult = await Promise.race([
                modelResponse,
                cancelPromise.then(() => null)
            ]);

            if (!raceResult) {
                // Cancelled
                return {
                    content: allPreviousSections,
                    isCancelled: true
                };
            }

            // Not cancelled, process normal response
            const responseContent = JSON.parse(new TextDecoder().decode(raceResult.body));
            return {
                content: responseContent.content[0].text,
                isCancelled: false
            };
        } catch (error) {
            this.logger.error('Error invoking Bedrock model:', error);
            throw new Error(`Failed to generate IaC document. Error invoking Bedrock model: ${error}`);
        }
    }

    private parseModelResponse(response: ModelResponse, questionGroup: QuestionGroup): any[] {
        try {
            return response.bestPractices.map((bp: BestPractice, index: number) => ({
                id: questionGroup.bestPracticeIds[index],
                name: bp.name,
                applied: bp.applied,
                reasonApplied: bp.reasonApplied,
                reasonNotApplied: bp.reasonNotApplied,
                recommendations: bp.recommendations,
            }));
        } catch (error) {
            this.logger.error('Error parsing model response:', error);
            throw new Error('Failed to parse analysis results');
        }
    }

    private async loadWellArchitectedAnswers(workloadId: string): Promise<WellArchitectedAnswer> {
        const waClient = this.awsConfig.createWAClient();

        try {
            const allAnswers: WellArchitectedAnswer = {
                AnswerSummaries: [],
                WorkloadId: workloadId,
            };

            const paginator = paginateListAnswers(
                {client: waClient},
                {
                    WorkloadId: workloadId,
                    LensAlias: 'wellarchitected'
                }
            );

            // Iterate through all pages
            for await (const page of paginator) {
                if (page.AnswerSummaries) {
                    allAnswers.AnswerSummaries.push(...page.AnswerSummaries);
                }

                // Set LensAlias and LensArn from the page response
                if (page.LensAlias) {
                    allAnswers.LensAlias = page.LensAlias;
                }
                if (page.LensArn) {
                    allAnswers.LensArn = page.LensArn;
                }
            }

            return allAnswers;
        } catch (error) {
            this.logger.error('Error fetching Well-Architected answers:', error);
            throw new Error('Failed to fetch Well-Architected answers');
        }
    }

    // Load best practices once
    private async loadBestPractices(workloadId: string): Promise<WellArchitectedBestPractice[]> {
        if (this.cachedBestPractices) {
            return this.cachedBestPractices;
        }

        const s3Client = this.awsConfig.createS3Client();
        const waDocsBucket = this.configService.get<string>('aws.s3.waDocsBucket');

        try {
            // Fetch best practices from S3
            const s3Response = await s3Client.send(
                new GetObjectCommand({
                    Bucket: waDocsBucket,
                    Key: 'well_architected_best_practices.json'
                })
            );

            const responseBody = await s3Response.Body?.transformToString();
            if (!responseBody) {
                throw new Error('No data received from S3');
            }

            const baseBestPractices: WellArchitectedBestPractice[] = JSON.parse(responseBody);

            // Fetch WA Tool answers
            const waAnswers = await this.loadWellArchitectedAnswers(workloadId);

            // Create mappings for both ChoiceIds and QuestionIds
            const choiceIdMapping = new Map<string, string>();
            const questionIdMapping = new Map<string, string>();

            waAnswers.AnswerSummaries.forEach(answer => {
                // Map QuestionId to Question Title
                questionIdMapping.set(answer.QuestionTitle, answer.QuestionId);

                // Map Choice Titles to ChoiceIds
                answer.Choices?.forEach(choice => {
                    if (choice.Title && choice.ChoiceId) {
                        // Create a unique key combining question and choice (for cases of WA questions with same BP title)
                        const uniqueKey = `${answer.QuestionTitle}|||${choice.Title}`;
                        choiceIdMapping.set(uniqueKey, choice.ChoiceId);
                    }
                });
            });

            // Enhance best practices with their corresponding ChoiceIds and QuestionIds
            this.cachedBestPractices = baseBestPractices.map(bp => {
                // Create the same unique key for lookup
                const uniqueKey = `${bp.Question}|||${bp['Best Practice']}`;

                return {
                    ...bp,
                    bestPracticeId: choiceIdMapping.get(uniqueKey) ||
                        this.generateFallbackBestPracticeId(`${bp.Question}-${bp['Best Practice']}`),
                    questionId: questionIdMapping.get(bp.Question) ||
                        this.generateFallbackBestPracticeId(bp.Question)
                };
            });

            return this.cachedBestPractices;
        } catch (error) {
            this.logger.error('Error loading best practices:', error);
            throw new Error('Failed to load Well-Architected best practices');
        }
    }

    private async retrieveBestPractices(pillarId: string, workloadId: string): Promise<QuestionGroup[]> {
        try {
            const allBestPractices = await this.loadBestPractices(workloadId);
            const pillarBestPractices = allBestPractices.filter(
                bp => bp.Pillar.toLowerCase().replace(/\s+/g, '-') === pillarId
            );

            const questionGroups = new Map<string, {
                practices: Array<{ practice: string, id: string }>,
                questionId: string
            }>();

            pillarBestPractices.forEach(bp => {
                if (!questionGroups.has(bp.Question)) {
                    questionGroups.set(bp.Question, {
                        practices: [],
                        questionId: bp.questionId
                    });
                }
                questionGroups.get(bp.Question)?.practices.push({
                    practice: bp['Best Practice'],
                    id: bp.bestPracticeId
                });
            });

            return Array.from(questionGroups.entries()).map(([question, data]) => ({
                pillar: pillarBestPractices[0].Pillar,
                title: question,
                questionId: data.questionId,
                bestPractices: data.practices.map(p => p.practice),
                bestPracticeIds: data.practices.map(p => p.id)
            }));
        } catch (error) {
            this.logger.error('Error retrieving best practices:', error);
            throw new Error('Failed to retrieve Well-Architected best practices');
        }
    }

    private generateFallbackBestPracticeId(name: string): string {
        return name
            .toLowerCase()
            .replace(/[^a-z0-9]+/g, '-')
            .replace(/^-|-$/g, '');
    }
}
</file>

<file path="ecs_fargate_app/backend/src/modules/report/report.controller.ts">
import { 
    Controller, 
    Post, 
    Body, 
    HttpException, 
    HttpStatus,
    Logger 
  } from '@nestjs/common';
  import { ReportService } from './report.service';
  import { GenerateReportDto } from '../../shared/dto/analysis.dto';
  
  @Controller('report')
  export class ReportController {
    private readonly logger = new Logger(ReportController.name);
  
    constructor(private readonly reportService: ReportService) {}
  
    @Post('generate')
    async generateReport(@Body() generateReportDto: GenerateReportDto) {
      try {
        return await this.reportService.generateReport(generateReportDto.workloadId);
      } catch (error) {
        this.logger.error('Failed to generate report:', error);
        throw new HttpException(
          `Failed to generate report: ${error.message || error}`,
          HttpStatus.INTERNAL_SERVER_ERROR
        );
      }
    }
  
    @Post('recommendations')
    async generateRecommendations(@Body() results: any[]) {
      try {
        return this.reportService.generateRecommendationsCsv(results);
      } catch (error) {
        this.logger.error('Failed to generate recommendations:', error);
        throw new HttpException(
          `Failed to generate recommendations: ${error.message || error}`,
          HttpStatus.INTERNAL_SERVER_ERROR
        );
      }
    }
  }
</file>

<file path="ecs_fargate_app/backend/src/modules/report/report.module.ts">
import { Module } from '@nestjs/common';
import { ReportService } from './report.service';
import { ReportController } from './report.controller';
import { AwsConfigService } from '../../config/aws.config';

@Module({
  providers: [ReportService, AwsConfigService],
  controllers: [ReportController],
  exports: [ReportService],
})
export class ReportModule {}
</file>

<file path="ecs_fargate_app/backend/src/modules/report/report.service.ts">
import { Injectable, Logger } from '@nestjs/common';
import { AwsConfigService } from '../../config/aws.config';
import { GetLensReviewReportCommand } from '@aws-sdk/client-wellarchitected';

interface AnalysisResult {
  pillar: string;
  question: string;
  bestPractices: {
    name: string;
    applied: boolean;
    reasonApplied?: string;
    reasonNotApplied?: string;
    recommendations?: string;
  }[];
}

@Injectable()
export class ReportService {
  private readonly logger = new Logger(ReportService.name);
  private readonly lensAlias = 'wellarchitected';

  constructor(private readonly awsConfig: AwsConfigService) {}

  async generateReport(workloadId: string) {
    try {
      const waClient = this.awsConfig.createWAClient();
      const command = new GetLensReviewReportCommand({
        WorkloadId: workloadId,
        LensAlias: this.lensAlias,
      });

      const response = await waClient.send(command);
      return response.LensReviewReport?.Base64String;
    } catch (error) {
      this.logger.error('Error generating report:', error);
      throw new Error(error);
    }
  }

  generateRecommendationsCsv(results: AnalysisResult[]): string {
    try {
      const rows = [
        ['Pillar', 'Question', 'Best Practice', 'Applied', 'Reason', 'Recommendations'],
      ];

      for (const result of results) {
        for (const bp of result.bestPractices) {
          rows.push([
            result.pillar,
            result.question,
            bp.name,
            bp.applied ? 'Yes' : 'No',
            bp.applied ? (bp.reasonApplied || '') : (bp.reasonNotApplied || ''),
            bp.recommendations || '',
          ]);
        }
      }

      return rows.map(row => row.map(cell => `"${cell}"`).join(',')).join('\n');
    } catch (error) {
      this.logger.error('Error generating recommendations CSV:', error);
      throw new Error(error);
    }
  }
}
</file>

<file path="ecs_fargate_app/backend/src/modules/well-architected/well-architected.controller.ts">
import {
  Controller,
  Get,
  Post,
  Delete,
  Body,
  Param,
  HttpException,
  HttpStatus,
  Logger
} from '@nestjs/common';
import { WellArchitectedService } from './well-architected.service';
import { CreateMilestoneDto } from '../../shared/dto/analysis.dto';

@Controller('well-architected')
export class WellArchitectedController {
  private readonly logger = new Logger(WellArchitectedController.name);

  constructor(private readonly waService: WellArchitectedService) { }

  @Get('review/:workloadId')
  async getLensReview(@Param('workloadId') workloadId: string) {
    try {
      return await this.waService.getLensReview(workloadId);
    } catch (error) {
      this.logger.error(`Failed to get lens review for workload ${workloadId}:`, error);
      throw new HttpException(
        `Failed to retrieve workload review: ${error.message || error}`,
        HttpStatus.INTERNAL_SERVER_ERROR
      );
    }
  }

  @Get('risk-summary/:workloadId')
  async getRiskSummary(@Param('workloadId') workloadId: string) {
    try {
      return await this.waService.getRiskSummary(workloadId);
    } catch (error) {
      this.logger.error(`Failed to get risk summary for workload ${workloadId}:`, error);
      throw new HttpException(
        `Failed to retrieve risk summary: ${error.message || error}`,
        HttpStatus.INTERNAL_SERVER_ERROR
      );
    }
  }

  @Post('milestone')
  async createMilestone(@Body() createMilestoneDto: CreateMilestoneDto) {
    try {
      return await this.waService.createMilestone(
        createMilestoneDto.workloadId,
        createMilestoneDto.milestoneName
      );
    } catch (error) {
      this.logger.error('Failed to create milestone:', error);
      throw new HttpException(
        `Failed to create milestone: ${error.message || error}`,
        HttpStatus.INTERNAL_SERVER_ERROR
      );
    }
  }

  @Post('answer/:workloadId')
  async updateAnswer(
    @Param('workloadId') workloadId: string,
    @Body() body: { questionId: string; selectedChoices: string[] }
  ) {
    try {
      return await this.waService.updateAnswer(
        workloadId,
        body.questionId,
        body.selectedChoices
      );
    } catch (error) {
      this.logger.error(`Failed to update answer for workload ${workloadId}, for question ${body.questionId}:`, error);
      throw new HttpException(
        `Failed to update answer: ${error.message || error}`,
        HttpStatus.INTERNAL_SERVER_ERROR
      );
    }
  }

  @Post('workload/create')
  async createWorkload(@Body() body: { isTemp: boolean }) {
    try {
      return await this.waService.createWorkload(body.isTemp);
    } catch (error) {
      this.logger.error('Failed to create workload:', error);
      throw new HttpException(
        `Failed to create workload: ${error.message || error}`,
        HttpStatus.INTERNAL_SERVER_ERROR
      );
    }
  }

  @Delete('workload/:workloadId')
  async deleteWorkload(@Param('workloadId') workloadId: string) {
    try {
      await this.waService.deleteWorkload(workloadId);
    } catch (error) {
      this.logger.error(`Failed to delete workload ${workloadId}:`, error);
      throw new HttpException(
        `Failed to delete workload: ${error.message || error}`,
        HttpStatus.INTERNAL_SERVER_ERROR
      );
    }
  }
}
</file>

<file path="ecs_fargate_app/backend/src/modules/well-architected/well-architected.module.ts">
import { Module } from '@nestjs/common';
import { WellArchitectedService } from './well-architected.service';
import { WellArchitectedController } from './well-architected.controller';
import { AwsConfigService } from '../../config/aws.config';

@Module({
  providers: [WellArchitectedService, AwsConfigService],
  controllers: [WellArchitectedController],
  exports: [WellArchitectedService],
})
export class WellArchitectedModule {}
</file>

<file path="ecs_fargate_app/backend/src/modules/well-architected/well-architected.service.ts">
import { Injectable, Logger } from '@nestjs/common';
import { AwsConfigService } from '../../config/aws.config';
import {
  GetLensReviewCommand,
  ListAnswersCommand,
  UpdateAnswerCommand,
  CreateMilestoneCommand,
  CreateWorkloadCommand,
  DeleteWorkloadCommand,
} from '@aws-sdk/client-wellarchitected';
import { randomBytes, randomUUID } from 'crypto';

@Injectable()
export class WellArchitectedService {
  private readonly logger = new Logger(WellArchitectedService.name);
  private readonly lensAlias = 'wellarchitected';

  constructor(private readonly awsConfig: AwsConfigService) { }

  async getLensReview(workloadId: string) {
    const waClient = this.awsConfig.createWAClient();
    const command = new GetLensReviewCommand({
      WorkloadId: workloadId,
      LensAlias: this.lensAlias,
    });

    try {
      return await waClient.send(command);
    } catch (error) {
      this.logger.error(`Error getting lens review for workload ${workloadId}:`, error);
      throw new Error(error);
    }
  }

  async listAnswers(workloadId: string, pillarId: string) {
    const waClient = this.awsConfig.createWAClient();
    const command = new ListAnswersCommand({
      WorkloadId: workloadId,
      LensAlias: this.lensAlias,
      PillarId: pillarId,
    });

    try {
      return await waClient.send(command);
    } catch (error) {
      this.logger.error(`Error listing answers for workload ${workloadId}:`, error);
      throw new Error(error);
    }
  }

  async updateAnswer(workloadId: string, questionId: string, selectedChoices: string[]) {
    const waClient = this.awsConfig.createWAClient();
    const command = new UpdateAnswerCommand({
      WorkloadId: workloadId,
      LensAlias: this.lensAlias,
      QuestionId: questionId,
      SelectedChoices: selectedChoices,
      Notes: 'Updated from WA IaC Analyzer app',
    });

    try {
      return await waClient.send(command);
    } catch (error) {
      this.logger.error(`Error updating answer for workload ${workloadId}:`, error);
      throw new Error(error);
    }
  }

  async createMilestone(workloadId: string, milestoneName: string) {
    const waClient = this.awsConfig.createWAClient();
    const command = new CreateMilestoneCommand({
      WorkloadId: workloadId,
      MilestoneName: milestoneName,
    });

    try {
      return await waClient.send(command);
    } catch (error) {
      this.logger.error(`Error creating milestone for workload ${workloadId}:`, error);
      throw new Error(error);
    }
  }

  async getRiskSummary(workloadId: string) {
    try {
      const review = await this.getLensReview(workloadId);
      const summaries = [];

      for (const pillarSummary of review.LensReview?.PillarReviewSummaries || []) {
        const answers = await this.listAnswers(workloadId, pillarSummary.PillarId!);

        const summary = {
          pillarName: pillarSummary.PillarName!,
          totalQuestions: 0,
          answeredQuestions: 0,
          highRisks: 0,
          mediumRisks: 0,
        };

        for (const answer of answers.AnswerSummaries || []) {
          summary.totalQuestions++;
          if (answer.Risk !== 'UNANSWERED') {
            summary.answeredQuestions++;
            if (answer.Risk === 'HIGH') summary.highRisks++;
            if (answer.Risk === 'MEDIUM') summary.mediumRisks++;
          }
        }

        summaries.push(summary);
      }

      return summaries;
    } catch (error) {
      this.logger.error(`Error getting risk summary for workload ${workloadId}:`, error);
      throw new Error(error);
    }
  }

  private generateRandomString(length: number): string {
    return randomBytes(length / 2).toString('hex');
  }

  async createWorkload(isTemp: boolean = false): Promise<string> {
    const waClient = this.awsConfig.createWAClient();
    
    const now = new Date();
    const timestamp = now.toLocaleString('en-AU', {
      year: 'numeric',
      month: '2-digit',
      day: '2-digit',
      hour: '2-digit',
      minute: '2-digit',
      second: '2-digit',
      hour12: false,
      timeZone: 'UTC'
    }).replace(/[/,:]/g, '').replace(/\s/g, '_');
    const randomString = this.generateRandomString(10);

    const workloadName = isTemp
      ? `DO_NOT_DELETE_temp_IaCAnalyzer_${randomString}`
      : `IaCAnalyzer_${timestamp}_UTC_${randomString}`;

    const command = new CreateWorkloadCommand({
      WorkloadName: workloadName,
      Description: isTemp ? 'Temporary workload for IaC Analyzer' : 'IaC Analyzer workload',
      Environment: 'PREPRODUCTION',
      ReviewOwner: 'IaC Analyzer',
      Lenses: ['wellarchitected'],
      NonAwsRegions: ['global'],
      Tags: {
        'WorkloadName': workloadName
      }
    });

    try {
      const response = await waClient.send(command);
      return response.WorkloadId!;
    } catch (error) {
      this.logger.error(`Error creating workload: ${error}`);
      throw new Error(error);
    }
  }

  async deleteWorkload(workloadId: string): Promise<void> {
    const waClient = this.awsConfig.createWAClient();
    const command = new DeleteWorkloadCommand({
      WorkloadId: workloadId,
      ClientRequestToken: randomUUID()
    });

    try {
      await waClient.send(command);
    } catch (error) {
      this.logger.error(`Error deleting workload: ${error}`);
      throw new Error(error);
    }
  }
}
</file>

<file path="ecs_fargate_app/backend/src/shared/dto/analysis.dto.ts">
import { IsString, IsArray, IsNotEmpty } from 'class-validator';

export class AnalyzeRequestDto {
  @IsString()
  @IsNotEmpty()
  workloadId: string;

  @IsArray()
  @IsString({ each: true })
  selectedPillars: string[];

  @IsString()
  @IsNotEmpty()
  fileId: string;

  @IsString()
  @IsNotEmpty()
  fileName: string;

  @IsString()
  @IsNotEmpty()
  fileType: string;

  templateType?: IaCTemplateType;
}

export class UpdateWorkloadDto {
  @IsString()
  @IsNotEmpty()
  workloadId: string;

  @IsArray()
  results: any[];
}

export class GenerateReportDto {
  @IsString()
  @IsNotEmpty()
  workloadId: string;
}

export class CreateMilestoneDto {
  @IsString()
  @IsNotEmpty()
  workloadId: string;

  @IsString()
  @IsNotEmpty()
  milestoneName: string;
}

export enum IaCTemplateType {
  CLOUDFORMATION_YAML = 'CloudFormation (.yaml) template',
  CLOUDFORMATION_JSON = 'CloudFormation (.json) template',
  TERRAFORM = 'Terraform (.tf) document'
}
</file>

<file path="ecs_fargate_app/backend/src/shared/dto/file-upload.dto.ts">
import { IsString, IsNotEmpty } from 'class-validator';

export class FileUploadResponseDto {
  @IsString()
  @IsNotEmpty()
  fileId: string;
}
</file>

<file path="ecs_fargate_app/backend/src/shared/interfaces/analysis.interface.ts">
export interface AnalysisResult {
  pillar: string;
  question: string;
  questionId: string;
  bestPractices: BestPractice[];
}

export interface BestPractice {
  id: string;
  name: string;
  applied: boolean;
  reasonApplied?: string;
  reasonNotApplied?: string;
  recommendations?: string;
}

export interface RiskSummary {
  pillarName: string;
  totalQuestions: number;
  answeredQuestions: number;
  highRisks: number;
  mediumRisks: number;
}

export interface WorkloadReview {
  workloadId: string;
  lensAlias: string;
  results: AnalysisResult[];
}
</file>

<file path="ecs_fargate_app/backend/src/shared/services/storage.service.ts">
import { Injectable } from '@nestjs/common';
import { S3 } from '@aws-sdk/client-s3';
import { ConfigService } from '@nestjs/config';
import { createHash } from 'crypto';
import * as fs from 'fs';

@Injectable()
export class StorageService {
    private readonly s3Client: S3;
    private readonly bucketName: string;

    constructor(private configService: ConfigService) {
        this.s3Client = new S3({
            region: this.configService.get('AWS_REGION'),
        });
        this.bucketName = this.configService.get('STORAGE_BUCKET_NAME');
    }

    async uploadFile(fileContent: string, fileName: string): Promise<string> {
        const fileId = this.generateFileId(fileName);
        const key = `uploads/${fileId}`;
        
        await this.s3Client.putObject({
            Bucket: this.bucketName,
            Key: key,
            Body: fileContent,
            Metadata: {
                uploadTime: new Date().toISOString()
            }
        });

        return fileId;
    }

    async getFileContent(fileId: string): Promise<string> {
        const key = `uploads/${fileId}`;
        
        const response = await this.s3Client.getObject({
            Bucket: this.bucketName,
            Key: key
        });

        return response.Body.transformToString();
    }

    async deleteExpiredFiles(): Promise<void> {
        const response = await this.s3Client.listObjects({
            Bucket: this.bucketName,
            Prefix: 'uploads/'
        });

        const now = new Date();
        const objects = response.Contents || [];

        for (const object of objects) {
            const metadata = await this.s3Client.headObject({
                Bucket: this.bucketName,
                Key: object.Key
            });

            const uploadTime = new Date(metadata.Metadata.uploadTime);
            const hoursSinceUpload = (now.getTime() - uploadTime.getTime()) / (1000 * 60 * 60);

            if (hoursSinceUpload >= 48) {
                await this.s3Client.deleteObject({
                    Bucket: this.bucketName,
                    Key: object.Key
                });
            }
        }
    }

    private generateFileId(fileName: string): string {
        const timestamp = new Date().getTime();
        const hash = createHash('md5')
            .update(`${fileName}_${timestamp}`)
            .digest('hex');
        return hash;
    }
}
</file>

<file path="ecs_fargate_app/backend/src/tasks/cleanup.task.ts">
import { Injectable } from '@nestjs/common';
import { Cron, CronExpression } from '@nestjs/schedule';
import { StorageService } from '../shared/services/storage.service';

@Injectable()
export class CleanupTask {
  constructor(private readonly storageService: StorageService) {}

  @Cron(CronExpression.EVERY_HOUR)
  async handleCleanup() {
    await this.storageService.deleteExpiredFiles();
  }
}
</file>

<file path="ecs_fargate_app/backend/src/app.module.ts">
import {Module} from '@nestjs/common';
import {ConfigModule} from '@nestjs/config';
import {ScheduleModule} from '@nestjs/schedule';
import {AnalyzerModule} from './modules/analyzer/analyzer.module';
import {WellArchitectedModule} from './modules/well-architected/well-architected.module';
import {ReportModule} from './modules/report/report.module';
import configuration from './config/configuration';
import {CleanupTask} from './tasks/cleanup.task';
import storageConfig from './config/storage.config';
import {StorageService} from "./shared/services/storage.service";

@Module({
    imports: [
        ConfigModule.forRoot({
            isGlobal: true,
            load: [configuration, storageConfig],
        }),
        AnalyzerModule,
        WellArchitectedModule,
        ReportModule,
        ScheduleModule.forRoot()
    ],
    providers: [CleanupTask],
})
export class AppModule {
}
</file>

<file path="ecs_fargate_app/backend/src/main.ts">
import { NestFactory } from '@nestjs/core';
import { ValidationPipe } from '@nestjs/common';
import { AppModule } from './app.module';
import * as bodyParser from 'body-parser';

async function bootstrap() {
  const app = await NestFactory.create(AppModule);

  // Increase payload size limit
  app.use(bodyParser.json({limit: '50mb'}));
  app.use(bodyParser.urlencoded({limit: '50mb', extended: true}));
  
  app.enableCors({
    origin: process.env.FRONTEND_URL || 'http://localhost:8080',
    methods: ['GET', 'POST', 'PUT', 'DELETE'],
    allowedHeaders: ['Content-Type', 'Authorization'],
  });

  app.useGlobalPipes(new ValidationPipe());
  
  await app.listen(3000);
}
bootstrap();
</file>

<file path="ecs_fargate_app/backend/nest-cli.json">
{
  "$schema": "https://json.schemastore.org/nest-cli",
  "collection": "@nestjs/schematics",
  "sourceRoot": "src",
  "compilerOptions": {
    "deleteOutDir": true
  }
}
</file>

<file path="ecs_fargate_app/backend/package.json">
{
  "name": "backend",
  "version": "0.0.1",
  "description": "",
  "author": "",
  "private": true,
  "license": "UNLICENSED",
  "engines": {
    "node": ">=22.0.0"
  },
  "scripts": {
    "build": "nest build",
    "format": "prettier --write \"src/**/*.ts\" \"test/**/*.ts\"",
    "start": "nest start",
    "start:dev": "nest start --watch",
    "start:debug": "nest start --debug --watch",
    "start:prod": "node dist/main",
    "lint": "eslint \"{src,apps,libs,test}/**/*.ts\" --fix",
    "build:finch": "finch build -f ../finch/backend.Dockerfile .",
    "start:finch": "finch run --rm -p 3000:3000 backend"
  },
  "dependencies": {
    "@aws-sdk/client-bedrock-agent-runtime": "^3.712.0",
    "@aws-sdk/client-bedrock-runtime": "^3.712.0",
    "@aws-sdk/client-s3": "^3.712.0",
    "@aws-sdk/client-wellarchitected": "^3.712.0",
    "@nestjs/common": "^10.4.15",
    "@nestjs/config": "^3.3.0",
    "@nestjs/core": "^10.0.0",
    "@nestjs/platform-express": "^10.0.0",
    "@nestjs/platform-socket.io": "^10.4.15",
    "@nestjs/schedule": "^5.0.0",
    "@nestjs/websockets": "^10.4.15",
    "class-transformer": "^0.5.1",
    "class-validator": "^0.14.1",
    "multer": "^1.4.5-lts.1",
    "reflect-metadata": "^0.2.0",
    "rxjs": "^7.8.1",
    "socket.io": "^4.8.1"
  },
  "devDependencies": {
    "@nestjs/cli": "^10.0.0",
    "@nestjs/schematics": "^10.0.0",
    "@types/express": "^5.0.0",
    "@types/multer": "^1.4.12",
    "@types/node": "^20.3.1",
    "@typescript-eslint/eslint-plugin": "^8.0.0",
    "@typescript-eslint/parser": "^8.0.0",
    "eslint": "^9.0.0",
    "eslint-config-prettier": "^9.0.0",
    "eslint-plugin-prettier": "^5.0.0",
    "prettier": "^3.0.0",
    "source-map-support": "^0.5.21",
    "ts-loader": "^9.4.3",
    "ts-node": "^10.9.1",
    "tsconfig-paths": "^4.2.0",
    "typescript": "^5.1.3"
  }
}
</file>

<file path="ecs_fargate_app/backend/tsconfig.build.json">
{
  "extends": "./tsconfig.json",
  "exclude": ["node_modules", "test", "dist", "**/*spec.ts"]
}
</file>

<file path="ecs_fargate_app/backend/tsconfig.json">
{
  "compilerOptions": {
    "module": "commonjs",
    "declaration": true,
    "removeComments": true,
    "emitDecoratorMetadata": true,
    "experimentalDecorators": true,
    "allowSyntheticDefaultImports": true,
    "target": "ES2021",
    "sourceMap": true,
    "outDir": "./dist",
    "baseUrl": "./",
    "incremental": true,
    "skipLibCheck": true,
    "strictNullChecks": false,
    "noImplicitAny": false,
    "strictBindCallApply": false,
    "forceConsistentCasingInFileNames": false,
    "noFallthroughCasesInSwitch": false
  }
}
</file>

<file path="ecs_fargate_app/finch/backend.dev.Dockerfile">
ARG PLATFORM="amd64"

FROM --platform=linux/${PLATFORM} node:22-alpine

WORKDIR /app

# Copy package files
COPY backend/package*.json ./

# Install dependencies including development dependencies
RUN --mount=type=cache,target=/root/.npm \
    npm ci

# Install nest CLI globally
RUN npm install -g @nestjs/cli

# Copy the rest of the application
COPY backend/ .

EXPOSE 3000

CMD ["npm", "run", "start:dev"]
</file>

<file path="ecs_fargate_app/finch/backend.Dockerfile">
ARG PLATFORM="amd64"

# Build stage
FROM --platform=linux/${PLATFORM} node:22-alpine as build

WORKDIR /app

# Copy package files
COPY backend/package*.json ./

# Install dependencies
RUN --mount=type=cache,target=/root/.npm \
    npm ci

# Copy the rest of the application
COPY backend/ .

# Build the application
RUN npm run build

# Production stage
FROM --platform=linux/${PLATFORM} node:22-alpine

WORKDIR /app

# Copy package files and install production dependencies
COPY backend/package*.json ./
RUN --mount=type=cache,target=/root/.npm \
    npm ci --only=production

# Copy built files
COPY --from=build /app/dist ./dist

EXPOSE 3000

CMD ["node", "dist/main"]
</file>

<file path="ecs_fargate_app/finch/frontend.dev.Dockerfile">
ARG PLATFORM="amd64"

FROM --platform=linux/${PLATFORM} node:22-alpine

WORKDIR /app

# Install dependencies
COPY frontend/package*.json ./
RUN --mount=type=cache,target=/root/.npm \
    npm ci

# Copy the rest of the application
COPY frontend/ .

# Only for local dev usage. Symbolic link from from /app/public to /app/public/public
# This allows files to be accessed both as /file.ext and /public/file.ext
RUN ln -s /app/public /app/public/public

EXPOSE 8080

# Just run the Vite dev server
CMD ["npm", "run", "dev"]
</file>

<file path="ecs_fargate_app/finch/frontend.Dockerfile">
ARG PLATFORM="amd64"

# Build stage
FROM --platform=linux/${PLATFORM} node:22-alpine as build

WORKDIR /app

# Copy package files
COPY frontend/package*.json ./

# Install dependencies
RUN --mount=type=cache,target=/root/.npm \
    npm ci

# Copy the rest of the application
COPY frontend/ .

# Build the application
RUN npm run build

# Production stage
FROM --platform=linux/${PLATFORM} nginx:alpine

# Copy built files
COPY --from=build /app/dist /usr/share/nginx/html

COPY --from=build /app/public /usr/share/nginx/html

# Copy nginx configuration
COPY finch/nginx.conf /etc/nginx/conf.d/default.conf

# Create directory for nginx pid file
RUN mkdir -p /run/nginx

EXPOSE 8080

CMD ["nginx", "-g", "daemon off;"]
</file>

<file path="ecs_fargate_app/finch/nginx.conf">
# AWS VPC DNS resolver
resolver 169.254.169.253 valid=10s;
server {
    listen 8080;
    root /usr/share/nginx/html;
    index index.html;

    # Increase timeouts
    proxy_connect_timeout 3600s;
    proxy_send_timeout 3600s;
    proxy_read_timeout 3600s;
    fastcgi_send_timeout 3600s;
    fastcgi_read_timeout 3600s;
    keepalive_timeout 3600s;

    # Frontend routes
    location / {
        try_files $uri $uri/ /index.html;
        add_header Cache-Control "no-cache, no-store, must-revalidate";
        add_header Pragma "no-cache";
        add_header Expires "0";
    }

    # WebSocket specific location
    location /socket.io/ {
        set $backend_internal backend.internal;
        proxy_pass http://$backend_internal:3000;
        
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        
        # WebSocket specific timeouts
        proxy_connect_timeout 7d;
        proxy_send_timeout 7d;
        proxy_read_timeout 7d;
    }

    # Regular API requests
    location ~ ^/api/(.*) {
        set $backend_internal backend.internal;
        proxy_pass http://$backend_internal:3000/$1;
        
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        proxy_connect_timeout 3600s;
        proxy_send_timeout 3600s;
        proxy_read_timeout 3600s;
    }

    # Basic health check endpoint
    location /health {
        return 200 'healthy';
    }
}
</file>

<file path="ecs_fargate_app/frontend/src/assets/react.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="35.93" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 228"><path fill="#00D8FF" d="M210.483 73.824a171.49 171.49 0 0 0-8.24-2.597c.465-1.9.893-3.777 1.273-5.621c6.238-30.281 2.16-54.676-11.769-62.708c-13.355-7.7-35.196.329-57.254 19.526a171.23 171.23 0 0 0-6.375 5.848a155.866 155.866 0 0 0-4.241-3.917C100.759 3.829 77.587-4.822 63.673 3.233C50.33 10.957 46.379 33.89 51.995 62.588a170.974 170.974 0 0 0 1.892 8.48c-3.28.932-6.445 1.924-9.474 2.98C17.309 83.498 0 98.307 0 113.668c0 15.865 18.582 31.778 46.812 41.427a145.52 145.52 0 0 0 6.921 2.165a167.467 167.467 0 0 0-2.01 9.138c-5.354 28.2-1.173 50.591 12.134 58.266c13.744 7.926 36.812-.22 59.273-19.855a145.567 145.567 0 0 0 5.342-4.923a168.064 168.064 0 0 0 6.92 6.314c21.758 18.722 43.246 26.282 56.54 18.586c13.731-7.949 18.194-32.003 12.4-61.268a145.016 145.016 0 0 0-1.535-6.842c1.62-.48 3.21-.974 4.76-1.488c29.348-9.723 48.443-25.443 48.443-41.52c0-15.417-17.868-30.326-45.517-39.844Zm-6.365 70.984c-1.4.463-2.836.91-4.3 1.345c-3.24-10.257-7.612-21.163-12.963-32.432c5.106-11 9.31-21.767 12.459-31.957c2.619.758 5.16 1.557 7.61 2.4c23.69 8.156 38.14 20.213 38.14 29.504c0 9.896-15.606 22.743-40.946 31.14Zm-10.514 20.834c2.562 12.94 2.927 24.64 1.23 33.787c-1.524 8.219-4.59 13.698-8.382 15.893c-8.067 4.67-25.32-1.4-43.927-17.412a156.726 156.726 0 0 1-6.437-5.87c7.214-7.889 14.423-17.06 21.459-27.246c12.376-1.098 24.068-2.894 34.671-5.345a134.17 134.17 0 0 1 1.386 6.193ZM87.276 214.515c-7.882 2.783-14.16 2.863-17.955.675c-8.075-4.657-11.432-22.636-6.853-46.752a156.923 156.923 0 0 1 1.869-8.499c10.486 2.32 22.093 3.988 34.498 4.994c7.084 9.967 14.501 19.128 21.976 27.15a134.668 134.668 0 0 1-4.877 4.492c-9.933 8.682-19.886 14.842-28.658 17.94ZM50.35 144.747c-12.483-4.267-22.792-9.812-29.858-15.863c-6.35-5.437-9.555-10.836-9.555-15.216c0-9.322 13.897-21.212 37.076-29.293c2.813-.98 5.757-1.905 8.812-2.773c3.204 10.42 7.406 21.315 12.477 32.332c-5.137 11.18-9.399 22.249-12.634 32.792a134.718 134.718 0 0 1-6.318-1.979Zm12.378-84.26c-4.811-24.587-1.616-43.134 6.425-47.789c8.564-4.958 27.502 2.111 47.463 19.835a144.318 144.318 0 0 1 3.841 3.545c-7.438 7.987-14.787 17.08-21.808 26.988c-12.04 1.116-23.565 2.908-34.161 5.309a160.342 160.342 0 0 1-1.76-7.887Zm110.427 27.268a347.8 347.8 0 0 0-7.785-12.803c8.168 1.033 15.994 2.404 23.343 4.08c-2.206 7.072-4.956 14.465-8.193 22.045a381.151 381.151 0 0 0-7.365-13.322Zm-45.032-43.861c5.044 5.465 10.096 11.566 15.065 18.186a322.04 322.04 0 0 0-30.257-.006c4.974-6.559 10.069-12.652 15.192-18.18ZM82.802 87.83a323.167 323.167 0 0 0-7.227 13.238c-3.184-7.553-5.909-14.98-8.134-22.152c7.304-1.634 15.093-2.97 23.209-3.984a321.524 321.524 0 0 0-7.848 12.897Zm8.081 65.352c-8.385-.936-16.291-2.203-23.593-3.793c2.26-7.3 5.045-14.885 8.298-22.6a321.187 321.187 0 0 0 7.257 13.246c2.594 4.48 5.28 8.868 8.038 13.147Zm37.542 31.03c-5.184-5.592-10.354-11.779-15.403-18.433c4.902.192 9.899.29 14.978.29c5.218 0 10.376-.117 15.453-.343c-4.985 6.774-10.018 12.97-15.028 18.486Zm52.198-57.817c3.422 7.8 6.306 15.345 8.596 22.52c-7.422 1.694-15.436 3.058-23.88 4.071a382.417 382.417 0 0 0 7.859-13.026a347.403 347.403 0 0 0 7.425-13.565Zm-16.898 8.101a358.557 358.557 0 0 1-12.281 19.815a329.4 329.4 0 0 1-23.444.823c-7.967 0-15.716-.248-23.178-.732a310.202 310.202 0 0 1-12.513-19.846h.001a307.41 307.41 0 0 1-10.923-20.627a310.278 310.278 0 0 1 10.89-20.637l-.001.001a307.318 307.318 0 0 1 12.413-19.761c7.613-.576 15.42-.876 23.31-.876H128c7.926 0 15.743.303 23.354.883a329.357 329.357 0 0 1 12.335 19.695a358.489 358.489 0 0 1 11.036 20.54a329.472 329.472 0 0 1-11 20.722Zm22.56-122.124c8.572 4.944 11.906 24.881 6.52 51.026c-.344 1.668-.73 3.367-1.15 5.09c-10.622-2.452-22.155-4.275-34.23-5.408c-7.034-10.017-14.323-19.124-21.64-27.008a160.789 160.789 0 0 1 5.888-5.4c18.9-16.447 36.564-22.941 44.612-18.3ZM128 90.808c12.625 0 22.86 10.235 22.86 22.86s-10.235 22.86-22.86 22.86s-22.86-10.235-22.86-22.86s10.235-22.86 22.86-22.86Z"></path></svg>
</file>

<file path="ecs_fargate_app/frontend/src/components/utils/table-configs/analysis-table-config.ts">
export const tableFilteringProperties = [
    {
      propertyLabel: 'Pillar',
      key: 'pillar',
      groupValuesLabel: 'Pillar values',
      operators: [':', '!:', '=', '!=', '^'],
    },
    {
      propertyLabel: 'Question',
      key: 'question',
      groupValuesLabel: 'Question values',
      operators: [':', '!:', '=', '!=', '^'],
    },
    {
      propertyLabel: 'Best Practice',
      key: 'name',
      groupValuesLabel: 'Best Practice values',
      operators: [':', '!:', '=', '!=', '^'],
    },
    {
      propertyLabel: 'Is Best Practice Applied?',
      key: 'applied',
      groupValuesLabel: 'Status values',
      operators: ['=', '!='],
    },
  ];
  
  export const paginationLabels = {
    nextPageLabel: 'Next page',
    previousPageLabel: 'Previous page',
    pageLabel: (pageNumber: number) => `Page ${pageNumber} of all pages`,
  };
  
  export const getMatchesCountText = (count: number) => {
    return count === 1 ? '1 match' : `${count} matches`;
  };
  
  export const propertyFilterI18nStrings = {
    filteringAriaLabel: "Filter best practices",
    filteringPlaceholder: "Filter best practices",
    clearFiltersText: "Clear filters",
    cancelActionText: "Cancel",
    applyActionText: "Apply",
    operationAndText: "and",
    operationOrText: "or",
    operatorContainsText: "Contains",
    operatorDoesNotContainText: "Does not contain",
    operatorEqualsText: "Equals",
    operatorDoesNotEqualText: "Does not equal",
    operatorStartsWithText: "Starts with",
  };
</file>

<file path="ecs_fargate_app/frontend/src/components/utils/CopyButton.tsx">
/**
 * IMPORTANT NOTE: 
 * This component implements a fallback mechanism for clipboard operations because
 * this application supports local development and deployment scenarios where HTTPS
 * is not available. The modern Clipboard API requires a secure context (HTTPS),
 * so we provide a fallback using the legacy document.execCommand('copy') method
 * when running in non-secure contexts (HTTP).
 * 
 * If you're always deploying to HTTPS environments, you might want to use the
 * native Clipboard API directly or consider using Cloudscape's CopyToClipboard
 * component instead.
 * 
 * Technical Context:
 * - In secure contexts (HTTPS): Uses navigator.clipboard.writeText()
 * - In non-secure contexts (HTTP): Falls back to document.execCommand('copy')
 * 
 * @see https://developer.mozilla.org/en-US/docs/Web/API/Clipboard/writeText
 * @see https://developer.mozilla.org/en-US/docs/Web/API/Document/execCommand
 */

import { FC, useState } from 'react';
import { Button, Popover, StatusIndicator } from '@cloudscape-design/components';

interface CopyButtonProps {
  content: string;
}

const CopyButton: FC<CopyButtonProps> = ({ content }) => {
  const [copyStatus, setCopyStatus] = useState<'success' | 'error'>('success');

  const handleCopy = async () => {
    try {
      // Try modern clipboard API first
      if (window.isSecureContext && navigator.clipboard) {
        await navigator.clipboard.writeText(content);
      } else {
        // Fallback to execCommand
        const textarea = document.createElement('textarea');
        textarea.value = content;
        textarea.style.position = 'absolute';
        textarea.style.opacity = '0';
        document.body.appendChild(textarea);
        textarea.select();
        
        const successful = document.execCommand('copy');
        document.body.removeChild(textarea);
        
        if (!successful) throw new Error('Copy failed');
      }

      // Show success popover
      setCopyStatus('success');
    } catch (err) {
      // Show error popover
      setCopyStatus('error');
    }
  };

  return (
    <Popover
      dismissButton={false}
      position="top"
      size="small"
      triggerType="custom"
      content={
        <StatusIndicator type={copyStatus}>
          {copyStatus === 'success' ? 'Content copied' : 'Failed to copy'}
        </StatusIndicator>
      }
    >
      <Button
        iconName="copy"
        onClick={handleCopy}
        ariaLabel="Copy content"
      >
        Copy
      </Button>
    </Popover>
  );
};

export default CopyButton;
</file>

<file path="ecs_fargate_app/frontend/src/components/utils/help-content.tsx">
import { Box, Link, SpaceBetween, Button } from '@cloudscape-design/components';

export const helpContent = {
    default: {
        header: 'About Well-Architected IaC Analyzer',
        body: (
            <SpaceBetween size="xxs">
                <Box variant="p">
                    This tool helps you evaluate your infrastructure designs against AWS Well-Architected Framework best practices.
                </Box>

                <Box variant="h4">Key Features</Box>
                <ul>
                    <li><strong>IaC Analysis:</strong> Upload CloudFormation (YAML/JSON) or Terraform templates for automated analysis</li>
                    <li><strong>Architecture Review:</strong> Upload architecture diagrams (PNG/JPG) and get IaC recommendations</li>
                    <li><strong>Well-Architected Integration:</strong> Directly update your AWS Well-Architected Tool workload</li>
                    <li><strong>AI-Powered Analysis:</strong> Get detailed recommendations using AWS Bedrock</li>
                </ul>
                <Box variant="h4">How to Use</Box>
                <ol>
                    <li>Upload your IaC template or architecture diagram</li>
                    <li>Select the Well-Architected pillars to review</li>
                    <li>Optionally provide a Well-Architected Tool workload ID</li>
                    <li>Review the analysis results and recommendations</li>
                    <li>Update your Well-Architected Tool workload or generate IaC templates</li>
                </ol>

                <Box variant="h4">Need Help?</Box>
                <Box variant="p">
                    Look for the help icons (<Button variant="inline-icon" iconName="support" />) throughout the application for detailed information about specific features.
                </Box>

                <Box variant="h4">Additional Resources</Box>
                <SpaceBetween size="xs">
                    <Link external href="https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html">
                        AWS Well-Architected Framework Documentation
                    </Link>
                    <Link external href="https://docs.aws.amazon.com/wellarchitected/latest/userguide/getting-started.html">
                        Getting Started with AWS Well-Architected Tool
                    </Link>
                </SpaceBetween>
            </SpaceBetween>
        )
    },
    fileUpload: {
        header: 'File Upload',
        body: (
            <SpaceBetween size="xxs">
                <Box variant="p">
                    Upload your Infrastructure as Code (IaC) template or architecture diagram for analysis:
                </Box>
                <ul>
                    <li>Supported IaC formats: YAML, JSON (CloudFormation), and Terraform (.tf)</li>
                    <li>Supported image formats: PNG, JPG, JPEG</li>
                    <li>Maximum file size: 50MB</li>
                </ul>
                <Box variant="p">
                    When uploading an architecture diagram, you can later generate IaC templates based on the analysis.
                </Box>
            </SpaceBetween>
        )
    },
    pillarSelection: {
        header: 'Well-Architected Pillars',
        body: (
            <SpaceBetween size="xxs">
                <Box variant="p">
                    Select which Well-Architected Framework pillars to include in your analysis:
                </Box>
                <ul>
                    <li>Operational Excellence: Operations as code, observability, etc.</li>
                    <li>Security: Identity management, data protection, incident response</li>
                    <li>Reliability: Recovery planning, adapting to changes, etc.</li>
                    <li>Performance Efficiency: Resource optimization, monitoring</li>
                    <li>Cost Optimization: Cost-effective resources, expenditure awareness</li>
                    <li>Sustainability: Environmental impact reduction strategies</li>
                </ul>
                <Link external href="https://docs.aws.amazon.com/wellarchitected/latest/framework/the-pillars-of-the-framework.html">
                    Learn more about Well-Architected pillars
                </Link>
            </SpaceBetween>
        )
    },
    analysisResults: {
        header: 'Analysis Results',
        body: (
            <SpaceBetween size="xxs">
                <Box variant="p">
                    Review the analysis of your infrastructure against Well-Architected best practices:
                </Box>
                <ul>
                    <li>View applied and not applied best practices. Use the table filters and preferences to customize your view.</li>
                    <li><strong>Get More Details:</strong> Get in-depth analysis and recommendations for selected best practices</li>
                    <li><strong>Generate IaC Document:</strong> Convert architecture diagrams into infrastructure code (Available only for image uploads)</li>
                    <li><strong>Download Analysis:</strong> Export all findings and recommendations as a CSV file</li>
                </ul>
            </SpaceBetween>
        )
    },
    wellArchitectedTool: {
        header: 'Well-Architected Tool Integration',
        body: (
            <SpaceBetween size="xxs">
                <Box variant="p">
                    Track and manage your workload's alignment with AWS Well-Architected Framework:
                </Box>
                <ul>
                    <li>View risk summary across all pillars</li>
                    <li>Track high and medium risks</li>
                    <li>Generate Well-Architected Tool reports</li>
                </ul>

                <Box variant="h4">
                    Important: Workload Management
                </Box>
                <ul>
                    <li><strong>Complete Well-Architected Tool Review:</strong>
                        <ul>
                            <li>If you provided an existing Workload ID in Optional Settings: Updates will be made to that workload</li>
                            <li>If no Workload ID was provided: A new workload will be created automatically</li>
                        </ul>
                    </li>
                    <li><strong>Delete Well-Architected Tool Workload:</strong>
                        <ul>
                            <li>Only available for workloads created by this tool</li>
                            <li>Not available for existing workloads (where you provided the Workload ID)</li>
                            <li>Use this to clean up temporary workloads created during your analysis</li>
                        </ul>
                    </li>
                </ul>

                <Box variant="p">
                    <strong>Note:</strong> For security reasons, this tool cannot delete Well-Architected workloads that were not created by it.
                    If you provided your own Workload ID, you'll need to manage that workload directly in the AWS Console.
                </Box>

                <Link external href="https://docs.aws.amazon.com/wellarchitected/latest/userguide/workloads.html">
                    Learn more about managing Well-Architected workloads
                </Link>
            </SpaceBetween>
        )
    },
    iacDocument: {
        header: 'IaC Document',
        body: (
            <SpaceBetween size="xxs">
                <Box variant="p">
                    View and manage generated Infrastructure as Code documents:
                </Box>
                <ul>
                    <li>Review generated IaC templates</li>
                    <li>Copy content to clipboard</li>
                    <li>Download as file</li>
                </ul>
                <Box variant="p">
                    Templates are generated following AWS best practices and Well-Architected recommendations.
                </Box>
            </SpaceBetween>
        )
    },
    workloadId: {
        header: 'Well-Architected Workload ID',
        body: (
            <SpaceBetween size="xxs">
                <Box variant="p">
                    The Workload ID connects your analysis with AWS Well-Architected Tool:
                </Box>
                <ul>
                    <li>Optional: Leave empty to create a new workload</li>
                    <li>Enter existing ID to update an existing workload</li>
                    <li>Found in AWS Well-Architected Tool console</li>
                </ul>
                <Link external href="https://docs.aws.amazon.com/wellarchitected/latest/userguide/define-workload.html">
                    Learn more about Well-Architected workloads
                </Link>
            </SpaceBetween>
        )
    },
    iacTypeSelection: {
        header: 'IaC Template Type Selection',
        body: (
            <SpaceBetween size="xxs">
                <Box variant="p">
                    Choose the type of Infrastructure as Code template to generate:
                </Box>
                <ul>
                    <li><strong>CloudFormation YAML:</strong> Generate AWS CloudFormation template in YAML format</li>
                    <li><strong>CloudFormation JSON:</strong> Generate AWS CloudFormation template in JSON format</li>
                    <li><strong>Terraform:</strong> Generate HashiCorp Terraform configuration files</li>
                </ul>
                <Box variant="p">
                    This option is only available when analyzing architecture diagrams.
                </Box>
            </SpaceBetween>
        )
    }
};
</file>

<file path="ecs_fargate_app/frontend/src/components/utils/HelpButton.tsx">
import React from 'react';
import { Button } from '@cloudscape-design/components';
import { useHelpPanel } from '../../contexts/HelpPanelContext';
import { helpContent } from './help-content';

interface HelpButtonProps {
  contentId: keyof typeof helpContent;
}

export const HelpButton: React.FC<HelpButtonProps> = ({ contentId }) => {
  const { setHelpContent } = useHelpPanel();
  const content = helpContent[contentId];

  return (
    <Button
      variant="inline-icon"
      iconName="support"
      onClick={() => setHelpContent(content.header, content.body)}
      ariaLabel={`Help for ${content.header}`}
    />
  );
};
</file>

<file path="ecs_fargate_app/frontend/src/components/AnalysisResults.tsx">
import React, { useState } from 'react';
import {
  Table,
  Box,
  StatusIndicator,
  Link,
  PropertyFilter,
  Pagination,
  CollectionPreferences,
  Button,
  Header,
  Container,
  KeyValuePairs,
  SpaceBetween,
} from '@cloudscape-design/components';
import { HelpButton } from './utils/HelpButton';
import { useCollection } from '@cloudscape-design/collection-hooks';
import { AnalysisResult, BestPractice, IaCTemplateType } from '../types';
import { DetailsModal } from './DetailsModal';
import { analyzerApi } from '../services/api';
import {
  tableFilteringProperties,
  paginationLabels,
  getMatchesCountText,
  propertyFilterI18nStrings,
} from './utils/table-configs/analysis-table-config';

interface AnalysisResultsProps {
  results: AnalysisResult[];
  isAnalyzing: boolean;
  onDownloadRecommendations: () => void;
  onGenerateIacDocument: () => void;
  isDownloading: boolean;
  isImplementing: boolean;
  uploadedFileID: string;
  isLoadingDetails: boolean;
  setIsLoadingDetails: (loading: boolean) => void;
  uploadedFileType: string;
  selectedIaCType: IaCTemplateType;
  setError: (error: string | null) => void;
}

interface EnhancedBestPractice extends BestPractice {
  pillar: string;
  question: string;
  questionId: string;
}

interface PreferencesType {
  pageSize: number;
  visibleContent: readonly string[];
}

export const AnalysisResults: React.FC<AnalysisResultsProps> = ({ results, isAnalyzing, onDownloadRecommendations, onGenerateIacDocument, isDownloading, isImplementing, uploadedFileID, isLoadingDetails, setIsLoadingDetails, uploadedFileType, selectedIaCType, setError }) => {
  const [preferences, setPreferences] = useState<PreferencesType>({
    pageSize: 10,
    visibleContent: ['pillar', 'question', 'name', 'status', 'reason', 'recommendations'],
  });
  const [selectedItems, setSelectedItems] = useState<any[]>([]);
  const [detailsModalVisible, setDetailsModalVisible] = useState(false);
  const [detailsContent, setDetailsContent] = useState('');
  const [detailsError, setDetailsError] = useState<string | null>(null);

  const handleGetMoreDetails = async () => {
    try {
      setIsLoadingDetails(true);
      setDetailsError(null);

      const result = await analyzerApi.getMoreDetails(
        selectedItems,
        uploadedFileID,
        uploadedFileType,
        selectedIaCType
      );

      if (result.error) {
        setDetailsError(result.error);
      }

      if (result.content) {
        setDetailsContent(result.content);
        setDetailsModalVisible(true);
      } else {
        setError('No content received from analysis');
      }
    } catch (error) {
        console.error('Failed to get more details:', error); // clp
        setError(error instanceof Error ? error.message : 'Failed to get detailed analysis');
    } finally {
        setIsLoadingDetails(false);
    }
  };

  const getBestPracticeCounts = (practices: EnhancedBestPractice[]) => {
    return practices.reduce(
      (acc, practice) => ({
        applied: acc.applied + (practice.applied ? 1 : 0),
        notApplied: acc.notApplied + (practice.applied ? 0 : 1),
      }),
      { applied: 0, notApplied: 0 }
    );
  };

  // Transform the nested structure into a flat array
  const flattenedBestPractices: EnhancedBestPractice[] = results.flatMap(result =>
    result.bestPractices.map(bp => ({
      ...bp,
      pillar: result.pillar,
      question: result.question,
      questionId: result.questionId,
    }))
  );

  const { applied, notApplied } = getBestPracticeCounts(flattenedBestPractices);

  const { items, actions, filteredItemsCount, collectionProps, propertyFilterProps, paginationProps } = useCollection(
    flattenedBestPractices,
    {
      propertyFiltering: {
        filteringProperties: tableFilteringProperties,
        empty: (
          <Box textAlign="center" color="inherit">
            <b>No best practices found</b>
          </Box>
        ),
        noMatch: (
          <Box textAlign="center" color="inherit">
            <b>No matches</b>
            <Box color="inherit" padding={{ top: 's' }}>
              <Button onClick={() => actions.setPropertyFiltering({ tokens: [], operation: 'and' })}>
                Clear filter
              </Button>
            </Box>
          </Box>
        ),
      },
      pagination: { pageSize: preferences.pageSize },
      sorting: { defaultState: { sortingColumn: { sortingField: 'pillar' } } },
    }
  );

  const handleCancelGeneration = async () => {
    try {
      await analyzerApi.cancelIaCGeneration();
    } catch (error) {
      console.error('Failed to cancel IaC generation:', error);
    }
  };

  return (
    <div>
      <Container
        variant="stacked"
      >
        <KeyValuePairs
          columns={2}
          items={[
            {
              label: "Best Practices Applied",
              value: isAnalyzing ?
                <StatusIndicator type="loading">Loading</StatusIndicator> :
                <StatusIndicator>{applied}</StatusIndicator>
            },
            {
              label: "Best Practices Not Applied",
              value: isAnalyzing ?
                <StatusIndicator type="loading">Loading</StatusIndicator> :
                <StatusIndicator type="error">{notApplied}</StatusIndicator>
            }
          ]}
        />
      </Container>
      <Table
        {...collectionProps}
        variant="stacked"
        header={
          <Header
            variant="h3"
            actions={
              <SpaceBetween direction="horizontal" size="xs">
                <Button
                  onClick={handleGetMoreDetails}
                  loading={isLoadingDetails}
                  disabled={selectedItems.length === 0 || isLoadingDetails}
                  iconName="gen-ai"
                >
                  Get More Details
                </Button>
                <Button
                  onClick={onGenerateIacDocument}
                  loading={isImplementing}
                  disabled={isDownloading || isImplementing || !uploadedFileType.startsWith('image/')}
                  iconName="gen-ai"
                >
                  Generate IaC Document
                </Button>
                {isImplementing && (
                  <Button
                    onClick={handleCancelGeneration}
                    iconName="close"
                  >
                    Cancel IaC Generation
                  </Button>
                )}
                <Button
                  onClick={onDownloadRecommendations}
                  loading={isDownloading}
                  disabled={isDownloading || isImplementing}
                  iconName="download"
                >
                  Download Analysis
                </Button>
              </SpaceBetween>
            }
            info={<HelpButton contentId="analysisResults" />}
          >
            Analysis Results
          </Header>
        }
        columnDefinitions={[
          {
            id: 'pillar',
            header: 'Pillar',
            cell: item => item.pillar,
            sortingField: 'pillar',
          },
          {
            id: 'question',
            header: 'Question',
            cell: item => item.question,
            sortingField: 'question',
          },
          {
            id: 'name',
            header: 'Best Practice',
            cell: item => (
              <Link external href={`https://docs.aws.amazon.com/wellarchitected/latest/framework/${item.id}.html`}>
                {item.name}
              </Link>
            ),
            sortingField: 'name',
            minWidth: 200,
          },
          {
            id: 'status',
            header: 'Status',
            cell: item => (
              <StatusIndicator type={item.applied ? 'success' : 'error'}>
                {item.applied ? 'Applied' : 'Not Applied'}
              </StatusIndicator>
            ),
            sortingField: 'applied',
            minWidth: 140,
          },
          {
            id: 'reason',
            header: 'Reason',
            cell: item => item.applied ? item.reasonApplied : item.reasonNotApplied,
            minWidth: 200,
          },
          {
            id: 'recommendations',
            header: 'Recommendations',
            cell: item => !item.applied && item.recommendations || 'N/A',
            minWidth: 500,
          },
        ]}
        items={items}
        loadingText="Analyzing uploaded file..."
        loading={isAnalyzing}
        columnDisplay={preferences.visibleContent.map(id => ({ id, visible: true }))}
        wrapLines
        stickyHeader
        selectionType="multi"
        selectedItems={selectedItems}
        onSelectionChange={({ detail }) =>
          setSelectedItems(detail.selectedItems)
        }
        ariaLabels={{
          allItemsSelectionLabel: ({ selectedItems }) =>
            `${selectedItems.length} ${selectedItems.length === 1 ? "item" : "items"
            } selected`,
          itemSelectionLabel: ({ selectedItems }, item) => {
            const isItemSelected = selectedItems.filter(i => i.id === item.id).length > 0;
            return `"${item.name}" is ${isItemSelected ? "" : "not "}selected`;
          }
        }}
        trackBy='name'
        filter={
          <PropertyFilter
            {...propertyFilterProps}
            i18nStrings={propertyFilterI18nStrings}
            countText={getMatchesCountText(filteredItemsCount || 0)}
            expandToViewport
          />
        }
        pagination={<Pagination {...paginationProps} ariaLabels={paginationLabels} />}
        preferences={
          <CollectionPreferences
            title="Preferences"
            confirmLabel="Confirm"
            cancelLabel="Cancel"
            preferences={preferences}
            onConfirm={({ detail }) => setPreferences({
              pageSize: detail.pageSize || 10,
              visibleContent: detail.visibleContent || [],
            })}
            pageSizePreference={{
              title: 'Page size',
              options: [
                { value: 10, label: '10 best practices' },
                { value: 25, label: '25 best practices' },
                { value: 50, label: '50 best practices' },
                { value: 100, label: '100 best practices' },
              ],
            }}
          />
        }
      />
      <DetailsModal
        visible={detailsModalVisible}
        onDismiss={() => setDetailsModalVisible(false)}
        content={detailsContent}
        error={detailsError || undefined}
      />
    </div>
  );
};
</file>

<file path="ecs_fargate_app/frontend/src/components/DetailsModal.tsx">
import React from 'react';
import ReactMarkdown from 'react-markdown';
import {
    Modal,
    Box,
    SpaceBetween,
    Button,
    Alert
} from '@cloudscape-design/components';
import CopyButton from './utils/CopyButton';

interface DetailsModalProps {
    visible: boolean;
    onDismiss: () => void;
    content: string;
    error?: string | undefined;
}

export const DetailsModal: React.FC<DetailsModalProps> = ({
    visible,
    onDismiss,
    content,
    error
}) => {
    const handleDownload = () => {
        const now = new Date();
        const timestamp = now.toLocaleString('en-AU', {
            year: 'numeric',
            month: '2-digit',
            day: '2-digit',
            hour: '2-digit',
            minute: '2-digit',
            second: '2-digit',
            hour12: false,
            timeZone: 'UTC'
        }).replace(/[/,:]/g, '').replace(/\s/g, '_');

        const newFileName = `WA_Details_${timestamp}_UTC.md`;
        const blob = new Blob([content], { type: 'text/markdown' });
        const url = window.URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = newFileName;
        document.body.appendChild(a);
        a.click();
        window.URL.revokeObjectURL(url);
        document.body.removeChild(a);
    };

    return (
        <Modal
            visible={visible}
            onDismiss={onDismiss}
            header="Detailed Analysis"
            size="large"
            footer={
                <Box float="right">
                    <SpaceBetween direction="horizontal" size="xs">
                        <CopyButton content={content} />
                        <Button onClick={handleDownload}>
                            Download
                        </Button>
                        <Button variant="primary" onClick={onDismiss}>
                            Close
                        </Button>
                    </SpaceBetween>
                </Box>
            }
        >
            <Box padding="s">
                {error && (
                    <Alert
                        type="warning"
                        dismissible
                        header="Partial Results"
                    >
                        {error}
                    </Alert>
                )}
                <ReactMarkdown>{content}</ReactMarkdown>
            </Box>
        </Modal>
    );
};
</file>

<file path="ecs_fargate_app/frontend/src/components/DocumentView.tsx">
import React from 'react';
import {
    Container,
    SpaceBetween,
    Button,
    Header
} from '@cloudscape-design/components';
import { HelpButton } from './utils/HelpButton';
import CodeView from "@cloudscape-design/code-view/code-view";
import jsonHighlight from "@cloudscape-design/code-view/highlight/json";
import yamlHighlight from "@cloudscape-design/code-view/highlight/yaml";
import { IaCTemplateType } from '../types';
import CopyButton from './utils/CopyButton';

interface DocumentViewProps {
    content: string;
    fileName: string;
    selectedIaCType: IaCTemplateType;
}

export const DocumentView: React.FC<DocumentViewProps> = ({
    content,
    fileName,
    selectedIaCType,
}) => {
    const getTemplateType = (): string => {
        const match = selectedIaCType.match(/\(([^\)]+)\)/);
        return match ? match[1] : 'txt';
    }

    const handleDownload = () => {
        const now = new Date();
        const timestamp = now.toLocaleString('en-AU', {
            year: 'numeric',
            month: '2-digit',
            day: '2-digit',
            hour: '2-digit',
            minute: '2-digit',
            second: '2-digit',
            hour12: false,
            timeZone: 'UTC'
        }).replace(/[/,:]/g, '').replace(/\s/g, '_');

        const newFileName = `IaCAnalyzer_${timestamp}_UTC_${fileName.replace(/\./g, '_')}${getTemplateType()}`;
        const blob = new Blob([content], { type: 'text/plain' });
        const url = window.URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = newFileName;
        document.body.appendChild(a);
        a.click();
        window.URL.revokeObjectURL(url);
        document.body.removeChild(a);
    };

    return (
        <Container
            header={
                <Header
                    variant="h2"
                    actions={
                        <SpaceBetween
                            direction="horizontal"
                            size="xs"
                        >
                            <CopyButton content={content} />
                            <Button
                                iconName="download"
                                onClick={handleDownload}
                                ariaLabel="Download content"
                            >
                                Download
                            </Button>
                        </SpaceBetween>
                    }
                    info={<HelpButton contentId="iacDocument" />}
                >
                    Generated IaC Document
                </Header>
            }
        >
            <SpaceBetween size="s">
                <CodeView
                    content={content}
                    highlight={
                        getTemplateType() === '.yaml' ? yamlHighlight : jsonHighlight
                    }
                    lineNumbers
                    wrapLines
                />
            </SpaceBetween>
        </Container>
    );
};
</file>

<file path="ecs_fargate_app/frontend/src/components/FileUpload.tsx">
import React, { useState } from 'react';
import {
  FormField,
  Header,
  SpaceBetween,
  Alert,
  StatusIndicator,
  FileUpload as CloudscapeFileUpload
} from '@cloudscape-design/components';
import { UploadedFile } from '../types';
import { HelpButton } from './utils/HelpButton';
import  { analyzerApi } from '../services/api';

interface FileUploadProps {
  onFileUploaded: (file: UploadedFile) => void;
  acceptedFileTypes: string[];
}

export const FileUpload: React.FC<FileUploadProps> = ({
  onFileUploaded,
  acceptedFileTypes,
}) => {
  const [value, setValue] = useState<File[]>([]);
  const [error, setError] = useState<string | null>(null);
  const [uploadStatus, setUploadStatus] = useState<'initial' | 'success' | 'error'>('initial');

  const handleFileChange = async (files: File[]) => {
    setValue(files);
    setError(null);

    if (!files.length) {
      return;
    }

    try {
      const file = files[0];
      
      // Upload the file to get a fileId
      const fileId = await analyzerApi.uploadFile(file);

      const uploadedFile: UploadedFile = {
        name: file.name,
        id: fileId, // Now using fileId instead of file content
        type: file.type,
        size: file.size,
      };

      onFileUploaded(uploadedFile);
      setUploadStatus('success');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to process file');
      setUploadStatus('error');
    }
  };

  return (
    <SpaceBetween size="l">
      <FormField
        label={
          <>
            <Header variant="h3">
              1. Upload your IaC document or architecture diagram image <HelpButton contentId="fileUpload" />
            </Header>
          </>
        }
        errorText={error}
      >
        <SpaceBetween size="s">
          <CloudscapeFileUpload
            onChange={({ detail }) => handleFileChange(detail.value)}
            value={value}
            constraintText={`Supported file types ${acceptedFileTypes.join(' or ')}`}
            accept={acceptedFileTypes.join(',')}
            i18nStrings={{
              uploadButtonText: () => 'Choose file',
              dropzoneText: () => 'Drop file to upload',
            }}
            showFileLastModified
            showFileSize
            tokenLimit={1}
            multiple={false}
          />
          {uploadStatus === 'success' && (
            <StatusIndicator type="success">
              File uploaded successfully
            </StatusIndicator>
          )}
        </SpaceBetween>
      </FormField>

      {error && (
        <Alert type="error" header="Error uploading file">
          {error}
        </Alert>
      )}
    </SpaceBetween>
  );
};
</file>

<file path="ecs_fargate_app/frontend/src/components/IaCTemplateSelector.tsx">
import React from 'react';
import { Select, FormField } from '@cloudscape-design/components';
import { HelpButton } from './utils/HelpButton';
import { IaCTemplateType } from '../types';

interface IaCTemplateSelectorProps {
  value: IaCTemplateType;
  onChange: (value: IaCTemplateType) => void;
  disabled?: boolean;
}

export const IaCTemplateSelector: React.FC<IaCTemplateSelectorProps> = ({
  value,
  onChange,
  disabled = false,
}) => {
  return (
    <FormField
      label={
        <>
          IaC Template Type <HelpButton contentId="iacTypeSelection" />
        </>
      }
      description="Select the type of IaC template to generate from the architectural diagrams uploaded"
    >
      <Select
        selectedOption={{ label: value, value: value }}
        onChange={({ detail }) =>
          onChange(detail.selectedOption.value as IaCTemplateType)
        }
        options={Object.values(IaCTemplateType).map(type => ({
          label: type,
          value: type,
        }))}
        disabled={disabled}
      />
    </FormField>
  );
};
</file>

<file path="ecs_fargate_app/frontend/src/components/PillarSelector.tsx">
import React, { useCallback, useMemo } from 'react';
import { NonCancelableCustomEvent, Multiselect, FormField, Header } from '@cloudscape-design/components';
import type { MultiselectProps } from '@cloudscape-design/components';
import { HelpButton } from './utils/HelpButton';
import { WellArchitectedPillar } from '../types';

interface PillarSelectorProps {
  pillars: WellArchitectedPillar[];
  selectedPillars: string[];
  onChange: (selectedPillarIds: string[]) => void;
  disabled?: boolean;
}

export const PillarSelector: React.FC<PillarSelectorProps> = ({
  pillars,
  selectedPillars,
  onChange,
  disabled = false,
}) => {
  // Memoize options to prevent unnecessary recalculations
  const options = useMemo(
    () => pillars.map(pillar => ({
      label: pillar.name,
      value: pillar.id,
    })),
    [pillars]
  );

  // Memoize selected options to prevent unnecessary recalculations
  const selectedOptions = useMemo(
    () => pillars
      .filter(pillar => selectedPillars.includes(pillar.id))
      .map(pillar => ({
        label: pillar.name,
        value: pillar.id,
      })),
    [pillars, selectedPillars]
  );

  // Memoize onChange handler
  const handleChange = useCallback(
    (event: NonCancelableCustomEvent<MultiselectProps.MultiselectChangeDetail>) => {
      const selectedValues = event.detail.selectedOptions
        .map(option => option.value)
        .filter((value): value is string => value !== undefined);
      onChange(selectedValues);
    },
    [onChange]
  );

  return (
    <FormField
      label={
        <>
          <Header variant="h3">
            2. Select the Well-Architected Pillars to review <HelpButton contentId="pillarSelection" />
          </Header>
        </>
      }
    >
      <Multiselect
        selectedOptions={selectedOptions}
        onChange={handleChange}
        options={options}
        placeholder="Select Well-Architected Pillars"
        selectedAriaLabel="Selected"
        disabled={disabled}
      />
    </FormField>
  );
};
</file>

<file path="ecs_fargate_app/frontend/src/components/RiskSummary.tsx">
import React from 'react';
import {
  Container,
  StatusIndicator,
  Table,
  Button,
  SpaceBetween,
  Header,
  KeyValuePairs,
  ButtonDropdown,
} from '@cloudscape-design/components';
import { HelpButton } from './utils/HelpButton';
import { RiskSummary as RiskSummaryType, RiskSummaryProps } from '../types';

export const RiskSummary: React.FC<RiskSummaryProps> = ({
  summary,
  onUpdate,
  onGenerateReport,
  onDeleteWorkload,
  onRefresh,
  isUpdating,
  isRefreshing,
  isGeneratingReport,
  isDeleting,
  canDeleteWorkload,
  hasProvidedWorkloadId
}) => {
  const totalHighRisks = summary?.reduce((acc, s) => acc + s.highRisks, 0) ?? 0;
  const totalMediumRisks = summary?.reduce((acc, s) => acc + s.mediumRisks, 0) ?? 0;
  const totalQuestions = summary?.reduce((acc, s) => acc + s.totalQuestions, 0) ?? 0;
  const totalAnswered = summary?.reduce((acc, s) => acc + s.answeredQuestions, 0) ?? 0;

  const dropdownItems = [
    {
      id: 'generate-report',
      text: 'Generate Well-Architected Tool Report',
      disabled: !summary || isUpdating || isGeneratingReport
    },
    {
      id: 'delete-workload',
      text: 'Delete Well-Architected Tool Workload',
      disabled: !canDeleteWorkload || hasProvidedWorkloadId || isDeleting
    }
  ];

  const handleDropdownAction = ({ detail: { id } }: { detail: { id: string } }) => {
    switch (id) {
      case 'generate-report':
        onGenerateReport();
        break;
      case 'delete-workload':
        onDeleteWorkload();
        break;
    }
  };

  return (
    <div>
      <Container
        variant="stacked"
      >
        <KeyValuePairs
          columns={3}
          items={[
            {
              label: "Questions Answered",
              value: isRefreshing || isUpdating ?
                <StatusIndicator type="loading">Loading</StatusIndicator> :
                <StatusIndicator type="info">{totalAnswered}/{totalQuestions}</StatusIndicator>
            },
            {
              label: "High Risks",
              value: isRefreshing || isUpdating ?
                <StatusIndicator type="loading">Loading</StatusIndicator> :
                <StatusIndicator type="error">{totalHighRisks}</StatusIndicator>
            },
            {
              label: "Medium Risks",
              value: isRefreshing || isUpdating ?
                <StatusIndicator type="loading">Loading</StatusIndicator> :
                <StatusIndicator type="warning">{totalMediumRisks}</StatusIndicator>
            }
          ]}
        />
      </Container>
      <Table
        variant="stacked"
        columnDefinitions={[
          { id: 'pillar', header: 'Pillar', cell: item => item.pillarName },
          {
            id: 'progress',
            header: 'Progress',
            cell: (item: RiskSummaryType) => {
              const { answeredQuestions, totalQuestions } = item;
              return `${answeredQuestions}/${totalQuestions}`;
            }
          },
          { id: 'high', header: 'High Risks', cell: item => item.highRisks },
          { id: 'medium', header: 'Medium Risks', cell: item => item.mediumRisks },
        ]}
        loading={isRefreshing || isUpdating}
        loadingText="Loading risk summary data..."
        items={summary || []}
        header={
          <Header
            variant="h3"
            actions={
              <SpaceBetween direction="horizontal" size="xs">
                <ButtonDropdown
                  items={dropdownItems}
                  loading={isUpdating || isGeneratingReport}
                  loadingText="Updating workload..."
                  onItemClick={handleDropdownAction}
                  mainAction={{
                    text: 'Complete Well-Architected Tool Review',
                    onClick: onUpdate
                  }}
                />
                <Button
                  iconName="refresh"
                  variant="icon"
                  onClick={onRefresh}
                  loading={isRefreshing}
                  disabled={!summary || isUpdating}
                />
              </SpaceBetween>
            }
            info={<HelpButton contentId="wellArchitectedTool" />}
          >
            Risk Summary
          </Header>
        }
      />
    </div>
  );
};
</file>

<file path="ecs_fargate_app/frontend/src/components/WellArchitectedAnalyzer.tsx">
import React, { useState, useEffect } from 'react';
import { DocumentView } from './DocumentView';
import { SpaceBetween, Container, Button, StatusIndicator, ProgressBar, Tabs, Alert, ExpandableSection } from '@cloudscape-design/components';
import { FileUpload } from './FileUpload';
import { WorkloadIdInput } from './WorkloadIdInput';
import { PillarSelector } from './PillarSelector';
import { AnalysisResults } from './AnalysisResults';
import { RiskSummary } from './RiskSummary';
import { useAnalyzer } from '../hooks/useAnalyzer';
import { UploadedFile, WellArchitectedPillar, IaCTemplateType, UpdatedDocument } from '../types';
import { analyzerApi } from '../services/api';
import { socketService } from '../services/socket';
import { IaCTemplateSelector } from './IaCTemplateSelector';

const DEFAULT_PILLARS: WellArchitectedPillar[] = [
  { id: 'operational-excellence', name: 'Operational Excellence', selected: true },
  { id: 'security', name: 'Security', selected: true },
  { id: 'reliability', name: 'Reliability', selected: true },
  { id: 'performance-efficiency', name: 'Performance Efficiency', selected: true },
  { id: 'cost-optimization', name: 'Cost Optimization', selected: true },
  { id: 'sustainability', name: 'Sustainability', selected: true },
];

interface ImplementationProgress {
  status: string;
  progress: number;
}

export const WellArchitectedAnalyzer: React.FC = () => {
  const [uploadedFile, setUploadedFile] = useState<UploadedFile | null>(null);
  const [updatedDocument, setUpdatedDocument] = useState<UpdatedDocument | null>(null);
  const [workloadId, setWorkloadId] = useState<string | null>(null);
  const [activeTabId, setActiveTabId] = useState('analysis');
  const [selectedPillars, setSelectedPillars] = useState(
    DEFAULT_PILLARS.filter(p => p.selected).map(p => p.id)
  );
  const [isDownloading, setIsDownloading] = useState(false);
  const [isImplementing, setIsImplementing] = useState(false);
  const [isLoadingDetails, setIsLoadingDetails] = useState(false);
  const [implementationProgress, setImplementationProgress] = useState<ImplementationProgress | null>(null);
  const [selectedIaCType, setSelectedIaCType] = useState<IaCTemplateType>(
    IaCTemplateType.CLOUDFORMATION_YAML
  );
  const [isImageFile, setIsImageFile] = useState(false);
  const [showCancellationAlert, setShowCancellationAlert] = useState(false);
  const [documentViewTabTitle, setDocumentViewTabTitle] = useState('IaC Document');
  const [showGenerationErrorWarning, setShowGenerationErrorWarning] = useState(false);
  const [generationError, setGenerationError] = useState<string | null>(null);

  useEffect(() => {
    const cleanup = socketService.onImplementationProgress((progressData: ImplementationProgress) => {
      setImplementationProgress(progressData);
    });

    return () => {
      cleanup();
    };
  }, []);

  const {
    analyze,
    cancelAnalysis,
    isCancellingAnalysis,
    showAnalysisCancellationAlert,
    setShowAnalysisCancellationAlert,
    updateWorkload,
    generateReport,
    downloadRecommendations,
    refreshSummary,
    deleteWorkload,
    setError,
    analysisResults,
    riskSummary,
    isAnalyzing,
    isUpdating,
    error,
    progress,
    isRefreshing,
    isGeneratingReport,
    isDeleting,
    canDeleteWorkload,
    createdWorkloadId,
    showPartialResultsWarning,
    setShowPartialResultsWarning,
    partialResultsError,
  } = useAnalyzer();

  const handleAnalyze = async () => {
    if (!uploadedFile) return;
    await analyze(uploadedFile, workloadId, selectedPillars);
  };

  const handleUpdate = async () => {
    await updateWorkload(workloadId);
  };

  const getFileType = (fileName: string, currentType: string | undefined): string => {
    if (fileName.endsWith('.tf')) return 'application/terraform';
    if (fileName.endsWith('.yaml') || fileName.endsWith('.yml')) return 'application/yaml';
    if (fileName.endsWith('.json')) return 'application/json';
    return currentType || 'undefined';
  };

  const handleFileUploaded = (file: UploadedFile) => {
    const processedFile = {
      ...file,
      type: getFileType(file.name, file.type)
    };

    setUploadedFile(processedFile);
    setIsImageFile(processedFile.type.startsWith('image/'));
  };

  const handleGenerateReport = async () => {
    const activeWorkloadId = workloadId || createdWorkloadId;
    if (!activeWorkloadId) return;
    await generateReport(activeWorkloadId);
  };

  const handleRefresh = () => {
    const activeWorkloadId = workloadId || createdWorkloadId;
    if (!activeWorkloadId) return;
    refreshSummary(activeWorkloadId);
  };

  const handleGenerateIacDocument = async () => {
    if (!uploadedFile || !analysisResults) return;

    try {
      setIsImplementing(true);
      setShowGenerationErrorWarning(false);
      setGenerationError(null);

      const result = await analyzerApi.generateIacDocument(
        uploadedFile.id,
        uploadedFile.name,
        uploadedFile.type,
        analysisResults,
        selectedIaCType
      );

      if (result.error) {
        setShowGenerationErrorWarning(true);
        setGenerationError(result.error);
      }

      if (result.content) {
        setUpdatedDocument({
          content: result.content,
          name: uploadedFile.name,
          templateType: selectedIaCType
        });
        setDocumentViewTabTitle('IaC Document (Updated)');

        if (result.isCancelled) {
          setShowCancellationAlert(true);
        }
      }
    } catch (error) {
        setShowGenerationErrorWarning(true);
        setGenerationError('An unexpected error occurred during generation.');
    } finally {
        setIsImplementing(false);
        setImplementationProgress(null);
    }
  };

  const handleDownloadRecommendations = async () => {
    try {
      setIsDownloading(true);
      await downloadRecommendations();
    } finally {
      setIsDownloading(false);
    }
  };

  const acceptedFileTypes = [
    '.yaml', '.yml', '.json', '.tf',  // IaC files
    '.png', '.jpg', '.jpeg',          // Image files
    '.xml', '.txt'                    // Repomix
  ];

  return (
    <SpaceBetween size="l">
      <Container>
        <SpaceBetween size="l">
          <FileUpload
            onFileUploaded={handleFileUploaded}
            acceptedFileTypes={acceptedFileTypes}
          />

          <PillarSelector
            pillars={DEFAULT_PILLARS}
            selectedPillars={selectedPillars}
            onChange={setSelectedPillars}
            disabled={isAnalyzing || isUpdating}
          />

          <ExpandableSection
            variant="inline"
            headerText="Optional settings"
          >
            <SpaceBetween size="l">
              <WorkloadIdInput
                value={workloadId || ''}
                onChange={(value) => setWorkloadId(value || null)}
                optional={true}
                disabled={!!createdWorkloadId}
              />
              <IaCTemplateSelector
                value={selectedIaCType}
                onChange={setSelectedIaCType}
                disabled={isAnalyzing || isUpdating || !isImageFile}
              />
            </SpaceBetween>
          </ExpandableSection>



          {error && (
            <Alert
              type="error"
              dismissible
              onDismiss={() => setError(null)}
              header="Error"
            >
              {error}
            </Alert>
          )}

          <SpaceBetween size="xs" direction="horizontal">
            <Button
              variant="primary"
              onClick={handleAnalyze}
              loading={isAnalyzing}
              disabled={!uploadedFile || selectedPillars.length === 0}
              iconName="gen-ai"
            >
              Review Uploaded Document
            </Button>
            {isAnalyzing && (
              <Button
                onClick={cancelAnalysis}
                iconName="close"
                disabled={isCancellingAnalysis || !progress}
                loading={isCancellingAnalysis}
              >
                {isCancellingAnalysis ? 'Cancelling...' : 'Cancel Review'}
              </Button>
            )}
          </SpaceBetween>
        </SpaceBetween>
      </Container>

      {isAnalyzing && progress && (
        <Container>
          <SpaceBetween size="m">
            <StatusIndicator type="in-progress">
              [{progress.processedQuestions}/{progress.totalQuestions}] Analyzing uploaded file according to:
              '{progress.currentPillar} - {progress.currentQuestion}'
            </StatusIndicator>
            <ProgressBar
              value={Math.round((progress.processedQuestions / progress.totalQuestions) * 100)}
              description="Analysis progress"
            />
          </SpaceBetween>
        </Container>
      )}

      {isImplementing && implementationProgress && (
        <Container>
          <SpaceBetween size="m">
            <StatusIndicator type="in-progress">
              {implementationProgress.status}
            </StatusIndicator>
            <ProgressBar
              value={implementationProgress.progress}
              description="IaC document generation progress"
            />
          </SpaceBetween>
        </Container>
      )}

      {isLoadingDetails && implementationProgress && (
        <Container>
          <SpaceBetween size="m">
            <StatusIndicator type="in-progress">
              {implementationProgress.status}
            </StatusIndicator>
            <ProgressBar
              value={implementationProgress.progress}
              description="Analysis progress"
            />
          </SpaceBetween>
        </Container>
      )}

      {showAnalysisCancellationAlert && (
        <Alert
          onDismiss={() => setShowAnalysisCancellationAlert(false)}
          dismissible
          type="warning"
          header="Analysis cancelled"
        >
          The analysis of the uploaded file was cancelled. Partial results are shown below.
          You can either use these partial results or try analyzing the complete
          file again.
        </Alert>
      )}

      {showCancellationAlert && (
        <Alert
          onDismiss={() => setShowCancellationAlert(false)}
          dismissible
          type="warning"
          header="Generation cancelled"
        >
          The IaC document generation was cancelled. A partial version has been generated
          and can be viewed in the 'IaC Document' tab. You can either use this partial
          version or try generating the complete document again.
        </Alert>
      )}

      {showPartialResultsWarning && (
        <Alert
          onDismiss={() => setShowPartialResultsWarning(false)}
          dismissible
          type="warning"
          header="Partial Analysis Results"
        >
          {partialResultsError + ' ' || 'Analysis was interrupted. Showing partial results.'}
          You can either use these partial results or try
          analyzing the complete file again after waiting a few minutes.
        </Alert>
      )}

      {showGenerationErrorWarning && (
        <Alert
          onDismiss={() => setShowGenerationErrorWarning(false)}
          dismissible
          type="warning"
          header="Partial IaC Document Generation"
        >
          {generationError + ' ' || 'Template generation was interrupted. Showing partial results.'}
          You can try generating the complete document again after waiting a few minutes.
        </Alert>
      )}

      {analysisResults && (
        <Tabs
          activeTabId={activeTabId}
          onChange={({ detail }) => {
            setActiveTabId(detail.activeTabId);
            if (detail.activeTabId == 'diff')
              setDocumentViewTabTitle('IaC Document')
          }}
          tabs={[
            {
              id: 'analysis',
              label: 'Analysis Results',
              content: (
                <AnalysisResults
                  results={analysisResults}
                  isAnalyzing={isAnalyzing}
                  onDownloadRecommendations={handleDownloadRecommendations}
                  onGenerateIacDocument={handleGenerateIacDocument}
                  isDownloading={isDownloading}
                  isImplementing={isImplementing}
                  uploadedFileID={uploadedFile?.id || ''}
                  isLoadingDetails={isLoadingDetails}
                  setIsLoadingDetails={setIsLoadingDetails}
                  uploadedFileType={uploadedFile?.type || ''}
                  selectedIaCType={selectedIaCType}
                  setError={setError}
                />
              )
            },
            {
              id: 'wat',
              label: 'Well-Architected Tool',
              disabled: isLoadingDetails || isImplementing,
              content: (
                <div>
                  <RiskSummary
                    summary={riskSummary}
                    onUpdate={handleUpdate}
                    onGenerateReport={handleGenerateReport}
                    onDeleteWorkload={deleteWorkload}
                    onRefresh={handleRefresh}
                    isUpdating={isUpdating}
                    isRefreshing={isRefreshing}
                    isGeneratingReport={isGeneratingReport}
                    isDeleting={isDeleting}
                    canDeleteWorkload={canDeleteWorkload}
                    hasProvidedWorkloadId={!!workloadId}
                  />
                </div>
              )
            },
            {
              id: 'diff',
              label: documentViewTabTitle,
              disabled: isLoadingDetails || isImplementing || !updatedDocument,
              content: (
                <div>
                  {updatedDocument && (
                    <DocumentView
                      content={updatedDocument.content}
                      fileName={updatedDocument.name}
                      selectedIaCType={selectedIaCType}
                    />
                  )}
                </div>
              )
            }
          ]}
        />
      )}
    </SpaceBetween>
  );
};
</file>

<file path="ecs_fargate_app/frontend/src/components/WorkloadIdInput.tsx">
import React from 'react';
import { Input, FormField, Link } from '@cloudscape-design/components';
import { HelpButton } from './utils/HelpButton';

interface WorkloadIdInputProps {
  value: string;
  onChange: (value: string) => void;
  optional?: boolean;
  disabled?: boolean;
}

export const WorkloadIdInput: React.FC<WorkloadIdInputProps> = ({
  value,
  onChange,
  optional = false,
  disabled = false,
}) => {
  return (
    <FormField
      label={
        <>
          Well-Architected Tool Workload Id <HelpButton contentId="workloadId" />
        </>
      }
      description={
        <>
          {optional
            ? 'Optionally enter an existing Well-Architected Tool workload ID, or leave empty to create a new one.'
            : 'Enter the Workload ID from your Well-Architected Tool workload.'}{' '}
          <Link
            external
            href="https://docs.aws.amazon.com/wellarchitected/latest/userguide/define-workload.html"
          >
            Learn more
          </Link>
        </>
      }
    >
      <Input
        value={value}
        onChange={event => onChange(event.detail.value)}
        placeholder={optional ? "Enter workload ID (optional)" : "Enter workload ID"}
        disabled={disabled}
      />
    </FormField>
  );
};
</file>

<file path="ecs_fargate_app/frontend/src/contexts/HelpPanelContext.tsx">
import React, { createContext, useContext, useState, ReactNode } from 'react';

interface HelpPanelContextType {
  isToolsOpen: boolean;
  content: {
    header: string;
    body: ReactNode;
  } | null;
  setIsToolsOpen: (isOpen: boolean) => void;
  setHelpContent: (header: string, body: ReactNode) => void;
}

const HelpPanelContext = createContext<HelpPanelContextType | undefined>(undefined);

export const HelpPanelProvider: React.FC<{ children: ReactNode }> = ({ children }) => {
  const [isToolsOpen, setIsToolsOpen] = useState(false);
  const [content, setContent] = useState<{ header: string; body: ReactNode } | null>(null);

  const setHelpContent = (header: string, body: ReactNode) => {
    setContent({ header, body });
    setIsToolsOpen(true);
  };

  return (
    <HelpPanelContext.Provider value={{ 
      isToolsOpen, 
      content, 
      setIsToolsOpen,
      setHelpContent 
    }}>
      {children}
    </HelpPanelContext.Provider>
  );
};

export const useHelpPanel = () => {
  const context = useContext(HelpPanelContext);
  if (undefined === context) {
    throw new Error('useHelpPanel must be used within a HelpPanelProvider');
  }
  return context;
};
</file>

<file path="ecs_fargate_app/frontend/src/hooks/useAnalyzer.ts">
import {useState, useEffect} from 'react';
import {analyzerApi} from '../services/api';
import {socketService} from '../services/socket';
import {AnalysisResult, UploadedFile, RiskSummary} from '../types';

export const useAnalyzer = () => {
    const [analysisResults, setAnalysisResults] = useState<AnalysisResult[] | null>(null);
    const [riskSummary, setRiskSummary] = useState<RiskSummary[] | null>(null);
    const [isAnalyzing, setIsAnalyzing] = useState(false);
    const [isUpdating, setIsUpdating] = useState(false);
    const [isRefreshing, setIsRefreshing] = useState(false);
    const [isGeneratingReport, setIsGeneratingReport] = useState(false);
    const [isDeleting, setIsDeleting] = useState(false);
    const [error, setError] = useState<string | null>(null);
    const [progress, setProgress] = useState<{
        processedQuestions: number;
        totalQuestions: number;
        currentPillar: string;
        currentQuestion: string;
    } | null>(null);
    const [createdWorkloadId, setCreatedWorkloadId] = useState<string | null>(null);
    const [canDeleteWorkload, setCanDeleteWorkload] = useState(false);
    const [showAnalysisCancellationAlert, setShowAnalysisCancellationAlert] = useState(false);
    const [isCancellingAnalysis, setIsCancellingAnalysis] = useState(false);
    const [showPartialResultsWarning, setShowPartialResultsWarning] = useState(false);
    const [partialResultsError, setPartialResultsError] = useState<string | null>(null);

    useEffect(() => {
        const cleanup = socketService.onAnalysisProgress((progressData) => {
            setProgress(progressData);
        });

        return () => {
            cleanup();
            socketService.disconnect();
        };
    }, []);

    const analyze = async (
        file: UploadedFile,
        workloadId: string | null,
        selectedPillars: string[]
    ) => {
        setIsAnalyzing(true);
        setError(null);
        setProgress(null);
        setShowPartialResultsWarning(false);
        setPartialResultsError(null);
        let tempWorkloadId: string | null = null;

        try {
            // Create temp workload if no workloadId provided
            if (!workloadId) {
                tempWorkloadId = await analyzerApi.createWorkload(true);
                workloadId = tempWorkloadId;
            }

            const {results, isCancelled, error: analysisError} = await analyzerApi.analyze(
                file.id,
                file.name,
                file.type,
                workloadId,
                selectedPillars
            );

            setAnalysisResults(results);

            if (isCancelled) {
                setShowAnalysisCancellationAlert(true);
            } else if (analysisError) {
                setShowPartialResultsWarning(true);
                setPartialResultsError(analysisError);
            }

            // Delete temp workload if it was created
            if (tempWorkloadId) {
                await analyzerApi.deleteWorkload(tempWorkloadId);
            }
        } catch (err) {
            const errorMessage = err instanceof Error ? err.message : 'Analysis failed';
            setError(errorMessage);

            // If we have any results, show partial results warning
            if (analysisResults && analysisResults.length > 0) {
                setShowPartialResultsWarning(true);
                setPartialResultsError('Analysis failed unexpectedly. Showing partial results.');
            }
        } finally {
            setIsAnalyzing(false);
            setIsCancellingAnalysis(false);
            setProgress(null);
        }
    };

    const cancelAnalysis = async () => {
        try {
            setIsCancellingAnalysis(true);
            await analyzerApi.cancelAnalysis();
        } catch (err) {
            setError(err instanceof Error ? err.message : 'Failed to cancel analysis');
        }
    };

    const updateWorkload = async (providedWorkloadId: string | null) => {
        if (!analysisResults) return;

        setIsUpdating(true);
        setError(null);
        try {
            let workloadId = providedWorkloadId;

            // Create new workload if no workloadId provided
            if (!workloadId) {
                workloadId = await analyzerApi.createWorkload(false);
                setCreatedWorkloadId(workloadId);
                setCanDeleteWorkload(true);
            }

            for (const result of analysisResults) {
                const appliedBestPractices = result.bestPractices
                    .filter(bp => bp.applied)
                    .map(bp => bp.id);

                if (appliedBestPractices.length > 0) {
                    await analyzerApi.updateWorkload(
                        workloadId,
                        result.questionId,
                        appliedBestPractices
                    );
                }
            }

            const milestoneName = `Review completed on ${new Date().toISOString()}`;
            await analyzerApi.createMilestone(workloadId, milestoneName);

            const summary = await analyzerApi.getRiskSummary(workloadId);
            setRiskSummary(summary);
        } catch (err) {
            setError(err instanceof Error ? err.message : 'Update failed');
        } finally {
            setIsUpdating(false);
        }
    };

    const deleteWorkload = async () => {
        if (!createdWorkloadId || !canDeleteWorkload) return;

        setIsDeleting(true);
        try {
            await analyzerApi.deleteWorkload(createdWorkloadId);
            setCreatedWorkloadId(null);
            setCanDeleteWorkload(false);
            setRiskSummary(null);
        } catch (err) {
            setError(err instanceof Error ? err.message : 'Failed to delete workload');
        } finally {
            setIsDeleting(false);
        }
    };

    const generateReport = async (workloadId: string) => {
        setIsGeneratingReport(true);
        try {
            const base64String = await analyzerApi.generateReport(workloadId);
            if (!base64String) {
                throw new Error('No report data received');
            }

            // Convert base64 to Blob and download
            const binaryString = window.atob(base64String);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }

            const blob = new Blob([bytes], {type: 'application/pdf'});
            const url = window.URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `WA_Review_Report_${workloadId}_${new Date().toISOString()}.pdf`;
            document.body.appendChild(a);
            a.click();
            window.URL.revokeObjectURL(url);
            document.body.removeChild(a);
        } catch (err) {
            setError(err instanceof Error ? err.message : 'Failed to generate report');
        } finally {
            setIsGeneratingReport(false);
        }
    };

    const downloadRecommendations = async () => {
        if (!analysisResults) return;

        try {
            const csv = await analyzerApi.generateRecommendations(analysisResults);
            const blob = new Blob([csv], {type: 'text/csv'});
            const url = window.URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `WA_Recommendations_${new Date().toISOString()}.csv`;
            document.body.appendChild(a);
            a.click();
            window.URL.revokeObjectURL(url);
            document.body.removeChild(a);
        } catch (err) {
            setError(err instanceof Error ? err.message : 'Failed to download recommendations');
        }
    };

    const refreshSummary = async (workloadId: string) => {
        setIsRefreshing(true);
        try {
            const summary = await analyzerApi.getRiskSummary(workloadId);
            setRiskSummary(summary);
        } catch (err) {
            setError(err instanceof Error ? err.message : 'Failed to refresh summary');
        } finally {
            setIsRefreshing(false);
        }
    };

    return {
        analyze,
        updateWorkload,
        generateReport,
        downloadRecommendations,
        refreshSummary,
        deleteWorkload,
        setError,
        analysisResults,
        riskSummary,
        isAnalyzing,
        isUpdating,
        error,
        progress,
        isRefreshing,
        isGeneratingReport,
        createdWorkloadId,
        canDeleteWorkload,
        isDeleting,
        cancelAnalysis,
        isCancellingAnalysis,
        showAnalysisCancellationAlert,
        setShowAnalysisCancellationAlert,
        showPartialResultsWarning,
        setShowPartialResultsWarning,
        partialResultsError,
    };
};
</file>

<file path="ecs_fargate_app/frontend/src/services/api.ts">
import axios, { AxiosError } from 'axios';
import { AnalysisResult, RiskSummary, IaCTemplateType } from '../types';

const api = axios.create({
  baseURL: '/api',
  headers: {
    'Content-Type': 'application/json',
  },
  timeout: 0, // Allow for long-running operations
});

// Move handleError outside as a standalone function
const handleError = (error: unknown) => {
  if (axios.isAxiosError(error)) {
    const axiosError = error as AxiosError<{ message: string }>;
    return new Error(
      axiosError.response?.data?.message ||
      axiosError.message ||
      'An unexpected error occurred'
    );
  }
  return new Error('An unexpected error occurred');
};

export const analyzerApi = {
  async uploadFile(file: File): Promise<string> {
    try {
      const formData = new FormData();
      formData.append('file', file);
      
      const response = await api.post('/analyzer/upload', formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      });
      
      return response.data.fileId;
    } catch (error) {
      throw handleError(error);
    }
  },
  async analyze(
    fileId: string,
    fileName: string,
    fileType: string,
    workloadId: string,
    selectedPillars: string[]
  ): Promise<{ results: AnalysisResult[]; isCancelled: boolean; error?: string }> {
    try {
      const response = await api.post('/analyzer/analyze', {
        fileId,
        fileName,
        fileType,
        workloadId,
        selectedPillars,
      });
      return response.data;
    } catch (error) {
      throw handleError(error);
    }
  },

  async cancelAnalysis(): Promise<void> {
    try {
      await api.post('/analyzer/cancel-analysis');
    } catch (error) {
      throw handleError(error);
    }
  },

  async updateWorkload(workloadId: string, questionId: string, selectedChoices: string[]) {
    try {
      const response = await api.post(`/well-architected/answer/${workloadId}`, {
        questionId,
        selectedChoices,
      });
      return response.data;
    } catch (error) {
      throw handleError(error);
    }
  },

  async getRiskSummary(workloadId: string): Promise<RiskSummary[]> {
    try {
      const response = await api.get(`/well-architected/risk-summary/${workloadId}`);
      return response.data;
    } catch (error) {
      throw handleError(error);
    }
  },

  async createMilestone(workloadId: string, milestoneName: string) {
    try {
      const response = await api.post('/well-architected/milestone', {
        workloadId,
        milestoneName,
      });
      return response.data;
    } catch (error) {
      throw handleError(error);
    }
  },

  async generateReport(workloadId: string): Promise<string> {
    try {
      const response = await api.post('/report/generate', { workloadId });
      return response.data;
    } catch (error) {
      throw handleError(error);
    }
  },

  async generateRecommendations(results: AnalysisResult[]): Promise<string> {
    try {
      const response = await api.post('/report/recommendations', results);
      return response.data;
    } catch (error) {
      throw handleError(error);
    }
  },

  async createWorkload(isTemp: boolean = false): Promise<string> {
    try {
      const response = await api.post('/well-architected/workload/create', {
        isTemp
      });
      return response.data;
    } catch (error) {
      throw handleError(error);
    }
  },

  async deleteWorkload(workloadId: string): Promise<void> {
    try {
      await api.delete(`/well-architected/workload/${workloadId}`);
    } catch (error) {
      throw handleError(error);
    }
  },

  async generateIacDocument(
    fileContent: string,
    fileName: string,
    fileType: string,
    recommendations: AnalysisResult[],
    templateType: IaCTemplateType
  ): Promise<{ content: string; isCancelled: boolean; error?: string }> {
    try {
      const response = await api.post('/analyzer/generate-iac', {
        fileContent,
        fileName,
        fileType,
        recommendations,
        templateType
      });
      return response.data;
    } catch (error) {
      // Return the error response
      return {
        content: '',
        isCancelled: false,
        error: error instanceof Error ? error.message : 'Failed to generate IaC document'
      };
    }
  },

  async getMoreDetails(
    selectedItems: AnalysisResult[],
    fileContent: string,
    fileType: string,
    templateType: IaCTemplateType
  ): Promise<{ content: string; error?: string }> {
    try {
      const response = await api.post('/analyzer/get-more-details', {
        selectedItems,
        fileContent,
        fileType,
        templateType
      });
      return response.data;
    } catch (error) {
      return {
        content: '',
        error: error instanceof Error ? error.message : 'Failed to get detailed analysis'
      };
    }
  },

  async cancelIaCGeneration(): Promise<void> {
    try {
      await api.post('/analyzer/cancel-iac-generation');
    } catch (error) {
      throw handleError(error);
    }
  }
};
</file>

<file path="ecs_fargate_app/frontend/src/services/socket.ts">
import { io, Socket } from 'socket.io-client';

class SocketService {
    private socket: Socket | null = null;

    connect() {
        if (!this.socket) {
            // Use relative URL to connect to the same host
            const baseUrl = window.location.origin;

            this.socket = io(baseUrl, {
                path: '/socket.io/',
                transports: ['websocket', 'polling'],
                reconnection: true,
                reconnectionAttempts: 5,
                reconnectionDelay: 1000,
                reconnectionDelayMax: 5000,
                timeout: 20000,
            });

            this.socket.on('connect_error', (error) => {
                console.error('Socket connection error:', error);
            });

            this.socket.on('reconnect_error', (error) => {
                console.error('Socket reconnection error:', error);
            });
        }
        return this.socket;
    }

    disconnect() {
        if (this.socket) {
            this.socket.disconnect();
            this.socket = null;
        }
    }

    onAnalysisProgress(callback: (data: {
        processedQuestions: number;
        totalQuestions: number;
        currentPillar: string;
        currentQuestion: string;
    }) => void) {
        const socket = this.connect();
        socket.on('analysisProgress', callback);
        return () => socket.off('analysisProgress', callback);
    }

    onImplementationProgress(callback: (data: {
        status: string;
        progress: number;
    }) => void) {
        const socket = this.connect();
        socket.on('implementationProgress', callback);
        return () => socket.off('implementationProgress', callback);
    }
}

export const socketService = new SocketService();
</file>

<file path="ecs_fargate_app/frontend/src/types/index.ts">
export interface WellArchitectedPillar {
  id: string;
  name: string;
  selected: boolean;
}

export interface BestPractice {
  id: string;
  name: string;
  pillarId: string;
  questionId: string;
  applied: boolean;
  reasonApplied?: string;
  reasonNotApplied?: string;
  recommendations?: string;
}

export interface AnalysisResult {
  pillar: string;
  question: string;
  questionId: string;
  bestPractices: BestPractice[];
}

export interface WorkloadReview {
  workloadId: string;
  lensAlias: string;
  results: AnalysisResult[];
}

export interface RiskSummary {
  pillarName: string;
  totalQuestions: number;
  answeredQuestions: number;
  highRisks: number;
  mediumRisks: number;
}

export interface UploadedFile {
  id: string
  name: string;
  type: string;
  size: number;
}

export enum FileType {
  IAC = 'iac',
  IMAGE = 'image'
}

export interface UpdatedDocument {
  content: string;
  name: string;
  templateType?: IaCTemplateType;
}

export interface WorkloadCreationResult {
  workloadId: string;
  isTemp: boolean;
}

export interface RiskSummaryProps {
  summary: RiskSummary[] | null;
  onUpdate: () => void;
  onGenerateReport: () => void;
  onDeleteWorkload: () => void;
  onRefresh: () => void;
  isUpdating: boolean;
  isRefreshing: boolean;
  isGeneratingReport: boolean;
  isDeleting: boolean;
  canDeleteWorkload: boolean;
  hasProvidedWorkloadId: boolean;
}

export interface SelectedAnalysisItem {
  pillar: string;
  question: string;
  questionId: string;
  bestPractices: BestPractice[];
}

export interface SelectedItem {
  pillar: string;
  question: string;
  bestPractices: {
      id: string;
      name: string;
      applied: boolean;
      recommendations?: string;
  }[];
}

export enum IaCTemplateType {
  CLOUDFORMATION_YAML = 'CloudFormation (.yaml) template',
  CLOUDFORMATION_JSON = 'CloudFormation (.json) template',
  TERRAFORM = 'Terraform (.tf) document'
}
</file>

<file path="ecs_fargate_app/frontend/src/App.css">
#root {
  /* max-width: 1280px; */
  width: 100%;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}

.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
  transition: filter 300ms;
}
.logo:hover {
  filter: drop-shadow(0 0 2em #646cffaa);
}
.logo.react:hover {
  filter: drop-shadow(0 0 2em #61dafbaa);
}

@keyframes logo-spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}

@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
    animation: logo-spin infinite 20s linear;
  }
}

.card {
  padding: 2em;
}

.read-the-docs {
  color: #888;
}
</file>

<file path="ecs_fargate_app/frontend/src/App.tsx">
import { AppLayout, ContentLayout, Header, TopNavigation, HelpPanel } from '@cloudscape-design/components';
import { WellArchitectedAnalyzer } from './components/WellArchitectedAnalyzer';
import { HelpPanelProvider, useHelpPanel } from './contexts/HelpPanelContext';
import { helpContent } from './components/utils/help-content';
import { HelpButton } from './components/utils/HelpButton';
import '@cloudscape-design/global-styles/index.css';

function AppContent() {
  const { isToolsOpen, content, setIsToolsOpen } = useHelpPanel();
  const defaultContent = helpContent.default;

  return (
    <div>
      <TopNavigation
        identity={{
          href: '#',
          title: "Infrastructure as Code (IaC) Analyzer",
          logo: {
            src: "/aws-wa-logo.png",
            alt: "Well-Architected"
          }
        }}
      />
      <AppLayout
        content={
          <ContentLayout
            header={
              <Header
                variant="h3"
                info={<HelpButton contentId="default" />}
              >
                Review your infrastructure as code against AWS Well-Architected Framework Best Practices
              </Header>
            }
          >
            <WellArchitectedAnalyzer />
          </ContentLayout>
        }
        navigationHide={true}
        toolsOpen={isToolsOpen}
        onToolsChange={({ detail }) => setIsToolsOpen(detail.open)}
        tools={
          <HelpPanel
            header={<h2>{content?.header || defaultContent.header}</h2>}
          >
            {content?.body || defaultContent.body}
          </HelpPanel>
        }
        maxContentWidth={Number.MAX_VALUE}
      />
    </div>
  );
}

function App() {
  return (
    <HelpPanelProvider>
      <AppContent />
    </HelpPanelProvider>
  );
}

export default App;
</file>

<file path="ecs_fargate_app/frontend/src/index.css">
:root {
  font-family: Inter, system-ui, Avenir, Helvetica, Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;

  color-scheme: light dark;
  color: rgba(255, 255, 255, 0.87);
  background-color: #242424;

  font-synthesis: none;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

a {
  font-weight: 500;
  color: #646cff;
  text-decoration: inherit;
}
a:hover {
  color: #535bf2;
}

body {
  margin: 0;
  display: flex;
  place-items: center;
  min-width: 320px;
  min-height: 100vh;
}

h1 {
  font-size: 3.2em;
  line-height: 1.1;
}

button {
  border-radius: 8px;
  border: 1px solid transparent;
  padding: 0.6em 1.2em;
  font-size: 1em;
  font-weight: 500;
  font-family: inherit;
  background-color: #1a1a1a;
  cursor: pointer;
  transition: border-color 0.25s;
}
button:hover {
  border-color: #646cff;
}
button:focus,
button:focus-visible {
  outline: 4px auto -webkit-focus-ring-color;
}

@media (prefers-color-scheme: light) {
  :root {
    color: #213547;
    background-color: #ffffff;
  }
  a:hover {
    color: #747bff;
  }
  button {
    background-color: #f9f9f9;
  }
}
</file>

<file path="ecs_fargate_app/frontend/src/main.tsx">
import { StrictMode } from 'react'
import { createRoot } from 'react-dom/client'
import './index.css'
import App from './App.tsx'

createRoot(document.getElementById('root')!).render(
  <StrictMode>
    <App />
  </StrictMode>,
)
</file>

<file path="ecs_fargate_app/frontend/src/vite-env.d.ts">
/// <reference types="vite/client" />

interface ImportMetaEnv {
    readonly VITE_AWS_REGION: string
    readonly VITE_AWS_ACCESS_KEY_ID: string
    readonly VITE_AWS_SECRET_ACCESS_KEY: string
    readonly VITE_IAC_TEMPLATE_S3_BUCKET: string
    readonly VITE_WA_DOCS_S3_BUCKET: string
    readonly VITE_KNOWLEDGE_BASE_ID: string
    readonly VITE_MODEL_ID: string
    readonly VITE_DEFAULT_REVIEWER: string
    readonly VITE_DEFAULT_ENVIRONMENT: string
  }
  
  interface ImportMeta {
    readonly env: ImportMetaEnv
  }
</file>

<file path="ecs_fargate_app/frontend/index.html">
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/png" href="/aws-wa-logo.png" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Well-Architected IaC Analyzer</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>
</file>

<file path="ecs_fargate_app/frontend/package.json">
{
  "name": "wa-analyzer",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "engines": {
    "node": ">=22.0.0"
  },
  "scripts": {
    "dev": "vite",
    "build": "tsc -b && vite build",
    "build:finch": "finch build -f ../finch/frontend.Dockerfile .",
    "start:finch": "finch run --rm -p 8080:8080 frontend",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "@aws-sdk/client-bedrock-agent-runtime": "^3.x.x",
    "@aws-sdk/client-bedrock-runtime": "^3.706.0",
    "@aws-sdk/client-s3": "^3.705.0",
    "@aws-sdk/client-wellarchitected": "^3.699.0",
    "@cloudscape-design/code-view": "^3.0.34",
    "@cloudscape-design/components": "^3.0.841",
    "@cloudscape-design/global-styles": "^1.0.33",
    "axios": "^1.7.9",
    "react": "^18.3.1",
    "react-dom": "^18.3.1",
    "react-markdown": "^9.0.1",
    "socket.io-client": "^4.8.1"
  },
  "devDependencies": {
    "@eslint/js": "^9.15.0",
    "@testing-library/jest-dom": "^6.6.3",
    "@testing-library/react": "^16.1.0",
    "@types/node": "^22.10.2",
    "@types/multer": "^1.4.12",
    "@types/react": "^18.3.12",
    "@types/react-dom": "^18.3.1",
    "@vitejs/plugin-react": "^4.3.4",
    "eslint": "^9.15.0",
    "eslint-plugin-react-hooks": "^5.0.0",
    "eslint-plugin-react-refresh": "^0.4.14",
    "globals": "^15.12.0",
    "jsdom": "^25.0.1",
    "typescript": "~5.6.2",
    "typescript-eslint": "^8.15.0",
    "vite": "^6.0.1",
    "vitest": "^2.1.8"
  }
}
</file>

<file path="ecs_fargate_app/frontend/tsconfig.app.json">
{
  "compilerOptions": {
    "incremental": true,
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.app.tsbuildinfo",
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "isolatedModules": true,
    "moduleDetection": "force",
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,
    "types": ["vite/client", "node"],
    "allowSyntheticDefaultImports": true,
    "resolveJsonModule": true,
    "esModuleInterop": true
  },
  "include": ["src"]
}
</file>

<file path="ecs_fargate_app/frontend/tsconfig.json">
{
  "files": [],
  "references": [
    { "path": "./tsconfig.app.json" },
    { "path": "./tsconfig.node.json" }
  ]
}
</file>

<file path="ecs_fargate_app/frontend/tsconfig.node.json">
{
  "compilerOptions": {
    "incremental": true,
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.node.tsbuildinfo",
    "target": "ES2022",
    "lib": ["ES2023"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "isolatedModules": true,
    "moduleDetection": "force",
    "noEmit": true,

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,

    /* Node.js support */
    "types": ["node"],
    "allowSyntheticDefaultImports": true
  },
  "include": ["vite.config.ts", "vitest.config.ts"]
}
</file>

<file path="ecs_fargate_app/frontend/vite.config.ts">
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';
import path from 'path';

export default defineConfig({
  plugins: [react()],
  server: {
    host: '0.0.0.0',
    port: 8080,
    watch: {
      usePolling: true
    },
    proxy: {
      '/api': {
        target: 'http://backend:3000',
        changeOrigin: true,
        rewrite: (path) => path.replace(/^\/api/, '')
      },
      '/socket.io': {
        target: 'http://backend:3000',
        ws: true
      }
    }
  },
  build: {
    target: 'es2020',
    outDir: 'dist',
    sourcemap: true,
    rollupOptions: {
      input: {
        main: path.resolve(__dirname, 'index.html'),
      },
    },
  },
});
</file>

<file path="ecs_fargate_app/lambda_kb_synchronizer/kb_synchronizer.py">
# lambda_kb_synchronizer/kb_synchronizer.py

import csv
import json
import os
from io import StringIO

import boto3
import requests
from botocore.exceptions import ClientError


def download_file(url):
    response = requests.get(url)
    response.raise_for_status()
    return response.content


def upload_to_s3(bucket_name, file_name, file_content):
    s3_client = boto3.client("s3")
    try:
        s3_client.put_object(Bucket=bucket_name, Key=file_name, Body=file_content)
        print(f"File {file_name} uploaded successfully")
    except ClientError as e:
        print(f"Error uploading file {file_name}: {e}")
        raise


def get_lens_review(workload_id, lens_alias):
    client = boto3.client("wellarchitected")
    response = client.get_lens_review(WorkloadId=workload_id, LensAlias=lens_alias)
    return response["LensReview"]


def upgrade_lens_review(workload_id, lens_alias):
    client = boto3.client("wellarchitected")
    client.upgrade_lens_review(
        WorkloadId=workload_id,
        LensAlias=lens_alias,
        MilestoneName="string",
        ClientRequestToken="string",
    )
    return


def list_answers(workload_id, lens_alias):
    client = boto3.client("wellarchitected")
    answers = []
    next_token = None

    while True:
        if next_token:
            response = client.list_answers(
                WorkloadId=workload_id, LensAlias=lens_alias, NextToken=next_token
            )
        else:
            response = client.list_answers(WorkloadId=workload_id, LensAlias=lens_alias)

        answers.extend(response["AnswerSummaries"])

        if "NextToken" in response:
            next_token = response["NextToken"]
        else:
            break

    return answers


def process_answers(answers, pillar_mapping):
    result = []
    for answer in answers:
        pillar_id = answer["PillarId"]
        pillar_name = pillar_mapping.get(pillar_id, pillar_id)
        question = answer["QuestionTitle"]
        for choice in answer["Choices"]:
            if choice["Title"] != "None of these":
                result.append(
                    {
                        "Pillar": pillar_name,
                        "Question": question,
                        "Best Practice": choice["Title"],
                    }
                )
    return result


def create_json(data):
    return json.dumps(data, indent=2)


def create_csv(data):
    output = StringIO()
    writer = csv.DictWriter(output, fieldnames=["Pillar", "Question", "Best Practice"])
    writer.writeheader()
    for row in data:
        writer.writerow(row)
    return output.getvalue()


def handler(event, context):
    bucket_name = os.environ["WA_DOCS_BUCKET_NAME"]
    workload_id = os.environ.get("WORKLOAD_ID")
    lens_alias = "wellarchitected"

    files_to_download = [
        {
            "url": "https://docs.aws.amazon.com/pdfs/wellarchitected/latest/cost-optimization-pillar/wellarchitected-cost-optimization-pillar.pdf",
            "name": "wellarchitected-cost-optimization-pillar.pdf",
        },
        {
            "url": "https://docs.aws.amazon.com/pdfs/wellarchitected/latest/operational-excellence-pillar/wellarchitected-operational-excellence-pillar.pdf",
            "name": "wellarchitected-operational-excellence-pillar.pdf",
        },
        {
            "url": "https://docs.aws.amazon.com/pdfs/wellarchitected/latest/performance-efficiency-pillar/wellarchitected-performance-efficiency-pillar.pdf",
            "name": "wellarchitected-performance-efficiency-pillar.pdf",
        },
        {
            "url": "https://docs.aws.amazon.com/pdfs/wellarchitected/latest/reliability-pillar/wellarchitected-reliability-pillar.pdf",
            "name": "wellarchitected-reliability-pillar.pdf",
        },
        {
            "url": "https://docs.aws.amazon.com/pdfs/wellarchitected/latest/security-pillar/wellarchitected-security-pillar.pdf",
            "name": "wellarchitected-security-pillar.pdf",
        },
        {
            "url": "https://docs.aws.amazon.com/pdfs/wellarchitected/latest/sustainability-pillar/wellarchitected-sustainability-pillar.pdf",
            "name": "wellarchitected-sustainability-pillar.pdf",
        },
    ]

    for file in files_to_download:
        try:
            content = download_file(file["url"])
            upload_to_s3(bucket_name, file["name"], content)
        except Exception as e:
            print(f"Error uploading WA whitepaper {file['name']}: {e}")

    # Parse and upload Best Practices names as JSON and CSV
    try:
        # Upgrade lens review
        upgrade_lens_review(workload_id, lens_alias)

        # Get lens review
        lens_review = get_lens_review(workload_id, lens_alias)

        # Create pillar mapping
        pillar_mapping = {
            pillar["PillarId"]: pillar["PillarName"]
            for pillar in lens_review["PillarReviewSummaries"]
        }

        # Get answers
        answers = list_answers(workload_id, lens_alias)

        # Process answers
        processed_data = process_answers(answers, pillar_mapping)

        # Create JSON
        json_data = create_json(processed_data)

        # Create CSV
        csv_data = create_csv(processed_data)

        # Upload JSON to S3
        upload_to_s3(bucket_name, "well_architected_best_practices.json", json_data)

        # Upload CSV to S3
        upload_to_s3(bucket_name, "well_architected_best_practices.csv", csv_data)

    except Exception as e:
        print(f"Error uploading JSON and CSV files to bucket {bucket_name}: {str(e)}")

    # After uploading WA whitepaper and JSON/CSV files, start the ingestion job
    bedrock_agent = boto3.client("bedrock-agent")

    response = bedrock_agent.start_ingestion_job(
        knowledgeBaseId=os.environ["KNOWLEDGE_BASE_ID"],
        dataSourceId=os.environ["DATA_SOURCE_ID"],
    )

    print(f"Started ingestion job: {response['ingestionJob']['ingestionJobId']}")
    return
</file>

<file path="ecs_fargate_app/lambda_kb_synchronizer/requirements.txt">
requests
</file>

<file path="ecs_fargate_app/well_architected_docs/well_architected_best_practices.csv">
Pillar,Question,Best Practice
Cost Optimization,How do you implement cloud financial management?,Establish ownership of cost optimization
Cost Optimization,How do you implement cloud financial management?,Establish a partnership between finance and technology
Cost Optimization,How do you implement cloud financial management?,Establish cloud budgets and forecasts
Cost Optimization,How do you implement cloud financial management?,Implement cost awareness in your organizational processes
Cost Optimization,How do you implement cloud financial management?,Monitor cost proactively
Cost Optimization,How do you implement cloud financial management?,Keep up-to-date with new service releases
Cost Optimization,How do you implement cloud financial management?,Quantify business value from cost optimization
Cost Optimization,How do you implement cloud financial management?,Report and notify on cost optimization
Cost Optimization,How do you implement cloud financial management?,Create a cost-aware culture
Cost Optimization,How do you govern usage?,Develop policies based on your organization requirements
Cost Optimization,How do you govern usage?,Implement goals and targets
Cost Optimization,How do you govern usage?,Implement an account structure
Cost Optimization,How do you govern usage?,Implement cost controls
Cost Optimization,How do you govern usage?,Implement groups and role
Cost Optimization,How do you govern usage?,Track project lifecycle
Cost Optimization,How do you monitor your cost and usage?,Configure detailed information sources
Cost Optimization,How do you monitor your cost and usage?,Identify cost attribution categories
Cost Optimization,How do you monitor your cost and usage?,Establish organization metrics
Cost Optimization,How do you monitor your cost and usage?,Configure billing and cost management tools
Cost Optimization,How do you monitor your cost and usage?,Add organization information to cost and usage
Cost Optimization,How do you monitor your cost and usage?,Allocate costs based on workload metrics
Cost Optimization,How do you decommission resources?,Track resources over their life time
Cost Optimization,How do you decommission resources?,Implement a decommissioning process
Cost Optimization,How do you decommission resources?,Decommission resources
Cost Optimization,How do you decommission resources?,Enforce data retention policies
Cost Optimization,How do you decommission resources?,Decommission resources automatically
Cost Optimization,How do you evaluate cost when you select services?,Identify organization requirements for cost
Cost Optimization,How do you evaluate cost when you select services?,Analyze all components of this workload
Cost Optimization,How do you evaluate cost when you select services?,Perform a thorough analysis of each component
Cost Optimization,How do you evaluate cost when you select services?,Select components of this workload to optimize cost in line with organization priorities
Cost Optimization,How do you evaluate cost when you select services?,Perform cost analysis for different usage over time
Cost Optimization,How do you evaluate cost when you select services?,Select software with cost effective licensing
Cost Optimization,"How do you meet cost targets when you select resource type, size and number?",Perform cost modeling
Cost Optimization,"How do you meet cost targets when you select resource type, size and number?","Select resource type, size, and number based on data"
Cost Optimization,"How do you meet cost targets when you select resource type, size and number?",Consider using shared resources
Cost Optimization,"How do you meet cost targets when you select resource type, size and number?","Select resource type, size, and number automatically based on metrics"
Cost Optimization,How do you use pricing models to reduce cost?,Perform pricing model analysis
Cost Optimization,How do you use pricing models to reduce cost?,Choose Regions based on cost
Cost Optimization,How do you use pricing models to reduce cost?,Select third-party agreements with cost-efficient terms
Cost Optimization,How do you use pricing models to reduce cost?,Implement pricing models for all components of this workload
Cost Optimization,How do you use pricing models to reduce cost?,Perform pricing model analysis at the management account level
Cost Optimization,How do you plan for data transfer charges?,Perform data transfer modeling
Cost Optimization,How do you plan for data transfer charges?,Select components to optimize data transfer cost
Cost Optimization,How do you plan for data transfer charges?,Implement services to reduce data transfer costs
Cost Optimization,"How do you manage demand, and supply resources?",Perform an analysis on the workload demand
Cost Optimization,"How do you manage demand, and supply resources?",Implement a buffer or throttle to manage demand
Cost Optimization,"How do you manage demand, and supply resources?",Supply resources dynamically
Cost Optimization,How do you evaluate new services?,Develop a workload review process
Cost Optimization,How do you evaluate new services?,Review and analyze this workload regularly
Cost Optimization,How do you evaluate the cost of effort?,Perform automation for operations
Operational Excellence,How do you determine what your priorities are?,Evaluate customer needs
Operational Excellence,How do you determine what your priorities are?,Evaluate internal customer needs
Operational Excellence,How do you determine what your priorities are?,Evaluate governance requirements
Operational Excellence,How do you determine what your priorities are?,Evaluate compliance requirements
Operational Excellence,How do you determine what your priorities are?,Evaluate threat landscape
Operational Excellence,How do you determine what your priorities are?,Evaluate tradeoffs while managing benefits and risks
Operational Excellence,How do you structure your organization to support your business outcomes?,Resources have identified owners
Operational Excellence,How do you structure your organization to support your business outcomes?,Processes and procedures have identified owners
Operational Excellence,How do you structure your organization to support your business outcomes?,Operations activities have identified owners responsible for their performance
Operational Excellence,How do you structure your organization to support your business outcomes?,Mechanisms exist to manage responsibilities and ownership
Operational Excellence,How do you structure your organization to support your business outcomes?,"Mechanisms exist to request additions, changes, and exceptions"
Operational Excellence,How do you structure your organization to support your business outcomes?,Responsibilities between teams are predefined or negotiated
Operational Excellence,How does your organizational culture support your business outcomes?,Provide executive sponsorship
Operational Excellence,How does your organizational culture support your business outcomes?,Escalation is encouraged
Operational Excellence,How does your organizational culture support your business outcomes?,"Communications are timely, clear, and actionable"
Operational Excellence,How does your organizational culture support your business outcomes?,Team members are empowered to take action when outcomes are at risk
Operational Excellence,How does your organizational culture support your business outcomes?,Experimentation is encouraged
Operational Excellence,How does your organizational culture support your business outcomes?,Team members are encouraged to maintain and grow their skill sets
Operational Excellence,How does your organizational culture support your business outcomes?,Resource teams appropriately
Operational Excellence,How do you implement observability in your workload?,Identify key performance indicators
Operational Excellence,How do you implement observability in your workload?,Implement application telemetry
Operational Excellence,How do you implement observability in your workload?,Implement user experience telemetry
Operational Excellence,How do you implement observability in your workload?,Implement dependency telemetry
Operational Excellence,How do you implement observability in your workload?,Implement distributed tracing
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?",Use version control
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?",Test and validate changes
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?",Use configuration management systems
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?",Use build and deployment management systems
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?",Perform patch management
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?",Share design standards
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?",Implement practices to improve code quality
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?",Use multiple environments
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?","Make frequent, small, reversible changes"
Operational Excellence,"How do you reduce defects, ease remediation, and improve flow into production?",Fully automate integration and deployment
Operational Excellence,How do you mitigate deployment risks?,Plan for unsuccessful changes
Operational Excellence,How do you mitigate deployment risks?,Test deployments
Operational Excellence,How do you mitigate deployment risks?,Employ safe deployment strategies
Operational Excellence,How do you mitigate deployment risks?,Automate testing and rollback
Operational Excellence,How do you know that you are ready to support a workload?,Ensure personnel capability
Operational Excellence,How do you know that you are ready to support a workload?,Ensure a consistent review of operational readiness
Operational Excellence,How do you know that you are ready to support a workload?,Use runbooks to perform procedures
Operational Excellence,How do you know that you are ready to support a workload?,Use playbooks to investigate issues
Operational Excellence,How do you know that you are ready to support a workload?,Make informed decisions to deploy systems and changes
Operational Excellence,How do you know that you are ready to support a workload?,Create support plans for production workloads
Operational Excellence,How do you utilize workload observability in your organization?,Create actionable alerts
Operational Excellence,How do you utilize workload observability in your organization?,Analyze workload metrics
Operational Excellence,How do you utilize workload observability in your organization?,Analyze workload logs
Operational Excellence,How do you utilize workload observability in your organization?,Analyze workload traces
Operational Excellence,How do you utilize workload observability in your organization?,Create dashboards
Operational Excellence,How do you understand the health of your operations?,Measure operations goals and KPIs with metrics
Operational Excellence,How do you understand the health of your operations?,Communicate status and trends to ensure visibility into operation
Operational Excellence,How do you understand the health of your operations?,Review operations metrics and prioritize improvement
Operational Excellence,How do you manage workload and operations events?,"Use a process for event, incident, and problem management"
Operational Excellence,How do you manage workload and operations events?,Have a process per alert
Operational Excellence,How do you manage workload and operations events?,Prioritize operational events based on business impact
Operational Excellence,How do you manage workload and operations events?,Define escalation paths
Operational Excellence,How do you manage workload and operations events?,Define a customer communication plan for service-impacting events
Operational Excellence,How do you manage workload and operations events?,Communicate status through dashboards
Operational Excellence,How do you manage workload and operations events?,Automate responses to events
Operational Excellence,How do you evolve operations?,Have a process for continuous improvement
Operational Excellence,How do you evolve operations?,Perform post-incident analysis
Operational Excellence,How do you evolve operations?,Implement feedback loops
Operational Excellence,How do you evolve operations?,Perform knowledge management
Operational Excellence,How do you evolve operations?,Define drivers for improvement
Operational Excellence,How do you evolve operations?,Validate insights
Operational Excellence,How do you evolve operations?,Perform operations metrics reviews
Operational Excellence,How do you evolve operations?,Document and share lessons learned
Operational Excellence,How do you evolve operations?,Allocate time to make improvements
Performance Efficiency,How do you select the appropriate cloud resources and architecture patterns for your workload?,Learn about and understand available cloud services and features
Performance Efficiency,How do you select the appropriate cloud resources and architecture patterns for your workload?,Evaluate how trade-offs impact customers and architecture efficiency
Performance Efficiency,How do you select the appropriate cloud resources and architecture patterns for your workload?,Use guidance from your cloud provider or an appropriate partner to learn about architecture patterns and best practices
Performance Efficiency,How do you select the appropriate cloud resources and architecture patterns for your workload?,Factor cost into architectural decisions
Performance Efficiency,How do you select the appropriate cloud resources and architecture patterns for your workload?,Use policies and reference architectures
Performance Efficiency,How do you select the appropriate cloud resources and architecture patterns for your workload?,Use benchmarking to drive architectural decisions
Performance Efficiency,How do you select the appropriate cloud resources and architecture patterns for your workload?,Use a data-driven approach for architectural choices
Performance Efficiency,How do you select and use compute resources in your workload?,Select the best compute options for your workload
Performance Efficiency,How do you select and use compute resources in your workload?,Collect compute-related metrics
Performance Efficiency,How do you select and use compute resources in your workload?,Scale your compute resources dynamically
Performance Efficiency,How do you select and use compute resources in your workload?,Understand the available compute configuration and features
Performance Efficiency,How do you select and use compute resources in your workload?,Configure and right-size compute resources
Performance Efficiency,How do you select and use compute resources in your workload?,Use optimized hardware-based compute accelerators
Performance Efficiency,"How do you store, manage, and access data in your workload?",Use purpose-built data store that best support your data access and storage requirements
Performance Efficiency,"How do you store, manage, and access data in your workload?",Collect and record data store performance metrics
Performance Efficiency,"How do you store, manage, and access data in your workload?",Evaluate available configuration options for data store
Performance Efficiency,"How do you store, manage, and access data in your workload?",Implement strategies to improve query performance in data store
Performance Efficiency,"How do you store, manage, and access data in your workload?",Implement data access patterns that utilize caching
Performance Efficiency,How do you select and configure networking resources in your workload?,Understand how networking impacts performance
Performance Efficiency,How do you select and configure networking resources in your workload?,Evaluate available networking features
Performance Efficiency,How do you select and configure networking resources in your workload?,Choose appropriate dedicated connectivity or VPN for your workload
Performance Efficiency,How do you select and configure networking resources in your workload?,Use load balancing to distribute traffic across multiple resources
Performance Efficiency,How do you select and configure networking resources in your workload?,Choose network protocols to improve performance
Performance Efficiency,How do you select and configure networking resources in your workload?,Choose your workload's location based on network requirements
Performance Efficiency,How do you select and configure networking resources in your workload?,Optimize network configuration based on metrics
Performance Efficiency,What process do you use to support more performance efficiency for your workload?,Establish key performance indicators (KPIs) to measure workload health and performance
Performance Efficiency,What process do you use to support more performance efficiency for your workload?,Use monitoring solutions to understand the areas where performance is most critical
Performance Efficiency,What process do you use to support more performance efficiency for your workload?,Define a process to improve workload performance
Performance Efficiency,What process do you use to support more performance efficiency for your workload?,Review metrics at regular intervals
Performance Efficiency,What process do you use to support more performance efficiency for your workload?,Load test your workload
Performance Efficiency,What process do you use to support more performance efficiency for your workload?,Use automation to proactively remediate performance-related issues
Performance Efficiency,What process do you use to support more performance efficiency for your workload?,Keep your workload and services up-to-date
Reliability,How do you manage service quotas and constraints?,Aware of service quotas and constraints
Reliability,How do you manage service quotas and constraints?,Manage service quotas across accounts and Regions
Reliability,How do you manage service quotas and constraints?,Accommodate fixed service quotas and constraints through architecture
Reliability,How do you manage service quotas and constraints?,Monitor and manage quotas
Reliability,How do you manage service quotas and constraints?,Automate quota management
Reliability,How do you manage service quotas and constraints?,Ensure that a sufficient gap exists between the current quotas and the maximum usage to accommodate failover
Reliability,How do you plan your network topology?,Use highly available network connectivity for your workload public endpoints
Reliability,How do you plan your network topology?,Provision redundant connectivity between private networks in the cloud and on-premises environments
Reliability,How do you plan your network topology?,Ensure IP subnet allocation accounts for expansion and availability
Reliability,How do you plan your network topology?,Prefer hub-and-spoke topologies over many-to-many mesh
Reliability,How do you plan your network topology?,Enforce non-overlapping private IP address ranges in all private address spaces where they are connected
Reliability,How do you design your workload service architecture?,Choose how to segment your workload
Reliability,How do you design your workload service architecture?,Build services focused on specific business domains and functionality
Reliability,How do you design your workload service architecture?,Provide service contracts per API
Reliability,How do you design interactions in a distributed system to prevent failures?,Identify the kind of distributed systems you depend on
Reliability,How do you design interactions in a distributed system to prevent failures?,Implement loosely coupled dependencies
Reliability,How do you design interactions in a distributed system to prevent failures?,Make all responses idempotent
Reliability,How do you design interactions in a distributed system to prevent failures?,Do constant work
Reliability,How do you design interactions in a distributed system to mitigate or withstand failures?,Implement graceful degradation to transform applicable hard dependencies into soft dependencies
Reliability,How do you design interactions in a distributed system to mitigate or withstand failures?,Throttle requests
Reliability,How do you design interactions in a distributed system to mitigate or withstand failures?,Control and limit retry calls
Reliability,How do you design interactions in a distributed system to mitigate or withstand failures?,Fail fast and limit queues
Reliability,How do you design interactions in a distributed system to mitigate or withstand failures?,Set client timeouts
Reliability,How do you design interactions in a distributed system to mitigate or withstand failures?,Make systems stateless where possible
Reliability,How do you design interactions in a distributed system to mitigate or withstand failures?,Implement emergency levers
Reliability,How do you monitor workload resources?,Monitor all components for the workload (Generation)
Reliability,How do you monitor workload resources?,Define and calculate metrics (Aggregation)
Reliability,How do you monitor workload resources?,Send notifications (Real-time processing and alarming)
Reliability,How do you monitor workload resources?,Automate responses (Real-time processing and alarming)
Reliability,How do you monitor workload resources?,Analyze logs
Reliability,How do you monitor workload resources?,Conduct reviews regularly
Reliability,How do you monitor workload resources?,Monitor end-to-end tracing of requests through your system
Reliability,How do you design your workload to adapt to changes in demand?,Use automation when obtaining or scaling resources
Reliability,How do you design your workload to adapt to changes in demand?,Obtain resources upon detection of impairment to a workload
Reliability,How do you design your workload to adapt to changes in demand?,Obtain resources upon detection that more resources are needed for a workload
Reliability,How do you design your workload to adapt to changes in demand?,Load test your workload
Reliability,How do you implement change?,Use runbooks for standard activities such as deployment
Reliability,How do you implement change?,Integrate functional testing as part of your deployment
Reliability,How do you implement change?,Integrate resiliency testing as part of your deployment
Reliability,How do you implement change?,Deploy using immutable infrastructure
Reliability,How do you implement change?,Deploy changes with automation
Reliability,How do you back up data?,"Identify and back up all data that needs to be backed up, or reproduce the data from sources"
Reliability,How do you back up data?,Secure and encrypt backups
Reliability,How do you back up data?,Perform data backup automatically
Reliability,How do you back up data?,Perform periodic recovery of the data to verify backup integrity and processes
Reliability,How do you use fault isolation to protect your workload?,Deploy the workload to multiple locations
Reliability,How do you use fault isolation to protect your workload?,Select the appropriate locations for your multi-location deployment
Reliability,How do you use fault isolation to protect your workload?,Use bulkhead architectures to limit scope of impact
Reliability,How do you use fault isolation to protect your workload?,Automate recovery for components constrained to a single location
Reliability,How do you design your workload to withstand component failures?,Monitor all components of the workload to detect failures
Reliability,How do you design your workload to withstand component failures?,Fail over to healthy resources
Reliability,How do you design your workload to withstand component failures?,Automate healing on all layers
Reliability,How do you design your workload to withstand component failures?,Rely on the data plane and not the control plane during recovery
Reliability,How do you design your workload to withstand component failures?,Use static stability to prevent bimodal behavior
Reliability,How do you design your workload to withstand component failures?,Send notifications when events impact availability
Reliability,How do you design your workload to withstand component failures?,Architect your product to meet availability targets and uptime service level agreements (SLAs)
Reliability,How do you test reliability?,Use playbooks to investigate failures
Reliability,How do you test reliability?,Perform post-incident analysis
Reliability,How do you test reliability?,Test functional requirements
Reliability,How do you test reliability?,Test scaling and performance requirements
Reliability,How do you test reliability?,Test resiliency using chaos engineering
Reliability,How do you test reliability?,Conduct game days regularly
Reliability,How do you plan for disaster recovery (DR)?,Define recovery objectives for downtime and data loss
Reliability,How do you plan for disaster recovery (DR)?,Use defined recovery strategies to meet the recovery objectives
Reliability,How do you plan for disaster recovery (DR)?,Test disaster recovery implementation to validate the implementation
Reliability,How do you plan for disaster recovery (DR)?,Manage configuration drift at the DR site or Region
Reliability,How do you plan for disaster recovery (DR)?,Automate recovery
Security,How do you securely operate your workload?,Separate workloads using accounts
Security,How do you securely operate your workload?,Secure account root user and properties
Security,How do you securely operate your workload?,Identify and validate control objectives
Security,How do you securely operate your workload?,Stay up to date with security threats and recommendations
Security,How do you securely operate your workload?,Identify and prioritize risks using a threat model
Security,How do you securely operate your workload?,Reduce security management scope
Security,How do you securely operate your workload?,Automate deployment of standard security controls
Security,How do you securely operate your workload?,Evaluate and implement new security services and features regularly
Security,How do you manage identities for people and machines?,Use strong sign-in mechanisms
Security,How do you manage identities for people and machines?,Use temporary credentials
Security,How do you manage identities for people and machines?,Store and use secrets securely
Security,How do you manage identities for people and machines?,Rely on a centralized identity provider
Security,How do you manage identities for people and machines?,Audit and rotate credentials periodically
Security,How do you manage identities for people and machines?,Employ user groups and attributes
Security,How do you manage permissions for people and machines?,Define access requirements
Security,How do you manage permissions for people and machines?,Grant least privilege access
Security,How do you manage permissions for people and machines?,Define permission guardrails for your organization
Security,How do you manage permissions for people and machines?,Manage access based on lifecycle
Security,How do you manage permissions for people and machines?,Establish emergency access process
Security,How do you manage permissions for people and machines?,Share resources securely within your organization
Security,How do you manage permissions for people and machines?,Reduce permissions continuously
Security,How do you manage permissions for people and machines?,Share resources securely with a third party
Security,How do you manage permissions for people and machines?,Analyze public and cross account access
Security,How do you detect and investigate security events?,Configure service and application logging
Security,How do you detect and investigate security events?,"Capture logs, findings, and metrics in standardized locations"
Security,How do you detect and investigate security events?,Initiate remediation for non-compliant resources
Security,How do you detect and investigate security events?,Correlate and enrich security events
Security,How do you protect your network resources?,Create network layers
Security,How do you protect your network resources?,Control traffic within your network layers
Security,How do you protect your network resources?,Implement inspection-based protection
Security,How do you protect your network resources?,Automate network protection
Security,How do you protect your compute resources?,Perform vulnerability management
Security,How do you protect your compute resources?,Provision compute from hardened images
Security,How do you protect your compute resources?,Validate software integrity
Security,How do you protect your compute resources?,Reduce manual management and interactive access
Security,How do you protect your compute resources?,Automate compute protection
Security,How do you classify your data?,Understand your data classification scheme
Security,How do you classify your data?,Apply data protection controls based on data sensitivity
Security,How do you classify your data?,Define scalable data lifecycle management
Security,How do you classify your data?,Automate identification and classification
Security,How do you protect your data at rest?,Implement secure key management
Security,How do you protect your data at rest?,Enforce encryption at rest
Security,How do you protect your data at rest?,Automate data at rest protection
Security,How do you protect your data at rest?,Enforce access control
Security,How do you protect your data in transit?,Implement secure key and certificate management
Security,How do you protect your data in transit?,Enforce encryption in transit
Security,How do you protect your data in transit?,Authenticate network communications
Security,"How do you anticipate, respond to, and recover from incidents?",Identify key personnel and external resources
Security,"How do you anticipate, respond to, and recover from incidents?",Develop incident management plans
Security,"How do you anticipate, respond to, and recover from incidents?",Prepare forensic capabilities
Security,"How do you anticipate, respond to, and recover from incidents?",Develop and test security incident response playbooks
Security,"How do you anticipate, respond to, and recover from incidents?",Pre-provision access
Security,"How do you anticipate, respond to, and recover from incidents?",Run simulations
Security,"How do you anticipate, respond to, and recover from incidents?",Establish a framework for learning from incidents
Security,"How do you anticipate, respond to, and recover from incidents?",Pre-deploy tools
Security,"How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",Perform regular penetration testing
Security,"How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",Deploy software programmatically
Security,"How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",Regularly assess security properties of the pipelines
Security,"How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",Train for application security
Security,"How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",Automate testing throughout the development and release lifecycle
Security,"How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",Manual code reviews
Security,"How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",Centralize services for packages and dependencies
Security,"How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",Build a program that embeds security ownership in workload teams
Sustainability,How do you select Regions for your workload?,Choose Region based on both business requirements and sustainability goals
Sustainability,How do you align cloud resources to your demand?,Scale workload infrastructure dynamically
Sustainability,How do you align cloud resources to your demand?,Align SLAs with sustainability goals
Sustainability,How do you align cloud resources to your demand?,Optimize geographic placement of workloads based on their networking requirements
Sustainability,How do you align cloud resources to your demand?,Stop the creation and maintenance of unused assets
Sustainability,How do you align cloud resources to your demand?,Optimize team member resources for activities performed
Sustainability,How do you align cloud resources to your demand?,Implement buffering or throttling to flatten the demand curve
Sustainability,How do you take advantage of software and architecture patterns to support your sustainability goals?,Optimize software and architecture for asynchronous and scheduled jobs
Sustainability,How do you take advantage of software and architecture patterns to support your sustainability goals?,Remove or refactor workload components with low or no use
Sustainability,How do you take advantage of software and architecture patterns to support your sustainability goals?,Optimize areas of code that consume the most time or resources
Sustainability,How do you take advantage of software and architecture patterns to support your sustainability goals?,Optimize impact on devices and equipment
Sustainability,How do you take advantage of software and architecture patterns to support your sustainability goals?,Use software patterns and architectures that best support data access and storage patterns
Sustainability,How do you take advantage of data management policies and patterns to support your sustainability goals?,Implement a data classification policy
Sustainability,How do you take advantage of data management policies and patterns to support your sustainability goals?,Use technologies that support data access and storage patterns
Sustainability,How do you take advantage of data management policies and patterns to support your sustainability goals?,Use policies to manage the lifecycle of your datasets
Sustainability,How do you take advantage of data management policies and patterns to support your sustainability goals?,Remove unneeded or redundant data
Sustainability,How do you take advantage of data management policies and patterns to support your sustainability goals?,Use shared file systems or storage to access common data
Sustainability,How do you take advantage of data management policies and patterns to support your sustainability goals?,Back up data only when difficult to recreate
Sustainability,How do you take advantage of data management policies and patterns to support your sustainability goals?,Use elasticity and automation to expand block storage or file system
Sustainability,How do you take advantage of data management policies and patterns to support your sustainability goals?,Minimize data movement across networks
Sustainability,How do you select and use cloud hardware and services in your architecture to support your sustainability goals?,Use the minimum amount of hardware to meet your needs
Sustainability,How do you select and use cloud hardware and services in your architecture to support your sustainability goals?,Use instance types with the least impact
Sustainability,How do you select and use cloud hardware and services in your architecture to support your sustainability goals?,Use managed services
Sustainability,How do you select and use cloud hardware and services in your architecture to support your sustainability goals?,Optimize your use of hardware-based compute accelerators
Sustainability,How do your organizational processes support your sustainability goals?,Adopt methods that can rapidly introduce sustainability improvements
Sustainability,How do your organizational processes support your sustainability goals?,Keep your workload up-to-date
Sustainability,How do your organizational processes support your sustainability goals?,Increase utilization of build environments
Sustainability,How do your organizational processes support your sustainability goals?,Use managed device farms for testing
</file>

<file path="ecs_fargate_app/well_architected_docs/well_architected_best_practices.json">
[
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you implement cloud financial management?",
    "Best Practice": "Establish ownership of cost optimization"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you implement cloud financial management?",
    "Best Practice": "Establish a partnership between finance and technology"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you implement cloud financial management?",
    "Best Practice": "Establish cloud budgets and forecasts"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you implement cloud financial management?",
    "Best Practice": "Implement cost awareness in your organizational processes"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you implement cloud financial management?",
    "Best Practice": "Monitor cost proactively"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you implement cloud financial management?",
    "Best Practice": "Keep up-to-date with new service releases"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you implement cloud financial management?",
    "Best Practice": "Quantify business value from cost optimization"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you implement cloud financial management?",
    "Best Practice": "Report and notify on cost optimization"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you implement cloud financial management?",
    "Best Practice": "Create a cost-aware culture"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you govern usage?",
    "Best Practice": "Develop policies based on your organization requirements"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you govern usage?",
    "Best Practice": "Implement goals and targets"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you govern usage?",
    "Best Practice": "Implement an account structure"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you govern usage?",
    "Best Practice": "Implement cost controls"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you govern usage?",
    "Best Practice": "Implement groups and role"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you govern usage?",
    "Best Practice": "Track project lifecycle"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you monitor your cost and usage?",
    "Best Practice": "Configure detailed information sources"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you monitor your cost and usage?",
    "Best Practice": "Identify cost attribution categories"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you monitor your cost and usage?",
    "Best Practice": "Establish organization metrics"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you monitor your cost and usage?",
    "Best Practice": "Configure billing and cost management tools"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you monitor your cost and usage?",
    "Best Practice": "Add organization information to cost and usage"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you monitor your cost and usage?",
    "Best Practice": "Allocate costs based on workload metrics"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you decommission resources?",
    "Best Practice": "Track resources over their life time"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you decommission resources?",
    "Best Practice": "Implement a decommissioning process"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you decommission resources?",
    "Best Practice": "Decommission resources"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you decommission resources?",
    "Best Practice": "Enforce data retention policies"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you decommission resources?",
    "Best Practice": "Decommission resources automatically"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you evaluate cost when you select services?",
    "Best Practice": "Identify organization requirements for cost"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you evaluate cost when you select services?",
    "Best Practice": "Analyze all components of this workload"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you evaluate cost when you select services?",
    "Best Practice": "Perform a thorough analysis of each component"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you evaluate cost when you select services?",
    "Best Practice": "Select components of this workload to optimize cost in line with organization priorities"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you evaluate cost when you select services?",
    "Best Practice": "Perform cost analysis for different usage over time"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you evaluate cost when you select services?",
    "Best Practice": "Select software with cost effective licensing"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you meet cost targets when you select resource type, size and number?",
    "Best Practice": "Perform cost modeling"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you meet cost targets when you select resource type, size and number?",
    "Best Practice": "Select resource type, size, and number based on data"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you meet cost targets when you select resource type, size and number?",
    "Best Practice": "Consider using shared resources"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you meet cost targets when you select resource type, size and number?",
    "Best Practice": "Select resource type, size, and number automatically based on metrics"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you use pricing models to reduce cost?",
    "Best Practice": "Perform pricing model analysis"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you use pricing models to reduce cost?",
    "Best Practice": "Choose Regions based on cost"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you use pricing models to reduce cost?",
    "Best Practice": "Select third-party agreements with cost-efficient terms"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you use pricing models to reduce cost?",
    "Best Practice": "Implement pricing models for all components of this workload"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you use pricing models to reduce cost?",
    "Best Practice": "Perform pricing model analysis at the management account level"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you plan for data transfer charges?",
    "Best Practice": "Perform data transfer modeling"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you plan for data transfer charges?",
    "Best Practice": "Select components to optimize data transfer cost"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you plan for data transfer charges?",
    "Best Practice": "Implement services to reduce data transfer costs"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you manage demand, and supply resources?",
    "Best Practice": "Perform an analysis on the workload demand"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you manage demand, and supply resources?",
    "Best Practice": "Implement a buffer or throttle to manage demand"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you manage demand, and supply resources?",
    "Best Practice": "Supply resources dynamically"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you evaluate new services?",
    "Best Practice": "Develop a workload review process"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you evaluate new services?",
    "Best Practice": "Review and analyze this workload regularly"
  },
  {
    "Pillar": "Cost Optimization",
    "Question": "How do you evaluate the cost of effort?",
    "Best Practice": "Perform automation for operations"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you determine what your priorities are?",
    "Best Practice": "Evaluate customer needs"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you determine what your priorities are?",
    "Best Practice": "Evaluate internal customer needs"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you determine what your priorities are?",
    "Best Practice": "Evaluate governance requirements"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you determine what your priorities are?",
    "Best Practice": "Evaluate compliance requirements"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you determine what your priorities are?",
    "Best Practice": "Evaluate threat landscape"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you determine what your priorities are?",
    "Best Practice": "Evaluate tradeoffs while managing benefits and risks"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you structure your organization to support your business outcomes?",
    "Best Practice": "Resources have identified owners"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you structure your organization to support your business outcomes?",
    "Best Practice": "Processes and procedures have identified owners"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you structure your organization to support your business outcomes?",
    "Best Practice": "Operations activities have identified owners responsible for their performance"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you structure your organization to support your business outcomes?",
    "Best Practice": "Mechanisms exist to manage responsibilities and ownership"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you structure your organization to support your business outcomes?",
    "Best Practice": "Mechanisms exist to request additions, changes, and exceptions"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you structure your organization to support your business outcomes?",
    "Best Practice": "Responsibilities between teams are predefined or negotiated"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How does your organizational culture support your business outcomes?",
    "Best Practice": "Provide executive sponsorship"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How does your organizational culture support your business outcomes?",
    "Best Practice": "Escalation is encouraged"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How does your organizational culture support your business outcomes?",
    "Best Practice": "Communications are timely, clear, and actionable"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How does your organizational culture support your business outcomes?",
    "Best Practice": "Team members are empowered to take action when outcomes are at risk"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How does your organizational culture support your business outcomes?",
    "Best Practice": "Experimentation is encouraged"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How does your organizational culture support your business outcomes?",
    "Best Practice": "Team members are encouraged to maintain and grow their skill sets"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How does your organizational culture support your business outcomes?",
    "Best Practice": "Resource teams appropriately"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you implement observability in your workload?",
    "Best Practice": "Identify key performance indicators"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you implement observability in your workload?",
    "Best Practice": "Implement application telemetry"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you implement observability in your workload?",
    "Best Practice": "Implement user experience telemetry"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you implement observability in your workload?",
    "Best Practice": "Implement dependency telemetry"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you implement observability in your workload?",
    "Best Practice": "Implement distributed tracing"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Use version control"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Test and validate changes"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Use configuration management systems"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Use build and deployment management systems"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Perform patch management"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Share design standards"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Implement practices to improve code quality"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Use multiple environments"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Make frequent, small, reversible changes"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you reduce defects, ease remediation, and improve flow into production?",
    "Best Practice": "Fully automate integration and deployment"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you mitigate deployment risks?",
    "Best Practice": "Plan for unsuccessful changes"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you mitigate deployment risks?",
    "Best Practice": "Test deployments"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you mitigate deployment risks?",
    "Best Practice": "Employ safe deployment strategies"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you mitigate deployment risks?",
    "Best Practice": "Automate testing and rollback"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you know that you are ready to support a workload?",
    "Best Practice": "Ensure personnel capability"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you know that you are ready to support a workload?",
    "Best Practice": "Ensure a consistent review of operational readiness"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you know that you are ready to support a workload?",
    "Best Practice": "Use runbooks to perform procedures"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you know that you are ready to support a workload?",
    "Best Practice": "Use playbooks to investigate issues"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you know that you are ready to support a workload?",
    "Best Practice": "Make informed decisions to deploy systems and changes"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you know that you are ready to support a workload?",
    "Best Practice": "Create support plans for production workloads"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you utilize workload observability in your organization?",
    "Best Practice": "Create actionable alerts"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you utilize workload observability in your organization?",
    "Best Practice": "Analyze workload metrics"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you utilize workload observability in your organization?",
    "Best Practice": "Analyze workload logs"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you utilize workload observability in your organization?",
    "Best Practice": "Analyze workload traces"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you utilize workload observability in your organization?",
    "Best Practice": "Create dashboards"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you understand the health of your operations?",
    "Best Practice": "Measure operations goals and KPIs with metrics"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you understand the health of your operations?",
    "Best Practice": "Communicate status and trends to ensure visibility into operation"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you understand the health of your operations?",
    "Best Practice": "Review operations metrics and prioritize improvement"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you manage workload and operations events?",
    "Best Practice": "Use a process for event, incident, and problem management"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you manage workload and operations events?",
    "Best Practice": "Have a process per alert"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you manage workload and operations events?",
    "Best Practice": "Prioritize operational events based on business impact"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you manage workload and operations events?",
    "Best Practice": "Define escalation paths"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you manage workload and operations events?",
    "Best Practice": "Define a customer communication plan for service-impacting events"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you manage workload and operations events?",
    "Best Practice": "Communicate status through dashboards"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you manage workload and operations events?",
    "Best Practice": "Automate responses to events"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you evolve operations?",
    "Best Practice": "Have a process for continuous improvement"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you evolve operations?",
    "Best Practice": "Perform post-incident analysis"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you evolve operations?",
    "Best Practice": "Implement feedback loops"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you evolve operations?",
    "Best Practice": "Perform knowledge management"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you evolve operations?",
    "Best Practice": "Define drivers for improvement"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you evolve operations?",
    "Best Practice": "Validate insights"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you evolve operations?",
    "Best Practice": "Perform operations metrics reviews"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you evolve operations?",
    "Best Practice": "Document and share lessons learned"
  },
  {
    "Pillar": "Operational Excellence",
    "Question": "How do you evolve operations?",
    "Best Practice": "Allocate time to make improvements"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select the appropriate cloud resources and architecture patterns for your workload?",
    "Best Practice": "Learn about and understand available cloud services and features"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select the appropriate cloud resources and architecture patterns for your workload?",
    "Best Practice": "Evaluate how trade-offs impact customers and architecture efficiency"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select the appropriate cloud resources and architecture patterns for your workload?",
    "Best Practice": "Use guidance from your cloud provider or an appropriate partner to learn about architecture patterns and best practices"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select the appropriate cloud resources and architecture patterns for your workload?",
    "Best Practice": "Factor cost into architectural decisions"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select the appropriate cloud resources and architecture patterns for your workload?",
    "Best Practice": "Use policies and reference architectures"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select the appropriate cloud resources and architecture patterns for your workload?",
    "Best Practice": "Use benchmarking to drive architectural decisions"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select the appropriate cloud resources and architecture patterns for your workload?",
    "Best Practice": "Use a data-driven approach for architectural choices"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and use compute resources in your workload?",
    "Best Practice": "Select the best compute options for your workload"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and use compute resources in your workload?",
    "Best Practice": "Collect compute-related metrics"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and use compute resources in your workload?",
    "Best Practice": "Scale your compute resources dynamically"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and use compute resources in your workload?",
    "Best Practice": "Understand the available compute configuration and features"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and use compute resources in your workload?",
    "Best Practice": "Configure and right-size compute resources"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and use compute resources in your workload?",
    "Best Practice": "Use optimized hardware-based compute accelerators"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you store, manage, and access data in your workload?",
    "Best Practice": "Use purpose-built data store that best support your data access and storage requirements"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you store, manage, and access data in your workload?",
    "Best Practice": "Collect and record data store performance metrics"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you store, manage, and access data in your workload?",
    "Best Practice": "Evaluate available configuration options for data store"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you store, manage, and access data in your workload?",
    "Best Practice": "Implement strategies to improve query performance in data store"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you store, manage, and access data in your workload?",
    "Best Practice": "Implement data access patterns that utilize caching"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and configure networking resources in your workload?",
    "Best Practice": "Understand how networking impacts performance"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and configure networking resources in your workload?",
    "Best Practice": "Evaluate available networking features"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and configure networking resources in your workload?",
    "Best Practice": "Choose appropriate dedicated connectivity or VPN for your workload"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and configure networking resources in your workload?",
    "Best Practice": "Use load balancing to distribute traffic across multiple resources"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and configure networking resources in your workload?",
    "Best Practice": "Choose network protocols to improve performance"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and configure networking resources in your workload?",
    "Best Practice": "Choose your workload's location based on network requirements"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "How do you select and configure networking resources in your workload?",
    "Best Practice": "Optimize network configuration based on metrics"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "What process do you use to support more performance efficiency for your workload?",
    "Best Practice": "Establish key performance indicators (KPIs) to measure workload health and performance"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "What process do you use to support more performance efficiency for your workload?",
    "Best Practice": "Use monitoring solutions to understand the areas where performance is most critical"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "What process do you use to support more performance efficiency for your workload?",
    "Best Practice": "Define a process to improve workload performance"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "What process do you use to support more performance efficiency for your workload?",
    "Best Practice": "Review metrics at regular intervals"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "What process do you use to support more performance efficiency for your workload?",
    "Best Practice": "Load test your workload"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "What process do you use to support more performance efficiency for your workload?",
    "Best Practice": "Use automation to proactively remediate performance-related issues"
  },
  {
    "Pillar": "Performance Efficiency",
    "Question": "What process do you use to support more performance efficiency for your workload?",
    "Best Practice": "Keep your workload and services up-to-date"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you manage service quotas and constraints?",
    "Best Practice": "Aware of service quotas and constraints"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you manage service quotas and constraints?",
    "Best Practice": "Manage service quotas across accounts and Regions"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you manage service quotas and constraints?",
    "Best Practice": "Accommodate fixed service quotas and constraints through architecture"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you manage service quotas and constraints?",
    "Best Practice": "Monitor and manage quotas"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you manage service quotas and constraints?",
    "Best Practice": "Automate quota management"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you manage service quotas and constraints?",
    "Best Practice": "Ensure that a sufficient gap exists between the current quotas and the maximum usage to accommodate failover"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan your network topology?",
    "Best Practice": "Use highly available network connectivity for your workload public endpoints"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan your network topology?",
    "Best Practice": "Provision redundant connectivity between private networks in the cloud and on-premises environments"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan your network topology?",
    "Best Practice": "Ensure IP subnet allocation accounts for expansion and availability"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan your network topology?",
    "Best Practice": "Prefer hub-and-spoke topologies over many-to-many mesh"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan your network topology?",
    "Best Practice": "Enforce non-overlapping private IP address ranges in all private address spaces where they are connected"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload service architecture?",
    "Best Practice": "Choose how to segment your workload"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload service architecture?",
    "Best Practice": "Build services focused on specific business domains and functionality"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload service architecture?",
    "Best Practice": "Provide service contracts per API"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to prevent failures?",
    "Best Practice": "Identify the kind of distributed systems you depend on"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to prevent failures?",
    "Best Practice": "Implement loosely coupled dependencies"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to prevent failures?",
    "Best Practice": "Make all responses idempotent"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to prevent failures?",
    "Best Practice": "Do constant work"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to mitigate or withstand failures?",
    "Best Practice": "Implement graceful degradation to transform applicable hard dependencies into soft dependencies"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to mitigate or withstand failures?",
    "Best Practice": "Throttle requests"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to mitigate or withstand failures?",
    "Best Practice": "Control and limit retry calls"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to mitigate or withstand failures?",
    "Best Practice": "Fail fast and limit queues"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to mitigate or withstand failures?",
    "Best Practice": "Set client timeouts"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to mitigate or withstand failures?",
    "Best Practice": "Make systems stateless where possible"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design interactions in a distributed system to mitigate or withstand failures?",
    "Best Practice": "Implement emergency levers"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you monitor workload resources?",
    "Best Practice": "Monitor all components for the workload (Generation)"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you monitor workload resources?",
    "Best Practice": "Define and calculate metrics (Aggregation)"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you monitor workload resources?",
    "Best Practice": "Send notifications (Real-time processing and alarming)"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you monitor workload resources?",
    "Best Practice": "Automate responses (Real-time processing and alarming)"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you monitor workload resources?",
    "Best Practice": "Analyze logs"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you monitor workload resources?",
    "Best Practice": "Conduct reviews regularly"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you monitor workload resources?",
    "Best Practice": "Monitor end-to-end tracing of requests through your system"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to adapt to changes in demand?",
    "Best Practice": "Use automation when obtaining or scaling resources"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to adapt to changes in demand?",
    "Best Practice": "Obtain resources upon detection of impairment to a workload"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to adapt to changes in demand?",
    "Best Practice": "Obtain resources upon detection that more resources are needed for a workload"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to adapt to changes in demand?",
    "Best Practice": "Load test your workload"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you implement change?",
    "Best Practice": "Use runbooks for standard activities such as deployment"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you implement change?",
    "Best Practice": "Integrate functional testing as part of your deployment"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you implement change?",
    "Best Practice": "Integrate resiliency testing as part of your deployment"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you implement change?",
    "Best Practice": "Deploy using immutable infrastructure"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you implement change?",
    "Best Practice": "Deploy changes with automation"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you back up data?",
    "Best Practice": "Identify and back up all data that needs to be backed up, or reproduce the data from sources"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you back up data?",
    "Best Practice": "Secure and encrypt backups"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you back up data?",
    "Best Practice": "Perform data backup automatically"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you back up data?",
    "Best Practice": "Perform periodic recovery of the data to verify backup integrity and processes"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you use fault isolation to protect your workload?",
    "Best Practice": "Deploy the workload to multiple locations"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you use fault isolation to protect your workload?",
    "Best Practice": "Select the appropriate locations for your multi-location deployment"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you use fault isolation to protect your workload?",
    "Best Practice": "Use bulkhead architectures to limit scope of impact"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you use fault isolation to protect your workload?",
    "Best Practice": "Automate recovery for components constrained to a single location"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to withstand component failures?",
    "Best Practice": "Monitor all components of the workload to detect failures"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to withstand component failures?",
    "Best Practice": "Fail over to healthy resources"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to withstand component failures?",
    "Best Practice": "Automate healing on all layers"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to withstand component failures?",
    "Best Practice": "Rely on the data plane and not the control plane during recovery"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to withstand component failures?",
    "Best Practice": "Use static stability to prevent bimodal behavior"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to withstand component failures?",
    "Best Practice": "Send notifications when events impact availability"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you design your workload to withstand component failures?",
    "Best Practice": "Architect your product to meet availability targets and uptime service level agreements (SLAs)"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you test reliability?",
    "Best Practice": "Use playbooks to investigate failures"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you test reliability?",
    "Best Practice": "Perform post-incident analysis"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you test reliability?",
    "Best Practice": "Test functional requirements"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you test reliability?",
    "Best Practice": "Test scaling and performance requirements"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you test reliability?",
    "Best Practice": "Test resiliency using chaos engineering"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you test reliability?",
    "Best Practice": "Conduct game days regularly"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan for disaster recovery (DR)?",
    "Best Practice": "Define recovery objectives for downtime and data loss"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan for disaster recovery (DR)?",
    "Best Practice": "Use defined recovery strategies to meet the recovery objectives"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan for disaster recovery (DR)?",
    "Best Practice": "Test disaster recovery implementation to validate the implementation"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan for disaster recovery (DR)?",
    "Best Practice": "Manage configuration drift at the DR site or Region"
  },
  {
    "Pillar": "Reliability",
    "Question": "How do you plan for disaster recovery (DR)?",
    "Best Practice": "Automate recovery"
  },
  {
    "Pillar": "Security",
    "Question": "How do you securely operate your workload?",
    "Best Practice": "Separate workloads using accounts"
  },
  {
    "Pillar": "Security",
    "Question": "How do you securely operate your workload?",
    "Best Practice": "Secure account root user and properties"
  },
  {
    "Pillar": "Security",
    "Question": "How do you securely operate your workload?",
    "Best Practice": "Identify and validate control objectives"
  },
  {
    "Pillar": "Security",
    "Question": "How do you securely operate your workload?",
    "Best Practice": "Stay up to date with security threats and recommendations"
  },
  {
    "Pillar": "Security",
    "Question": "How do you securely operate your workload?",
    "Best Practice": "Identify and prioritize risks using a threat model"
  },
  {
    "Pillar": "Security",
    "Question": "How do you securely operate your workload?",
    "Best Practice": "Reduce security management scope"
  },
  {
    "Pillar": "Security",
    "Question": "How do you securely operate your workload?",
    "Best Practice": "Automate deployment of standard security controls"
  },
  {
    "Pillar": "Security",
    "Question": "How do you securely operate your workload?",
    "Best Practice": "Evaluate and implement new security services and features regularly"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage identities for people and machines?",
    "Best Practice": "Use strong sign-in mechanisms"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage identities for people and machines?",
    "Best Practice": "Use temporary credentials"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage identities for people and machines?",
    "Best Practice": "Store and use secrets securely"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage identities for people and machines?",
    "Best Practice": "Rely on a centralized identity provider"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage identities for people and machines?",
    "Best Practice": "Audit and rotate credentials periodically"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage identities for people and machines?",
    "Best Practice": "Employ user groups and attributes"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage permissions for people and machines?",
    "Best Practice": "Define access requirements"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage permissions for people and machines?",
    "Best Practice": "Grant least privilege access"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage permissions for people and machines?",
    "Best Practice": "Define permission guardrails for your organization"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage permissions for people and machines?",
    "Best Practice": "Manage access based on lifecycle"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage permissions for people and machines?",
    "Best Practice": "Establish emergency access process"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage permissions for people and machines?",
    "Best Practice": "Share resources securely within your organization"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage permissions for people and machines?",
    "Best Practice": "Reduce permissions continuously"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage permissions for people and machines?",
    "Best Practice": "Share resources securely with a third party"
  },
  {
    "Pillar": "Security",
    "Question": "How do you manage permissions for people and machines?",
    "Best Practice": "Analyze public and cross account access"
  },
  {
    "Pillar": "Security",
    "Question": "How do you detect and investigate security events?",
    "Best Practice": "Configure service and application logging"
  },
  {
    "Pillar": "Security",
    "Question": "How do you detect and investigate security events?",
    "Best Practice": "Capture logs, findings, and metrics in standardized locations"
  },
  {
    "Pillar": "Security",
    "Question": "How do you detect and investigate security events?",
    "Best Practice": "Initiate remediation for non-compliant resources"
  },
  {
    "Pillar": "Security",
    "Question": "How do you detect and investigate security events?",
    "Best Practice": "Correlate and enrich security events"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your network resources?",
    "Best Practice": "Create network layers"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your network resources?",
    "Best Practice": "Control traffic within your network layers"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your network resources?",
    "Best Practice": "Implement inspection-based protection"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your network resources?",
    "Best Practice": "Automate network protection"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your compute resources?",
    "Best Practice": "Perform vulnerability management"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your compute resources?",
    "Best Practice": "Provision compute from hardened images"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your compute resources?",
    "Best Practice": "Validate software integrity"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your compute resources?",
    "Best Practice": "Reduce manual management and interactive access"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your compute resources?",
    "Best Practice": "Automate compute protection"
  },
  {
    "Pillar": "Security",
    "Question": "How do you classify your data?",
    "Best Practice": "Understand your data classification scheme"
  },
  {
    "Pillar": "Security",
    "Question": "How do you classify your data?",
    "Best Practice": "Apply data protection controls based on data sensitivity"
  },
  {
    "Pillar": "Security",
    "Question": "How do you classify your data?",
    "Best Practice": "Define scalable data lifecycle management"
  },
  {
    "Pillar": "Security",
    "Question": "How do you classify your data?",
    "Best Practice": "Automate identification and classification"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your data at rest?",
    "Best Practice": "Implement secure key management"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your data at rest?",
    "Best Practice": "Enforce encryption at rest"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your data at rest?",
    "Best Practice": "Automate data at rest protection"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your data at rest?",
    "Best Practice": "Enforce access control"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your data in transit?",
    "Best Practice": "Implement secure key and certificate management"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your data in transit?",
    "Best Practice": "Enforce encryption in transit"
  },
  {
    "Pillar": "Security",
    "Question": "How do you protect your data in transit?",
    "Best Practice": "Authenticate network communications"
  },
  {
    "Pillar": "Security",
    "Question": "How do you anticipate, respond to, and recover from incidents?",
    "Best Practice": "Identify key personnel and external resources"
  },
  {
    "Pillar": "Security",
    "Question": "How do you anticipate, respond to, and recover from incidents?",
    "Best Practice": "Develop incident management plans"
  },
  {
    "Pillar": "Security",
    "Question": "How do you anticipate, respond to, and recover from incidents?",
    "Best Practice": "Prepare forensic capabilities"
  },
  {
    "Pillar": "Security",
    "Question": "How do you anticipate, respond to, and recover from incidents?",
    "Best Practice": "Develop and test security incident response playbooks"
  },
  {
    "Pillar": "Security",
    "Question": "How do you anticipate, respond to, and recover from incidents?",
    "Best Practice": "Pre-provision access"
  },
  {
    "Pillar": "Security",
    "Question": "How do you anticipate, respond to, and recover from incidents?",
    "Best Practice": "Run simulations"
  },
  {
    "Pillar": "Security",
    "Question": "How do you anticipate, respond to, and recover from incidents?",
    "Best Practice": "Establish a framework for learning from incidents"
  },
  {
    "Pillar": "Security",
    "Question": "How do you anticipate, respond to, and recover from incidents?",
    "Best Practice": "Pre-deploy tools"
  },
  {
    "Pillar": "Security",
    "Question": "How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",
    "Best Practice": "Perform regular penetration testing"
  },
  {
    "Pillar": "Security",
    "Question": "How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",
    "Best Practice": "Deploy software programmatically"
  },
  {
    "Pillar": "Security",
    "Question": "How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",
    "Best Practice": "Regularly assess security properties of the pipelines"
  },
  {
    "Pillar": "Security",
    "Question": "How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",
    "Best Practice": "Train for application security"
  },
  {
    "Pillar": "Security",
    "Question": "How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",
    "Best Practice": "Automate testing throughout the development and release lifecycle"
  },
  {
    "Pillar": "Security",
    "Question": "How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",
    "Best Practice": "Manual code reviews"
  },
  {
    "Pillar": "Security",
    "Question": "How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",
    "Best Practice": "Centralize services for packages and dependencies"
  },
  {
    "Pillar": "Security",
    "Question": "How do you incorporate and validate the security properties of applications throughout the design, development, and deployment lifecycle?",
    "Best Practice": "Build a program that embeds security ownership in workload teams"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you select Regions for your workload?",
    "Best Practice": "Choose Region based on both business requirements and sustainability goals"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you align cloud resources to your demand?",
    "Best Practice": "Scale workload infrastructure dynamically"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you align cloud resources to your demand?",
    "Best Practice": "Align SLAs with sustainability goals"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you align cloud resources to your demand?",
    "Best Practice": "Optimize geographic placement of workloads based on their networking requirements"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you align cloud resources to your demand?",
    "Best Practice": "Stop the creation and maintenance of unused assets"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you align cloud resources to your demand?",
    "Best Practice": "Optimize team member resources for activities performed"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you align cloud resources to your demand?",
    "Best Practice": "Implement buffering or throttling to flatten the demand curve"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of software and architecture patterns to support your sustainability goals?",
    "Best Practice": "Optimize software and architecture for asynchronous and scheduled jobs"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of software and architecture patterns to support your sustainability goals?",
    "Best Practice": "Remove or refactor workload components with low or no use"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of software and architecture patterns to support your sustainability goals?",
    "Best Practice": "Optimize areas of code that consume the most time or resources"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of software and architecture patterns to support your sustainability goals?",
    "Best Practice": "Optimize impact on devices and equipment"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of software and architecture patterns to support your sustainability goals?",
    "Best Practice": "Use software patterns and architectures that best support data access and storage patterns"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of data management policies and patterns to support your sustainability goals?",
    "Best Practice": "Implement a data classification policy"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of data management policies and patterns to support your sustainability goals?",
    "Best Practice": "Use technologies that support data access and storage patterns"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of data management policies and patterns to support your sustainability goals?",
    "Best Practice": "Use policies to manage the lifecycle of your datasets"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of data management policies and patterns to support your sustainability goals?",
    "Best Practice": "Remove unneeded or redundant data"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of data management policies and patterns to support your sustainability goals?",
    "Best Practice": "Use shared file systems or storage to access common data"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of data management policies and patterns to support your sustainability goals?",
    "Best Practice": "Back up data only when difficult to recreate"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of data management policies and patterns to support your sustainability goals?",
    "Best Practice": "Use elasticity and automation to expand block storage or file system"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you take advantage of data management policies and patterns to support your sustainability goals?",
    "Best Practice": "Minimize data movement across networks"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you select and use cloud hardware and services in your architecture to support your sustainability goals?",
    "Best Practice": "Use the minimum amount of hardware to meet your needs"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you select and use cloud hardware and services in your architecture to support your sustainability goals?",
    "Best Practice": "Use instance types with the least impact"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you select and use cloud hardware and services in your architecture to support your sustainability goals?",
    "Best Practice": "Use managed services"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do you select and use cloud hardware and services in your architecture to support your sustainability goals?",
    "Best Practice": "Optimize your use of hardware-based compute accelerators"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do your organizational processes support your sustainability goals?",
    "Best Practice": "Adopt methods that can rapidly introduce sustainability improvements"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do your organizational processes support your sustainability goals?",
    "Best Practice": "Keep your workload up-to-date"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do your organizational processes support your sustainability goals?",
    "Best Practice": "Increase utilization of build environments"
  },
  {
    "Pillar": "Sustainability",
    "Question": "How do your organizational processes support your sustainability goals?",
    "Best Practice": "Use managed device farms for testing"
  }
]
</file>

<file path="ecs_fargate_app/wa_genai_stack.py">
"""CDK stack for hosting react app in ECS and Fargate"""

import configparser
import platform
import uuid

import aws_cdk as cdk
import aws_cdk.aws_servicediscovery as servicediscovery
from aws_cdk import Duration, RemovalPolicy, Stack
from aws_cdk import aws_ec2 as ec2
from aws_cdk import aws_ecs as ecs
from aws_cdk import aws_ecs_patterns as ecs_patterns
from aws_cdk import aws_events as events
from aws_cdk import aws_events_targets as targets
from aws_cdk import aws_iam as iam
from aws_cdk import aws_lambda as lambda_
from aws_cdk import aws_s3 as s3
from aws_cdk import aws_s3_deployment as s3deploy
from aws_cdk import custom_resources as cr
from aws_cdk.aws_ecr_assets import DockerImageAsset, Platform
from cdklabs.generative_ai_cdk_constructs import bedrock
from constructs import Construct


class WAGenAIStack(Stack):

    def __init__(self, scope: Construct, construct_id: str, **kwarg) -> None:
        super().__init__(scope, construct_id, **kwarg)

        # Read config.ini
        config = configparser.ConfigParser()
        config.read("config.ini")
        model_id = config["settings"]["model_id"]
        if config["settings"]["public_load_balancer"] == "False":
            public_lb = False
        else:
            public_lb = True

        random_id = str(uuid.uuid4())[:8]  # First 8 characters of a UUID

        platform_mapping = {
            "x86_64": {
                "fargate_architecture": ecs.CpuArchitecture.X86_64,
                "build_architecture": Platform.LINUX_AMD64,
                "build_architecture_argument": "amd64",
            },
            "arm64": {
                "fargate_architecture": ecs.CpuArchitecture.ARM64,
                "build_architecture": Platform.LINUX_ARM64,
                "build_architecture_argument": "arm64",
            },
            "aarch64": {
                "fargate_architecture": ecs.CpuArchitecture.ARM64,
                "build_architecture": Platform.LINUX_ARM64,
                "build_architecture_argument": "arm64",
            },
        }
        # Get architecture from platform (depending the machine that runs CDK)
        architecture = platform_mapping[platform.machine()]

        # Creates Bedrock KB using the generative_ai_cdk_constructs
        kb = bedrock.KnowledgeBase(
            self,
            "WAFR-KnowledgeBase",
            embeddings_model=bedrock.BedrockFoundationModel.TITAN_EMBED_TEXT_V2_1024,
            instruction="Use this knowledge base to answer questions about AWS Well Architected Framework Review (WAFR).",
            description="This knowledge base contains AWS Well Architected Framework Review (WAFR) reference documents",
        )

        KB_ID = kb.knowledge_base_id

        # Create S3 bucket where well architected reference docs are stored
        wafrReferenceDocsBucket = s3.Bucket(
            self,
            "wafr-accelerator-kb-docs",
            removal_policy=RemovalPolicy.DESTROY,
            auto_delete_objects=True,
            enforce_ssl=True,
        )

        # Uploading WAFR docs to the corresponding S3 bucket [wafrReferenceDocsBucket]
        wafrReferenceDeploy = s3deploy.BucketDeployment(
            self,
            "uploadwellarchitecteddocs",
            sources=[s3deploy.Source.asset("ecs_fargate_app/well_architected_docs")],
            destination_bucket=wafrReferenceDocsBucket,
        )

        WA_DOCS_BUCKET_NAME = wafrReferenceDocsBucket.bucket_name

        # Adds the created S3 bucket [docBucket] as a Data Source for Bedrock KB
        kbDataSource = bedrock.S3DataSource(
            self,
            "DataSource",
            bucket=wafrReferenceDocsBucket,
            knowledge_base=kb,
            data_source_name="wafr-reference-docs",
            chunking_strategy=bedrock.ChunkingStrategy.FIXED_SIZE,
        )

        # Data Ingestion Params
        dataSourceIngestionParams = {
            "dataSourceId": kbDataSource.data_source_id,
            "knowledgeBaseId": KB_ID,
        }

        # Define a custom resource to make an AwsSdk startIngestionJob call
        ingestion_job_cr = cr.AwsCustomResource(
            self,
            "IngestionCustomResource",
            on_create=cr.AwsSdkCall(
                service="bedrock-agent",
                action="startIngestionJob",
                parameters=dataSourceIngestionParams,
                physical_resource_id=cr.PhysicalResourceId.of("Parameter.ARN"),
            ),
            policy=cr.AwsCustomResourcePolicy.from_sdk_calls(
                resources=cr.AwsCustomResourcePolicy.ANY_RESOURCE
            ),
        )

        # Params for the test Well-Architected Workload
        test_workload_region = Stack.of(self).region
        waToolWorkloadParams = {
            "WorkloadName": f"DO-NOT-DELETE_WAIaCAnalyzerApp_{test_workload_region}_{random_id}",
            "Description": f"DO-NOT-DELETE_WAIaCAnalyzerApp_{test_workload_region} TestWorkload for WA IoC Analyzer App",
            "ReviewOwner": "WA IoC Analyzer App",
            "Environment": "PREPRODUCTION",
            "AwsRegions": [test_workload_region],
            "Lenses": ["wellarchitected"],
            "ClientRequestToken": random_id,
        }
        # Create a test Well-Architected Workload
        workload_cr = cr.AwsCustomResource(
            self,
            "TestWorkload",
            on_create=cr.AwsSdkCall(
                service="wellarchitected",
                action="createWorkload",
                parameters=waToolWorkloadParams,
                physical_resource_id=cr.PhysicalResourceId.from_response("WorkloadId"),
                output_paths=["WorkloadId"],
            ),
            on_update=cr.AwsSdkCall(
                service="wellarchitected",
                action="listLensReviews",
                parameters={
                    "WorkloadId": cr.PhysicalResourceIdReference(),
                },
                physical_resource_id=cr.PhysicalResourceId.from_response("WorkloadId"),
                output_paths=["WorkloadId"],
            ),
            on_delete=cr.AwsSdkCall(
                service="wellarchitected",
                action="deleteWorkload",
                parameters={
                    "WorkloadId": cr.PhysicalResourceIdReference(),
                    "ClientRequestToken": random_id,
                },
            ),
            policy=cr.AwsCustomResourcePolicy.from_sdk_calls(
                resources=cr.AwsCustomResourcePolicy.ANY_RESOURCE
            ),
        )

        # Lambda function to refresh and sync Knowledge Base with data source
        kb_lambda_synchronizer = lambda_.Function(
            self,
            "KbLambdaSynchronizer",
            runtime=lambda_.Runtime.PYTHON_3_12,
            handler="kb_synchronizer.handler",
            code=lambda_.Code.from_asset(
                "ecs_fargate_app/lambda_kb_synchronizer",
                bundling=cdk.BundlingOptions(
                    image=lambda_.Runtime.PYTHON_3_12.bundling_image,
                    command=[
                        "bash",
                        "-c",
                        "pip install --no-cache -r requirements.txt -t /asset-output && cp -au . /asset-output",
                    ],
                ),
            ),
            environment={
                "KNOWLEDGE_BASE_ID": KB_ID,
                "DATA_SOURCE_ID": kbDataSource.data_source_id,
                "WA_DOCS_BUCKET_NAME": wafrReferenceDocsBucket.bucket_name,
                "WORKLOAD_ID": workload_cr.get_response_field("WorkloadId"),
            },
            timeout=Duration.minutes(15),
        )

        # Grant permissions to the KB synchronizer Lambda
        kb_lambda_synchronizer.add_to_role_policy(
            iam.PolicyStatement(
                actions=["bedrock:StartIngestionJob"],
                resources=[
                    f"arn:aws:bedrock:{self.region}:{self.account}:knowledge-base/{KB_ID}"
                ],
            )
        )
        kb_lambda_synchronizer.add_to_role_policy(
            iam.PolicyStatement(
                actions=[
                    "wellarchitected:GetLensReview",
                    "wellarchitected:ListAnswers",
                    "wellarchitected:UpgradeLensReview",
                ],
                resources=["*"],
            )
        )
        wafrReferenceDocsBucket.grant_put(kb_lambda_synchronizer)

        # Create EventBridge rule to trigger KbLambdaSynchronizer weekly on Mondays
        events.Rule(
            self,
            "WeeklyIngestionRule",
            schedule=events.Schedule.cron(
                minute="0", hour="0", month="*", week_day="2", year="*"
            ),
            targets=[targets.LambdaFunction(kb_lambda_synchronizer)],
        )

        frontend_image = DockerImageAsset(
            self,
            "FrontendImage",
            directory="ecs_fargate_app",
            file="finch/frontend.Dockerfile",
            platform=architecture["build_architecture"],
            build_args={
                "BUILDKIT_INLINE_CACHE": "1",
                "PLATFORM": architecture["build_architecture_argument"],
            },
        )

        backend_image = DockerImageAsset(
            self,
            "BackendImage",
            directory="ecs_fargate_app",
            file="finch/backend.Dockerfile",
            platform=architecture["build_architecture"],
            build_args={
                "BUILDKIT_INLINE_CACHE": "1",
                "PLATFORM": architecture["build_architecture_argument"],
            },
        )

        # create app execute role
        app_execute_role = iam.Role(
            self,
            "AppExecuteRole",
            assumed_by=iam.ServicePrincipal("ecs-tasks.amazonaws.com"),
        )
        app_execute_role.add_to_policy(
            iam.PolicyStatement(
                actions=[
                    "ecr:GetAuthorizationToken",
                    "ecr:BatchCheckLayerAvailability",
                    "ecr:GetDownloadUrlForLayer",
                    "ecr:BatchGetImage",
                    "logs:CreateLogStream",
                    "logs:PutLogEvents",
                ],
                resources=["*"],
            )
        )

        # Add policy statements to the IAM role
        app_execute_role.add_to_policy(
            iam.PolicyStatement(
                actions=[
                    "wellarchitected:GetLensReview",
                    "wellarchitected:ListAnswers",
                    "wellarchitected:GetWorkload",
                    "wellarchitected:UpdateAnswer",
                    "wellarchitected:CreateMilestone",
                    "wellarchitected:GetLensReviewReport",
                ],
                resources=["*"],
            )
        )
        app_execute_role.add_to_policy(
            iam.PolicyStatement(
                actions=[
                    "wellarchitected:CreateWorkload",
                    "wellarchitected:TagResource",
                ],
                resources=["*"],
                conditions={
                    "StringLike": {
                        "aws:RequestTag/WorkloadName": [
                            "DO_NOT_DELETE_temp_IaCAnalyzer_*",
                            "IaCAnalyzer_*",
                        ]
                    }
                },
            )
        )
        app_execute_role.add_to_policy(
            iam.PolicyStatement(
                actions=[
                    "wellarchitected:DeleteWorkload",
                ],
                resources=["*"],
                conditions={
                    "StringLike": {
                        "aws:ResourceTag/WorkloadName": [
                            "DO_NOT_DELETE_temp_IaCAnalyzer_*",
                            "IaCAnalyzer_*",
                        ]
                    }
                },
            )
        )
        app_execute_role.add_to_policy(
            iam.PolicyStatement(actions=["bedrock:InvokeModel"], resources=["*"])
        )
        app_execute_role.add_to_policy(
            iam.PolicyStatement(
                actions=["s3:GetObject", "s3:ListBucket"],
                resources=[
                    f"arn:aws:s3:::{WA_DOCS_BUCKET_NAME}",
                    f"arn:aws:s3:::{WA_DOCS_BUCKET_NAME}/*",
                ],
            )
        )
        app_execute_role.add_managed_policy(
            iam.ManagedPolicy.from_aws_managed_policy_name("AmazonBedrockFullAccess")
        )

        # Create VPC to host the ECS cluster
        vpc = ec2.Vpc(
            self,
            "ECSVpc",
            ip_addresses=ec2.IpAddresses.cidr("10.0.0.0/16"),
            max_azs=2,
            nat_gateways=1,
            subnet_configuration=[
                ec2.SubnetConfiguration(
                    name="public", subnet_type=ec2.SubnetType.PUBLIC
                ),
                ec2.SubnetConfiguration(
                    name="private", subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS
                ),
            ],
        )

        # Capture the public subnets
        public_subnets = vpc.select_subnets(subnet_type=ec2.SubnetType.PUBLIC)

        # Create ECS Cluster
        ecs_cluster = ecs.Cluster(self, "AppCluster", vpc=vpc, container_insights=True)

        # Add ECS Service Discovery namespace
        namespace = servicediscovery.PrivateDnsNamespace(
            self, "ServiceDiscovery", name="internal", vpc=vpc
        )

        # Create security groups for frontend and backend
        frontend_security_group = ec2.SecurityGroup(
            self,
            "FrontendSecurityGroup",
            vpc=vpc,
            description="Security group for frontend service",
        )

        backend_security_group = ec2.SecurityGroup(
            self,
            "BackendSecurityGroup",
            vpc=vpc,
            description="Security group for backend service",
        )

        # Create frontend service with ALB
        frontend_service = ecs_patterns.ApplicationLoadBalancedFargateService(
            self,
            "FrontendService",
            cluster=ecs_cluster,
            runtime_platform=ecs.RuntimePlatform(
                operating_system_family=ecs.OperatingSystemFamily.LINUX,
                cpu_architecture=architecture["fargate_architecture"],
            ),
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_docker_image_asset(frontend_image),
                container_port=8080,
                environment={
                    # Use service discovery DNS name
                    "VITE_API_URL": f"http://backend.internal:3000"
                },
            ),
            public_load_balancer=public_lb,
            security_groups=[frontend_security_group],
        )

        # Set ALB idle timeout to 15 minutes
        frontend_service.load_balancer.set_attribute(
            "idle_timeout.timeout_seconds", "3600"
        )

        # Allow ALB to access frontend on port 8080
        frontend_security_group.add_ingress_rule(
            peer=frontend_service.load_balancer.connections.security_groups[
                0
            ],  # ALB security group
            connection=ec2.Port.tcp(8080),
            description="Allow ALB to access frontend",
        )

        # Allow frontend to access backend on port 3000
        backend_security_group.add_ingress_rule(
            peer=frontend_security_group,
            connection=ec2.Port.tcp(3000),
            description="Allow frontend to access backend",
        )

        # Get the ALB DNS name after frontend service is created
        alb_dns = frontend_service.load_balancer.load_balancer_dns_name

        # Configure health check for ALB
        frontend_service.target_group.configure_health_check(path="/healthz")

        # Create backend service with service discovery
        backend_task_definition = ecs.FargateTaskDefinition(
            self,
            "BackendTaskDef",
            runtime_platform=ecs.RuntimePlatform(
                operating_system_family=ecs.OperatingSystemFamily.LINUX,
                cpu_architecture=architecture["fargate_architecture"],
            ),
            task_role=app_execute_role,
        )

        backend_container = backend_task_definition.add_container(
            "BackendContainer",
            image=ecs.ContainerImage.from_docker_image_asset(backend_image),
            environment={
                "WA_DOCS_S3_BUCKET": WA_DOCS_BUCKET_NAME,
                "KNOWLEDGE_BASE_ID": KB_ID,
                "MODEL_ID": model_id,
                "AWS_REGION": Stack.of(self).region,
                "FRONTEND_URL": f"http://{alb_dns}",
            },
            logging=ecs.LogDriver.aws_logs(stream_prefix="backend"),
        )

        backend_container.add_port_mappings(ecs.PortMapping(container_port=3000))

        # Create the backend service
        backend_service = ecs.FargateService(
            self,
            "BackendService",
            cluster=ecs_cluster,
            task_definition=backend_task_definition,
            vpc_subnets=ec2.SubnetSelection(
                subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS
            ),
            security_groups=[backend_security_group],
        )

        # Add service discovery
        backend_service.enable_cloud_map(cloud_map_namespace=namespace, name="backend")

        # Output the frontend ALB DNS name
        cdk.CfnOutput(
            self,
            "FrontendURL",
            value=frontend_service.load_balancer.load_balancer_dns_name,
            description="Frontend application URL",
        )

        # Output the ID of the Bedrock knowledge base
        cdk.CfnOutput(
            self,
            "KnowledgeBaseID",
            value=KB_ID,
            description="ID of the Bedrock knowledge base",
        )

        # Output S3 bucket (Source of Bedrock knowledge base) with well-architected documents.
        cdk.CfnOutput(
            self,
            "WellArchitectedDocsS3Bucket",
            value=wafrReferenceDocsBucket.bucket_name,
            description="S3 bucket (Source of Bedrock knowledge base) with well-architected documents.",
        )

        # Output the VPC ID
        cdk.CfnOutput(
            self,
            "VpcId",
            value=vpc.vpc_id,
            description="ID of the VPC where the private ALB is created",
        )

        # Output the ID of the first public subnet
        cdk.CfnOutput(
            self,
            "PublicSubnetId",
            value=public_subnets.subnet_ids[0],
            description="ID of the public subnet created in the VPC",
        )

        # Node dependencies
        kbDataSource.node.add_dependency(wafrReferenceDocsBucket)
        ingestion_job_cr.node.add_dependency(kb)
        kb_lambda_synchronizer.node.add_dependency(kb)
        kb_lambda_synchronizer.node.add_dependency(kbDataSource)
        kb_lambda_synchronizer.node.add_dependency(wafrReferenceDocsBucket)
        kb_lambda_synchronizer.node.add_dependency(workload_cr)
</file>

<file path=".gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class
ecs_fargate_streamlit_app/__pycache__/

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

.DS_Store

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
.idea/

# cdk asset
cdk.out
bin/
node_modules/
*/asset-output/*


.finch/
npm-cache/
</file>

<file path="app.py">
#!/usr/bin/env python3
import os

import aws_cdk as cdk

from ecs_fargate_app.wa_genai_stack import WAGenAIStack

app = cdk.App()

# Try to get the region from an environment variable
REGION = os.environ.get("CDK_DEPLOY_REGION")

# If REGION is still None, it will use the default region when deployed
env = cdk.Environment(region=REGION) if REGION else None

APP_PREFIX = f"WA-IaC-Analyzer-{REGION or 'default'}"

# Create the front-end Stack
wa_genai_stack = WAGenAIStack(
    app,
    f"{APP_PREFIX}-GenAIStack",
    env=env,
)

app.synth()
</file>

<file path="cdk.json">
{
  "app": "python3 app.py",
  "watch": {
    "include": [
      "**"
    ],
    "exclude": [
      "README.md",
      "cdk*.json",
      "requirements*.txt",
      "source.bat",
      "**/__init__.py",
      "python/__pycache__",
      "tests"
    ]
  },
  "context": {
    "@aws-cdk/aws-lambda:recognizeLayerVersion": true,
    "@aws-cdk/core:checkSecretUsage": true,
    "@aws-cdk/core:target-partitions": [
      "aws",
      "aws-cn"
    ],
    "@aws-cdk-containers/ecs-service-extensions:enableDefaultLogDriver": true,
    "@aws-cdk/aws-ec2:uniqueImdsv2TemplateName": true,
    "@aws-cdk/aws-ecs:arnFormatIncludesClusterName": true,
    "@aws-cdk/aws-iam:minimizePolicies": true,
    "@aws-cdk/core:validateSnapshotRemovalPolicy": true,
    "@aws-cdk/aws-codepipeline:crossAccountKeyAliasStackSafeResourceName": true,
    "@aws-cdk/aws-s3:createDefaultLoggingPolicy": true,
    "@aws-cdk/aws-sns-subscriptions:restrictSqsDescryption": true,
    "@aws-cdk/aws-apigateway:disableCloudWatchRole": true,
    "@aws-cdk/core:enablePartitionLiterals": true,
    "@aws-cdk/aws-events:eventsTargetQueueSameAccount": true,
    "@aws-cdk/aws-iam:standardizedServicePrincipals": true,
    "@aws-cdk/aws-ecs:disableExplicitDeploymentControllerForCircuitBreaker": true,
    "@aws-cdk/aws-iam:importedRoleStackSafeDefaultPolicyName": true,
    "@aws-cdk/aws-s3:serverAccessLogsUseBucketPolicy": true,
    "@aws-cdk/aws-route53-patters:useCertificate": true,
    "@aws-cdk/customresources:installLatestAwsSdkDefault": false,
    "@aws-cdk/aws-rds:databaseProxyUniqueResourceName": true,
    "@aws-cdk/aws-codedeploy:removeAlarmsFromDeploymentGroup": true,
    "@aws-cdk/aws-apigateway:authorizerChangeDeploymentLogicalId": true,
    "@aws-cdk/aws-ec2:launchTemplateDefaultUserData": true,
    "@aws-cdk/aws-secretsmanager:useAttachedSecretResourcePolicyForSecretTargetAttachments": true,
    "@aws-cdk/aws-redshift:columnId": true,
    "@aws-cdk/aws-stepfunctions-tasks:enableEmrServicePolicyV2": true,
    "@aws-cdk/aws-ec2:restrictDefaultSecurityGroup": true,
    "@aws-cdk/aws-apigateway:requestValidatorUniqueId": true,
    "@aws-cdk/aws-kms:aliasNameRef": true,
    "@aws-cdk/aws-autoscaling:generateLaunchTemplateInsteadOfLaunchConfig": true,
    "@aws-cdk/core:includePrefixInUniqueNameGeneration": true,
    "@aws-cdk/aws-opensearchservice:enableOpensearchMultiAzWithStandby": true
  }
}
</file>

<file path="CODE_OF_CONDUCT.md">
## Code of Conduct
This project has adopted the [Amazon Open Source Code of Conduct](https://aws.github.io/code-of-conduct).
For more information see the [Code of Conduct FAQ](https://aws.github.io/code-of-conduct-faq) or contact
opensource-codeofconduct@amazon.com with any additional questions or comments.
</file>

<file path="config.ini">
[settings]
model_id = anthropic.claude-3-5-sonnet-20241022-v2:0

# [ WARNING ] 
# Please note that this project is prepared as a demo without any authentication mechanism. Therefore, we recommend deploying this project using an internal-facing load balancer scheme and keeping the parameter below as "False." Should you choose to change the parameter below to "True" or modify the load balancer to be internet-facing, you are accepting the risk and any implications that this application, along with its functionalities, will be accessible directly through the internet without any form of authentication.


public_load_balancer = False
</file>

<file path="CONTRIBUTING.md">
# Contributing Guidelines

Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional
documentation, we greatly value feedback and contributions from our community.

Please read through this document before submitting any issues or pull requests to ensure we have all the necessary
information to effectively respond to your bug report or contribution.


## Reporting Bugs/Feature Requests

We welcome you to use the GitHub issue tracker to report bugs or suggest features.

When filing an issue, please check existing open, or recently closed, issues to make sure somebody else hasn't already
reported the issue. Please try to include as much information as you can. Details like these are incredibly useful:

* A reproducible test case or series of steps
* The version of our code being used
* Any modifications you've made relevant to the bug
* Anything unusual about your environment or deployment


## Contributing via Pull Requests
Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that:

1. You are working against the latest source on the *main* branch.
2. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already.
3. You open an issue to discuss any significant work - we would hate for your time to be wasted.

To send us a pull request, please:

1. Fork the repository.
2. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change.
3. Ensure local tests pass.
4. Commit to your fork using clear commit messages.
5. Send us a pull request, answering any default questions in the pull request interface.
6. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.

GitHub provides additional document on [forking a repository](https://help.github.com/articles/fork-a-repo/) and
[creating a pull request](https://help.github.com/articles/creating-a-pull-request/).


## Finding contributions to work on
Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels (enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.


## Code of Conduct
This project has adopted the [Amazon Open Source Code of Conduct](https://aws.github.io/code-of-conduct).
For more information see the [Code of Conduct FAQ](https://aws.github.io/code-of-conduct-faq) or contact
opensource-codeofconduct@amazon.com with any additional questions or comments.


## Security issue notifications
If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our [vulnerability reporting page](http://aws.amazon.com/security/vulnerability-reporting/). Please do **not** create a public github issue.


## Licensing

See the [LICENSE](LICENSE) file for our project's licensing. We will ask you to confirm the licensing of your contribution.
</file>

<file path="deploy-wa-analyzer.sh">
#!/bin/bash

# Instructions for using the script:

# 1. Make the script executable:
# ```bash
# chmod +x deploy-wa-analyzer.sh
# ```

# 2. Basic usage with defaults (us-west-2 region and finch for container tool):
# ```bash
# ./deploy-wa-analyzer.sh
# ```

# 3. Deploy to a specific region and using docker for container tool:
# ```bash
# ./deploy-wa-analyzer.sh -r us-east-1 -c docker
# ```

# 4. Show help:
# ```bash
# ./deploy-wa-analyzer.sh -h
# ```

# Exit on error
set -e

# Default values
DEFAULT_REGION="us-west-2" # Default deployment region
CONTAINER_TOOL="finch"  # Default container tool

# Set environment variable to ignore ECR credentials storage
export AWS_ECR_IGNORE_CREDS_STORAGE=true

# Print script usage
print_usage() {
    echo "Usage: ./deploy-wa-analyzer.sh [-r region] [-c container_tool]"
    echo ""
    echo "Options:"
    echo "  -r    AWS Region (default: us-west-2)"
    echo "  -c    Container tool (finch or docker, default: finch)"
    echo "  -h    Show this help message"
    echo ""
    echo "Example:"
    echo "  ./deploy-wa-analyzer.sh -r us-east-1 -c docker"
}

# Parse command line arguments
while getopts "r:c:h" flag; do
    case "${flag}" in
        r) DEFAULT_REGION=${OPTARG};;
        c) CONTAINER_TOOL=${OPTARG};;
        h) print_usage
           exit 0;;
        *) print_usage
           exit 1;;
    esac
done

# Validate container tool
if [[ "$CONTAINER_TOOL" != "finch" && "$CONTAINER_TOOL" != "docker" ]]; then
    echo " Invalid container tool. Must be either 'finch' or 'docker'"
    print_usage
    exit 1
fi

# Function to check Docker daemon
check_docker_daemon() {
    echo "Checking Docker setup..."
    
    # First check if Docker client exists
    if ! command -v docker &> /dev/null; then
        echo " Docker is not installed"
        if [[ "$OSTYPE" == "darwin"* ]]; then
            echo "Please install Docker Desktop for Mac from https://www.docker.com/products/docker-desktop"
        elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
            echo "Please install Docker using your distribution's package manager"
            echo "For Ubuntu/Debian: sudo apt-get install docker.io"
            echo "For RHEL/CentOS: sudo yum install docker"
        else
            echo "Please install Docker and try again"
        fi
        exit 1
    fi

    # Try to get Docker server version and capture the output and exit status
    local server_version
    local exit_status
    
    server_version=$(docker info --format '{{.ServerVersion}}' 2>&1)
    exit_status=$?

    # Check if the command was successful and if the output doesn't contain error messages
    if [ $exit_status -ne 0 ] || [[ $server_version == *"Cannot connect"* ]] || [[ $server_version == *"error"* ]] || [[ $server_version == *"command not found"* ]]; then
        echo " Docker daemon is not running"
        if [[ "$OSTYPE" == "darwin"* ]]; then
            echo "Please start Docker Desktop for Mac and try again"
            echo "You can start it from the Applications folder or menu bar icon"
        elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
            echo "Please start Docker daemon (dockerd) and try again"
            echo "You can start it with: sudo systemctl start docker"
        else
            echo "Please start Docker daemon and try again"
        fi
        echo "Error details: $server_version"
        exit 1
    fi
    
    echo " Docker daemon is running (Server Version: $server_version)"
}

# Function to check Finch VM status
check_finch_vm() {
    echo "Checking Finch setup..."
    local max_attempts=30  # Maximum number of attempts (30 * 2 seconds = 60 seconds timeout)
    local attempt=1

    if ! finch vm status &> /dev/null; then
        echo "Initializing Finch VM..."
        finch vm init
        echo "Starting Finch VM..."
        finch vm start
    elif ! finch vm status | grep -q "Running"; then
        echo "Starting Finch VM..."
        finch vm start
    fi

    echo "Waiting for Finch VM to be ready..."
    while ! finch vm status | grep -q "Running"; do
        if [ $attempt -ge $max_attempts ]; then
            echo " Timeout waiting for Finch VM to start"
            exit 1
        fi
        echo "Still waiting for Finch VM to be ready... (attempt $attempt/$max_attempts)"
        sleep 2
        ((attempt++))
    done
    echo " Finch VM is running"
}

# Function to check prerequisites
check_prerequisites() {
    echo " Checking prerequisites..."
    
    # Define base required commands
    local base_commands=("node" "npm" "aws" "cdk" "python3" "pip3")
    local required_commands=("${base_commands[@]}")
    
    # Add container-specific command
    required_commands+=("$CONTAINER_TOOL")
    
    local missing_commands=()
    
    for cmd in "${required_commands[@]}"; do
        if ! command -v $cmd &> /dev/null; then
            missing_commands+=($cmd)
            echo " $cmd is required but not installed"
        else
            echo " $cmd is installed"
        fi
    done
    
    # Check AWS credentials
    if ! aws sts get-caller-identity &> /dev/null; then
        echo " AWS credentials not configured"
        exit 1
    else
        echo " AWS credentials configured"
    fi
    
    # Check container runtime
    if [ "$CONTAINER_TOOL" = "docker" ]; then
        check_docker_daemon
    else
        check_finch_vm
    fi
    
    # Exit if any commands are missing
    if [ ${#missing_commands[@]} -ne 0 ]; then
        echo -e "\n Please install missing prerequisites: ${missing_commands[*]}"
        exit 1
    fi
    
    echo " All prerequisites met"
}

# Function to setup dependencies
setup_dependencies() {
    echo " Setting up dependencies..."
    
    # Create and activate Python virtual environment
    echo "Creating Python virtual environment..."
    python3 -m venv .venv
    
    # Activate virtual environment
    echo "Activating virtual environment..."
    source .venv/bin/activate
    
    # Install Python dependencies
    echo "Installing Python dependencies..."
    pip3 install --upgrade pip
    pip3 install -r requirements.txt
    
    # Install CDK dependencies
    echo "Installing CDK dependencies..."
    npm install
    
    # Install frontend dependencies
    echo "Installing frontend dependencies..."
    cd ecs_fargate_app/frontend
    npm install
    cd ../..
    
    # Install backend dependencies
    echo "Installing backend dependencies..."
    cd ecs_fargate_app/backend
    npm install
    cd ../..
    
    echo " Dependencies setup completed"
}

# Function to cleanup
cleanup() {
    echo " Cleaning up..."
    # Deactivate virtual environment if it's active
    if [ -n "$VIRTUAL_ENV" ]; then
        deactivate
        echo " Virtual environment deactivated"
    fi
}

# Function to deploy the stack
deploy_stack() {
    echo " Deploying Well-Architected Analyzer stack..."
    
    # Set AWS region
    export CDK_DEPLOY_REGION=$DEFAULT_REGION
    echo "Using AWS Region: $DEFAULT_REGION"

    # Set container runtime for building the CDK container images
    export CDK_DOCKER=$CONTAINER_TOOL
    echo "Using container runtime: $CONTAINER_TOOL"
    
    # Bootstrap CDK if needed
    echo "Bootstrapping CDK (if needed) in AWS account $AWS_ACCOUNT and region $DEFAULT_REGION..."
    cdk bootstrap aws://$AWS_ACCOUNT/$DEFAULT_REGION
    
    # Deploy stack
    echo "Deploying stack..."
    cdk deploy --require-approval never
    
    # Print post-deployment information
    echo -e "\n Post-Deployment Steps:"
    echo "1. Note the ALB Domain Name from the outputs above"
    echo "2. Access the application through the ALB domain name"
}

# Main execution
main() {
    echo " Starting Well-Architected Analyzer deployment..."
    echo "Region: $DEFAULT_REGION"
    echo "Container Tool: $CONTAINER_TOOL"
    
    # Get AWS account ID
    AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
    
    # Set up trap to ensure cleanup runs on exit
    trap cleanup EXIT
    
    # Run deployment steps
    check_prerequisites
    setup_dependencies
    deploy_stack
    
    echo -e "\n Deployment completed successfully!"
}

# Run main function
main
</file>

<file path="destroy-wa-analyzer.sh">
#!/bin/bash

# Instructions for using the script:

# 1. Make the script executable:
# ```bash
# chmod +x destroy-wa-analyzer.sh
# ```

# 2. Basic usage with defaults (us-west-2 region and finch for container tool):
# ```bash
# ./destroy-wa-analyzer.sh
# ```

# 3. Destroy stack in a specific region and using docker for container tool:
# ```bash
# ./destroy-wa-analyzer.sh -r us-east-1 -c docker
# ```

# 4. Show help:
# ```bash
# ./destroy-wa-analyzer.sh -h
# ```

# Exit on error
set -e

# Default values
DEFAULT_REGION="us-west-2"
CONTAINER_TOOL="finch"  # Default container tool

# Print script usage
print_usage() {
    echo "Usage: ./destroy-wa-analyzer.sh [-r region] [-c container_tool]"
    echo ""
    echo "Options:"
    echo "  -r    AWS Region (default: us-west-2)"
    echo "  -c    Container tool (finch or docker, default: finch)"
    echo "  -h    Show this help message"
    echo ""
    echo "Example:"
    echo "  ./destroy-wa-analyzer.sh -r us-east-1 -c docker"
}

# Parse command line arguments
while getopts "r:c:h" flag; do
    case "${flag}" in
        r) DEFAULT_REGION=${OPTARG};;
        c) CONTAINER_TOOL=${OPTARG};;
        h) print_usage
           exit 0;;
        *) print_usage
           exit 1;;
    esac
done

# Validate container tool
if [[ "$CONTAINER_TOOL" != "finch" && "$CONTAINER_TOOL" != "docker" ]]; then
    echo " Invalid container tool. Must be either 'finch' or 'docker'"
    print_usage
    exit 1
fi

# Function to check Docker daemon
check_docker_daemon() {
    echo "Checking Docker setup..."
    
    # First check if Docker client exists
    if ! command -v docker &> /dev/null; then
        echo " Docker is not installed"
        if [[ "$OSTYPE" == "darwin"* ]]; then
            echo "Please install Docker Desktop for Mac from https://www.docker.com/products/docker-desktop"
        elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
            echo "Please install Docker using your distribution's package manager"
            echo "For Ubuntu/Debian: sudo apt-get install docker.io"
            echo "For RHEL/CentOS: sudo yum install docker"
        else
            echo "Please install Docker and try again"
        fi
        exit 1
    fi

    # Try to get Docker server version and capture the output and exit status
    local server_version
    local exit_status
    
    server_version=$(docker info --format '{{.ServerVersion}}' 2>&1)
    exit_status=$?

    # Check if the command was successful and if the output doesn't contain error messages
    if [ $exit_status -ne 0 ] || [[ $server_version == *"Cannot connect"* ]] || [[ $server_version == *"error"* ]] || [[ $server_version == *"command not found"* ]]; then
        echo " Docker daemon is not running"
        if [[ "$OSTYPE" == "darwin"* ]]; then
            echo "Please start Docker Desktop for Mac and try again"
            echo "You can start it from the Applications folder or menu bar icon"
        elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
            echo "Please start Docker daemon (dockerd) and try again"
            echo "You can start it with: sudo systemctl start docker"
        else
            echo "Please start Docker daemon and try again"
        fi
        echo "Error details: $server_version"
        exit 1
    fi
    
    echo " Docker daemon is running (Server Version: $server_version)"
}

# Function to check Finch VM status
check_finch_vm() {
    echo "Checking Finch setup..."
    local max_attempts=30  # Maximum number of attempts (30 * 2 seconds = 60 seconds timeout)
    local attempt=1

    if ! finch vm status &> /dev/null; then
        echo "Initializing Finch VM..."
        finch vm init
        echo "Starting Finch VM..."
        finch vm start
    elif ! finch vm status | grep -q "Running"; then
        echo "Starting Finch VM..."
        finch vm start
    fi

    echo "Waiting for Finch VM to be ready..."
    while ! finch vm status | grep -q "Running"; do
        if [ $attempt -ge $max_attempts ]; then
            echo " Timeout waiting for Finch VM to start"
            exit 1
        fi
        echo "Still waiting for Finch VM to be ready... (attempt $attempt/$max_attempts)"
        sleep 2
        ((attempt++))
    done
    echo " Finch VM is running"
}

# Function to check prerequisites
check_prerequisites() {
    echo " Checking prerequisites..."
    
    # Define base required commands
    local base_commands=("node" "npm" "aws" "cdk" "python3" "pip3")
    local required_commands=("${base_commands[@]}")
    
    # Add container-specific command
    required_commands+=("$CONTAINER_TOOL")
    
    local missing_commands=()
    
    for cmd in "${required_commands[@]}"; do
        if ! command -v $cmd &> /dev/null; then
            missing_commands+=($cmd)
            echo " $cmd is required but not installed"
        else
            echo " $cmd is installed"
        fi
    done
    
    # Check AWS credentials
    if ! aws sts get-caller-identity &> /dev/null; then
        echo " AWS credentials not configured"
        exit 1
    else
        echo " AWS credentials configured"
    fi
    
    # Check container runtime
    if [ "$CONTAINER_TOOL" = "docker" ]; then
        check_docker_daemon
    else
        check_finch_vm
    fi
    
    # Exit if any commands are missing
    if [ ${#missing_commands[@]} -ne 0 ]; then
        echo -e "\n Please install missing prerequisites: ${missing_commands[*]}"
        exit 1
    fi
    
    echo " All prerequisites met"
}

# Function to setup Python environment
setup_python_env() {
    echo " Setting up Python environment..."
    
    # Create and activate Python virtual environment
    echo "Creating Python virtual environment..."
    python3 -m venv .venv
    
    # Activate virtual environment
    echo "Activating virtual environment..."
    source .venv/bin/activate
    
    # Install Python dependencies
    echo "Installing Python dependencies..."
    pip3 install --upgrade pip
    pip3 install -r requirements.txt
    
    echo " Python environment setup completed"
}

# Function to cleanup
cleanup() {
    echo " Cleaning up..."
    # Deactivate virtual environment if it's active
    if [ -n "$VIRTUAL_ENV" ]; then
        deactivate
        echo " Virtual environment deactivated"
    fi
}

# Function to destroy the stack
destroy_stack() {
    echo " Destroying Well-Architected Analyzer stack..."
    
    # Set AWS region
    export CDK_DEPLOY_REGION=$DEFAULT_REGION
    echo "Using AWS Region: $DEFAULT_REGION"

    # Set container runtime for building the CDK container images
    export CDK_DOCKER=$CONTAINER_TOOL
    echo "Using container runtime: $CONTAINER_TOOL"
    
    # Destroy stack
    echo " WARNING: This will destroy all resources in the stack!"
    echo "Proceeding with stack destruction in 5 seconds..."
    sleep 5
    
    echo "Running 'cdk destroy --force' command..."
    cdk destroy --force
}

# Main execution
main() {
    echo " Starting Well-Architected Analyzer stack destruction..."
    echo "Region: $DEFAULT_REGION"
    echo "Container Tool: $CONTAINER_TOOL"
    
    # Get AWS account ID
    AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
    
    # Set up trap to ensure cleanup runs on exit
    trap cleanup EXIT
    
    # Run destruction steps
    check_prerequisites
    setup_python_env
    destroy_stack
    
    echo -e "\n Stack destruction completed successfully!"
}

# Run main function
main
</file>

<file path="dev.sh">
#!/bin/bash

# Color codes for output
YELLOW='\033[1;33m'
GREEN='\033[0;32m'
NC='\033[0m' # No Color

# Default container tool
CONTAINER_TOOL="finch"

# Print script usage
print_usage() {
    echo "Usage: ./dev.sh [-c container_tool]"
    echo ""
    echo "Options:"
    echo "  -c    Container tool (finch or docker, default: finch)"
    echo "  -h    Show this help message"
    echo ""
    echo "Example:"
    echo "  ./dev.sh -c docker"
}

# Parse command line arguments
while getopts "c:h" flag; do
    case "${flag}" in
        c) CONTAINER_TOOL=${OPTARG};;
        h) print_usage
           exit 0;;
        *) print_usage
           exit 1;;
    esac
done

# Validate container tool
if [[ "$CONTAINER_TOOL" != "finch" && "$CONTAINER_TOOL" != "docker" ]]; then
    echo " Invalid container tool. Must be either 'finch' or 'docker'"
    print_usage
    exit 1
fi

# Function to check if a command exists
check_command() {
    if ! command -v "$1" &> /dev/null; then
        echo -e " Error: $1 is not installed"
        return 1
    else
        echo -e " $1 is installed"
        return 0
    fi
}

# Function to check Docker daemon
check_docker_daemon() {
    echo "Checking Docker setup..."
    
    # First check if Docker client exists
    if ! command -v docker &> /dev/null; then
        echo " Docker is not installed"
        if [[ "$OSTYPE" == "darwin"* ]]; then
            echo "Please install Docker Desktop for Mac from https://www.docker.com/products/docker-desktop"
        elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
            echo "Please install Docker using your distribution's package manager"
            echo "For Ubuntu/Debian: sudo apt-get install docker.io"
            echo "For RHEL/CentOS: sudo yum install docker"
        else
            echo "Please install Docker and try again"
        fi
        return 1
    fi

    # Try to get Docker server version and capture the output and exit status
    local server_version
    local exit_status
    
    server_version=$(docker info --format '{{.ServerVersion}}' 2>&1)
    exit_status=$?

    # Check if the command was successful and if the output doesn't contain error messages
    if [ $exit_status -ne 0 ] || [[ $server_version == *"Cannot connect"* ]] || [[ $server_version == *"error"* ]] || [[ $server_version == *"command not found"* ]]; then
        echo " Docker daemon is not running"
        if [[ "$OSTYPE" == "darwin"* ]]; then
            echo "Please start Docker Desktop for Mac and try again"
            echo "You can start it from the Applications folder or menu bar icon"
        elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
            echo "Please start Docker daemon (dockerd) and try again"
            echo "You can start it with: sudo systemctl start docker"
        else
            echo "Please start Docker daemon and try again"
        fi
        echo "Error details: $server_version"
        return 1
    fi
    
    echo " Docker daemon is running (Server Version: $server_version)"
    return 0
}

# Function to check and start Finch VM if needed
check_and_start_finch_vm() {
    echo "Checking Finch VM status..."
    if ! finch vm status | grep -q "Running"; then
        echo -e "${YELLOW}Finch VM is not running. Starting it now...${NC}"
        if ! finch vm start; then
            echo -e " Error: Failed to start Finch VM"
            return 1
        fi
        
        # Wait for VM to be fully ready
        echo "Waiting for Finch VM to be ready..."
        sleep 5
        
        if ! finch vm status | grep -q "Running"; then
            echo -e " Error: Finch VM failed to start properly"
            return 1
        fi
    fi
    echo -e " Finch VM is running"
    return 0
}

# Function to check Node.js version
check_node_version() {
    local required_version="18"
    local current_version=$(node -v | cut -d'v' -f2 | cut -d'.' -f1)
    
    if [ "$current_version" -lt "$required_version" ]; then
        echo -e " Error: Node.js version must be v${required_version} or higher"
        echo -e "${YELLOW}Current version: $(node -v)${NC}"
        return 1
    else
        echo -e " Node.js version $(node -v) is compatible"
        return 0
    fi
}

# Function to check npm installation
check_npm() {
    if ! npm -v &> /dev/null; then
        echo -e " Error: npm is not installed"
        return 1
    else
        echo -e " npm is installed ($(npm -v))"
        return 0
    fi
}

# Function to check AWS credentials
check_aws_credentials() {
    if ! aws sts get-caller-identity &> /dev/null; then
        echo -e " Error: AWS credentials not configured"
        echo -e "${YELLOW}Please configure your AWS credentials using 'aws configure' or set appropriate environment variables${NC}"
        return 1
    else
        echo -e " AWS credentials are configured"
        return 0
    fi
}

# Function to setup dependencies
setup_dependencies() {
    echo " Setting up dependencies..."
    
    # Create and activate Python virtual environment
    echo "Creating Python virtual environment..."
    python3 -m venv .venv
    
    # Activate virtual environment
    echo "Activating virtual environment..."
    source .venv/bin/activate
    
    # Install Python dependencies
    echo "Installing Python dependencies..."
    pip3 install --upgrade pip
    pip3 install -r requirements.txt
    
    # Install CDK dependencies
    echo "Installing CDK dependencies..."
    npm install
    
    # Install frontend dependencies
    echo "Installing frontend dependencies..."
    cd ecs_fargate_app/frontend
    npm install
    cd ../..
    
    # Install backend dependencies
    echo "Installing backend dependencies..."
    cd ecs_fargate_app/backend
    npm install
    cd ../..
    
    echo " Dependencies setup completed"
}

# Main verification process
echo "Verifying development environment..."
echo "Using container tool: $CONTAINER_TOOL"

# Initialize error flag
has_error=0

# Perform all checks
check_command "node" || has_error=1
check_command "npm" || has_error=1
check_command "aws" || has_error=1
check_command "$CONTAINER_TOOL" || has_error=1

if [ "$CONTAINER_TOOL" = "docker" ]; then
    check_docker_daemon || has_error=1
else
    check_and_start_finch_vm || has_error=1
fi

check_node_version || has_error=1
check_npm || has_error=1
check_aws_credentials || has_error=1
setup_dependencies

# Exit if any checks failed
if [ $has_error -eq 1 ]; then
    echo -e "\n Environment verification failed. Please fix the above issues and try again."
    exit 1
fi

echo -e "\n Environment verification completed successfully!${NC}"

# Start the development environment
echo "Starting development environment..."

# Use the appropriate compose command based on the container tool
if [ "$CONTAINER_TOOL" = "docker" ]; then
    docker compose -f finch-compose.dev.yaml up --build
    # Set up trap for clean shutdown
    trap 'docker compose -f finch-compose.dev.yaml down' EXIT
else
    finch compose -f finch-compose.dev.yaml up --build
    # Set up trap for clean shutdown
    trap 'finch compose -f finch-compose.dev.yaml down' EXIT
fi
</file>

<file path="finch-compose.dev.yaml">
version: '3.8'

services:
  backend:
    build:
      context: ./ecs_fargate_app
      dockerfile: finch/backend.dev.Dockerfile
    environment:
      - AWS_REGION=${AWS_REGION:-us-west-2}
      - WA_DOCS_S3_BUCKET=${WA_DOCS_S3_BUCKET}
      - KNOWLEDGE_BASE_ID=${KNOWLEDGE_BASE_ID}
      - MODEL_ID=${MODEL_ID}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - FRONTEND_URL=http://localhost:8080
    ports:
      - "3000:3000"
    volumes:
      - ./ecs_fargate_app/backend/src:/app/src
      - ./ecs_fargate_app/backend/package.json:/app/package.json

  frontend:
    build:
      context: ./ecs_fargate_app
      dockerfile: finch/frontend.dev.Dockerfile
    ports:
      - "8080:8080"
    volumes:
      - ./ecs_fargate_app/frontend/src:/app/src
      - ./ecs_fargate_app/frontend/public:/app/public
      - ./ecs_fargate_app/frontend/index.html:/app/index.html
      - ./ecs_fargate_app/frontend/package.json:/app/package.json
      - ./ecs_fargate_app/frontend/vite.config.ts:/app/vite.config.ts
    environment:
      - VITE_API_URL=http://localhost:8080/api
    depends_on:
      - backend
</file>

<file path="finch.yaml">
# finch.yaml
version: 1
builder:
  name: buildkit
  settings:
    platforms: linux/amd64

volumes:
  npm-cache:
    path: /root/.npm
    scope: shared
</file>

<file path="LICENSE">
MIT No Attribution

Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</file>

<file path="package.json">
{
  "name": "well-architected-iac-analyzer",
  "version": "1.0.0",
  "scripts": {
    "dev": "./dev.sh",
    "dev:down": "finch compose -f finch-compose.dev.yaml down",
    "dev:clean": "finch compose -f finch-compose.dev.yaml down -v"
  }
}
</file>

<file path="README.md">
# Well-Architected IaC (Infrastructure as Code) Analyzer

![solutions_diagram](/assets/wa_genai_app_diagram.png)

## Description 

Well-Architected Infrastructure as Code (IaC) Analyzer is a project that demonstrates how generative AI can be used to evaluate infrastructure code for alignment with best practices.

It features a modern web application built with React and AWS Cloudscape Design System, allowing users to upload IaC documents (e.g., AWS CloudFormation or Terraform templates) or architecture diagrams for assessment. The application leverages Amazon Bedrock to analyze the infrastructure against AWS Well-Architected best practices. These best practices are sourced from AWS Well-Architected whitepapers and synchronized with the Amazon Bedrock knowledge base.

This tool provides users with insights into how well their infrastructure code aligns with or deviates from established AWS best practices, offering suggestions for improving cloud architecture designs. For architecture diagrams, it can even generate corresponding IaC templates following AWS best practices.

The project deploys resources running on the following AWS services:
* Amazon Virtual Private Cloud (VPC)
* Application Load Balancer
* Amazon Elastic Container Service (ECS)
* AWS Fargate
* Amazon S3
* AWS Lambda
* Amazon Bedrock

## Features

- Upload and analyze Infrastructure as Code templates:
  - CloudFormation (YAML/JSON)
  - Terraform (.tf)
- Upload and analyze architecture diagrams:
  - PNG format
  - JPEG/JPG format
- Generate IaC templates from architecture diagrams
- Real-time analysis against Well-Architected best practices
- Integration with AWS Well-Architected Tool
- Export analysis results and recommendations

![wa_aic_analyzer_screenshot_main](/assets/wa_aic_analyzer_screenshot_main.png)

![wa_aic_analyzer_screenshot_results](/assets/wa_aic_analyzer_screenshot_results.png)

![wa_aic_analyzer_screenshot_details](/assets/wa_aic_analyzer_screenshot_details.png)

![wa_aic_analyzer_screenshot_wa_tool](/assets/wa_aic_analyzer_screenshot_wa_tool.png)

![wa_aic_analyzer_screenshot_template_generation](/assets/wa_aic_analyzer_screenshot_template_generation.png)

## Prerequisites

The following tools must be installed on your local machine:

* [Node.js](https://nodejs.org/en/download) (v18 or later) and npm
* [Python](https://www.python.org/downloads/) (v3.11 or later) and pip
* [AWS CDK CLI](https://docs.aws.amazon.com/cdk/v2/guide/cli.html)
* Either one of these container tools:
  * [Finch](https://github.com/runfinch/finch?tab=readme-ov-file#installing-finch) (default)
  * [Docker](https://docs.docker.com/get-started/get-docker/)
* [AWS CLI](https://docs.aws.amazon.com/cli/v1/userguide/cli-chap-install.html) configured with [appropriate credentials](https://docs.aws.amazon.com/cli/v1/userguide/cli-chap-configure.html)

### AWS Bedrock Model Access

You must enable access to the following models in your AWS region:
* **Titan Text Embeddings V2**
* **Claude 3.5 Sonnet v2**

To enable these models, follow the instructions [here](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html).

## Installation and Deployment

> **Note:** If you would like to change the default Load Balancer scheme or AI model, check the [Configuration Options section](#configuration-options) first before deploying.

You have two options for deploying this solution:

### Option 1: Using the Deployment Script (Recommended)

1. Clone the Repository
```bash
git clone https://github.com/aws-samples/well-architected-iac-analyzer.git
cd well-architected-iac-analyzer
```

2. Make the deployment script executable:
```bash
chmod +x deploy-wa-analyzer.sh
```

3. Deploy with default settings (us-west-2 region and Finch as container tool):
```bash
./deploy-wa-analyzer.sh
```

4. Or deploy with specific options:
```bash
# Deploy to a specific region
./deploy-wa-analyzer.sh -r us-east-1

# Deploy using Docker instead of Finch
./deploy-wa-analyzer.sh -c docker

# Deploy to a specific region using Docker
./deploy-wa-analyzer.sh -r us-east-1 -c docker
```

The script will automatically:
- Check for prerequisites
- Set up the Python virtual environment
- Install all dependencies
- Deploy the CDK stack
- Provide post-deployment information

### Option 2: Manual Deployment

<details>

<summary>If you prefer to deploy step by step, expand this section for more instructions:</summary>

#### 1. Clone the Repository
```bash
git clone https://github.com/aws-samples/well-architected-iac-analyzer.git
cd well-architected-iac-analyzer
```

#### 2. Set Up Python Virtual Environment
```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
# On Linux/macOS:
source .venv/bin/activate
# On Windows:
.venv\Scripts\activate

# Verify you're in the virtual environment
# You should see (.venv) at the beginning of your prompt
```

#### 3. Install Dependencies

Install Python dependencies:
```bash
pip3 install -r requirements.txt
```

Install CDK dependencies:
```bash
npm install
```

Install Frontend dependencies:
```bash
cd ecs_fargate_app/frontend
npm install
cd ../..
```

Install Backend dependencies:
```bash
cd ecs_fargate_app/backend
npm install
cd ../..
```

#### 4. Deploy the Stack

Set the AWS region and ignore ECR credentials storage during CDK deployment:
```bash
export CDK_DEPLOY_REGION=us-west-2
export AWS_ECR_IGNORE_CREDS_STORAGE=true
```

Set the container runtime:
```bash
export CDK_DOCKER=finch  # For Finch (default)

# OR

export CDK_DOCKER=docker # For Docker
```

Bootstrap CDK (if not already done):
```bash
cdk bootstrap
```

Deploy the stack:
```bash
cdk deploy
```

</details>

## Accessing the Application

After successful deployment, you can find the Application Load Balancer (ALB) DNS name in:
1. The outputs of the `cdk deploy` command
2. The outputs section of the CloudFormation stack named `WA-IaC-Analyzer-{region}-GenAIStack` in the AWS Console

## Configuration Options

### Model Selection

If you want to use a different model than "Claude 3.5 Sonnet v2", update the config.ini with the correct [model ID](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns):
```ini
[settings]
model_id = anthropic.claude-3-5-sonnet-20241022-v2:0
```

> **Note:** This application has been primarily tested with "Claude 3.5 Sonnet v2". While other Bedrock models may work, using different models might lead to unexpected results. The default model ID is set to `anthropic.claude-3-5-sonnet-20241022-v2:0`.

### Load Balancer Scheme Selection

By default, this project will deploy the Load Balancer scheme as [**internal**](https://docs.aws.amazon.com./elasticloadbalancing/latest/userguide/how-elastic-load-balancing-works.html#load-balancer-scheme) **(Private load balancer)**. To access the application, you will need to be in the private network connected to the deployed VPC, either via:
* [VPC peering](https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html)
* VPN
* AWS Direct Connect
* Other network connectivity solutions

If you need to change the load balancer scheme to [**internet-facing**](https://docs.aws.amazon.com./elasticloadbalancing/latest/userguide/how-elastic-load-balancing-works.html#load-balancer-scheme), you can modify the `public_load_balancer` parameter in the config.ini file:
```ini
[settings]
public_load_balancer = True
```
 **Security Warning**: This project is prepared as a **demo** with **no authentication mechanism**. If you change the load balancer to be **internet-facing**, the application and all its functionalities will be accessible directly through the internet without authentication. Proceed with caution and understand the security implications.

## Clean up

You have two options to remove all resources created by this solution:

### Option 1 - Using the Destroy Script (Recommended)

1. Make the destroy script executable:
```bash
chmod +x destroy-wa-analyzer.sh
```

2. Run the script:
```bash
# With default settings (us-west-2 region and Finch as container tool)
./destroy-wa-analyzer.sh

# Specify a different region
./destroy-wa-analyzer.sh -r us-east-1

# Use Docker instead of Finch
./destroy-wa-analyzer.sh -c docker

# Specify both region and container tool
./destroy-wa-analyzer.sh -r us-east-1 -c docker
```

The script will automatically:
- Verify prerequisites
- Set up the necessary environment
- Destroy all resources in the stack

### Option 2 - Using AWS Console

1. Open the CloudFormation console
2. Find and delete the stack named `WA-IaC-Analyzer-{region}-GenAIStack`

## Local Development

For development purposes, you can run the application locally using either Finch (default) or Docker containers. This allows you to make changes to the code and see them reflected immediately without having to deploy to AWS.

### Prerequisites for Local Development

In addition to the main prerequisites, ensure you have:
* Either Finch or Docker installed and running
* AWS credentials configured with access to required services
* Access to Amazon Bedrock service and the required models (as described in the main Prerequisites section)

### Setting up Required AWS Resources

> **Note for Existing Stack Users**: If you have already deployed this CDK stack in your AWS account, you can skip the manual resource creation steps below. Instead:
> 1. Go to the CloudFormation console and find your stack (it starts with "WA-IaC-Analyzer-")
> 2. In the "Outputs" tab of the CDK CloudFormation stack, find:
>    - `KnowledgeBaseID`: Use this value for KNOWLEDGE_BASE_ID in your .env file (for "Setting up Local Development Environment" section below)
>    - `WellArchitectedDocsS3Bucket`: Use this value for WA_DOCS_S3_BUCKET in your .env file (for "Setting up Local Development Environment" section below)
> 
> If you haven't deployed the stack yet, follow the steps below to create the required resources manually:

1. Create an S3 bucket:
   ```bash
   aws s3 mb s3://your-bucket-name --region your-aws-region
   ```

2. Upload Well-Architected documents:
   ```bash
   aws s3 cp ecs_fargate_app/well_architected_docs/ s3://your-bucket-name/ --recursive
   ```

3. Create a Bedrock Knowledge Base:
   - Go to the Amazon Bedrock console
   - Navigate to Knowledge bases
   - Click "Create knowledge base with vector store"
   - Enter a name for your knowledge base
   - Select "Amazon S3" as the data source
   - Click "Next"
   - Add your S3 bucket as a data source:
     - Choose the bucket you created
     - Leave all other settings as default
     - Click "Next"
   - Select "Titan Text Embeddings v2" as the embedding model and use the default Vector database settings
   - Click "Next" and Complete the knowledge base creation
   - Note the Knowledge Base ID from the details page

### Setting up Local Development Environment

1. Create a `.env` file in the root directory with the following variables:
```ini
AWS_REGION=your-aws-region-key
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
WA_DOCS_S3_BUCKET=your-s3-bucket
KNOWLEDGE_BASE_ID=your-kb-id
MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0
```

2. Make the development script executable:
```bash
chmod +x dev.sh
```

3. Start the development environment:
```bash
# Start development environment using Finch
./dev.sh -c finch

# OR, using Docker
./dev.sh -c docker
```

This will:
- Build and start the frontend container (available at http://localhost:8080)
- Build and start the backend container (available at http://localhost:3000)
- Enable hot reloading for both frontend and backend changes
- Mount source code directories as volumes for immediate updates

### Development Commands

```bash
# Start development environment using Finch
./dev.sh -c finch

# OR, using Docker
./dev.sh -c docker

# Stop development environment
npm run dev:down

# Clean up development environment (removes volumes)
npm run dev:clean
```

### Switching Between Development and Production

- Local development uses `finch-compose.dev.yaml` for container configuration
- Production deployment continues to use CDK as described in the Installation and Deployment section

## Contributing

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This library is licensed under the MIT-0 License. See the LICENSE file.
</file>

<file path="requirements.txt">
aws-cdk-lib==2.162.1
constructs>=10.0.0,<11.0.0
cdklabs.generative_ai_cdk_constructs==0.1.277
</file>

</files>
